{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[Chainer](http://chainer.org/) とはニューラルネットの実装を簡単にしたフレームワークです。\n",
    "\n",
    "* 今回は言語の分野でニューラルネットを適用してみました。\n",
    "\n",
    "![](./pictures/Chainer.jpg)\n",
    "\n",
    "* 今回は言語モデルを作成していただきます。\n",
    "\n",
    "\n",
    "言語モデルとはある単語が来たときに次の単語に何が来やすいかを予測するものです。\n",
    "\n",
    "言語モデルにはいくつか種類があるのでここでも紹介しておきます。\n",
    "\n",
    "* n-グラム言語モデル\n",
    " * 単語の数を単純に数え挙げて作成されるモデル。考え方としてはデータにおけるある単語の頻度に近い\n",
    "* ニューラル言語モデル\n",
    " * 単語の辞書ベクトルを潜在空間ベクトルに落とし込み、ニューラルネットで次の文字を学習させる手法\n",
    "\n",
    "* リカレントニューラル言語モデル\n",
    " * 基本的なアルゴリズムはニューラル言語モデルと同一だが過去に使用した単語を入力に加えることによって文脈を考慮した言語モデルの学習が可能となる。ニューラル言語モデルとは異なり、より古い情報も取得可能\n",
    "\n",
    "以下では、このChainerを利用しデータを準備するところから実際に言語モデルを構築し学習・評価を行うまでの手順を解説します。\n",
    "\n",
    "1. [各種ライブラリ導入](#各種ライブラリ導入) \n",
    "2. [初期設定](#初期設定) \n",
    "3. [データ入力](#データ入力)\n",
    "4. [リカレントニューラル言語モデル設定](#リカレントニューラル言語モデル設定) \n",
    "5. [学習を始める前の設定](#学習を始める前の設定)\n",
    "6. [パラメータ更新方法（確率的勾配法）](#パラメータ更新方法（確率的勾配法）)\n",
    "7. [言語の予測](#言語の予測)\n",
    "\n",
    "もしGPUを使用したい方は、以下にまとめてあるのでご参考ください。\n",
    "\n",
    "[Chainer を用いてリカレントニューラル言語モデル作成のサンプルコードを解説してみた](http://qiita.com/GushiSnow/private/b34da4962dd930d1487a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種ライブラリ導入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerの言語処理では多数のライブラリを導入します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from chainer import cuda, Variable, FunctionSet, optimizers\n",
    "import chainer.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`導入するライブラリの代表例は下記です。\n",
    "\n",
    "* `numpy`: 行列計算などの複雑な計算を行なうライブラリ\n",
    "* `chainer`: Chainerの導入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記を設定しています。\n",
    "* 学習回数：n_epochs\n",
    "* ニューラルネットのユニット数：n_units\n",
    "* 確率的勾配法に使用するデータの数：batchsize\n",
    "* 学習に使用する文字列の長さ：bprop_len\n",
    "* 勾配法で使用する敷居値：grad_clip\n",
    "* 学習データの格納場所：data_dir\n",
    "* モデルの出力場所：checkpoint_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-------------Explain7 in the Qiita-------------\n",
    "n_epochs    = 10\n",
    "n_units     = 128\n",
    "batchsize   = 50\n",
    "bprop_len   = 50\n",
    "grad_clip   = 5\n",
    "data_dir = \"data_hands_on\"\n",
    "checkpoint_dir = \"cv\"\n",
    "#-------------Explain7 in the Qiita-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ入力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用にダウンロードしたファイルをプログラムに読ませる処理を関数化しています\n",
    "\n",
    "* 学習データをバイナリ形式で読み込んでいます。\n",
    "* 文字データを確保するための行列を定義しています。\n",
    "* データは単語をキー、語彙数の連番idを値とした辞書データにして行列データセットに登録しています。\n",
    "\n",
    "学習データ、単語の長さ、語彙数を取得しています。\n",
    "上記をそれぞれ行列データとして保持しています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_hands_on/linux_source.c\n",
      "corpus length: 3490080\n",
      "vocab size: 80\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "#-------------Explain1 in the Qiita-------------\n",
    "def load_data():\n",
    "    vocab = {}\n",
    "    print ('%s/linux_source.c'% data_dir)\n",
    "    words = open('%s/linux_source.c' % data_dir, 'rb').read()\n",
    "    words = list(words)\n",
    "    dataset = np.ndarray((len(words),), dtype=np.int32)\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "        dataset[i] = vocab[word]\n",
    "    print('corpus length:', len(words))\n",
    "    print('vocab size:', len(vocab))\n",
    "    return dataset, words, vocab\n",
    "#-------------Explain1 in the Qiita-------------\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "    \n",
    "train_data, words, vocab = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リカレントニューラル言語モデル設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNLM(リカレントニューラル言語モデルの設定を行っています）\n",
    "\n",
    "* EmbedIDで行列変換を行い、疎なベクトルを密なベクトルに変換しています。\n",
    "* 出力が4倍の理由は入力層、出力層、忘却層、前回の出力をLSTMでは入力に使用するためです。\n",
    "* 隠れ層に前回保持した隠れ層の状態を入力することによってLSTMを実現しています。\n",
    "* ドロップアウトにより過学習するのを抑えています。\n",
    "* 予測を行なうメソッドも実装しており、入力されたデータ、状態を元に次の文字列と状態を返すような関数になっています。\n",
    "* モデルの初期化を行なう関数もここで定義しています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CharRNN(FunctionSet):\n",
    "\n",
    "#-------------Explain2 in the Qiita-------------\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        super(CharRNN, self).__init__(\n",
    "            embed = F.EmbedID(n_vocab, n_units),\n",
    "            l1_x = F.Linear(n_units, 4*n_units),\n",
    "            l1_h = F.Linear(n_units, 4*n_units),\n",
    "            l2_h = F.Linear(n_units, 4*n_units),\n",
    "            l2_x = F.Linear(n_units, 4*n_units),\n",
    "            l3   = F.Linear(n_units, n_vocab),\n",
    "        )\n",
    "        for param in self.parameters:\n",
    "            param[:] = np.random.uniform(-0.08, 0.08, param.shape)\n",
    "\n",
    "    def forward_one_step(self, x_data, y_data, state, train=True, dropout_ratio=0.5):\n",
    "        x = Variable(x_data, volatile=not train)\n",
    "        t = Variable(y_data, volatile=not train)\n",
    "\n",
    "        h0      = self.embed(x)\n",
    "        h1_in   = self.l1_x(F.dropout(h0, ratio=dropout_ratio, train=train)) + self.l1_h(state['h1'])\n",
    "        c1, h1  = F.lstm(state['c1'], h1_in)\n",
    "        h2_in   = self.l2_x(F.dropout(h1, ratio=dropout_ratio, train=train)) + self.l2_h(state['h2'])\n",
    "        c2, h2  = F.lstm(state['c2'], h2_in)\n",
    "        y       = self.l3(F.dropout(h2, ratio=dropout_ratio, train=train))\n",
    "        state   = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "\n",
    "        return state, F.softmax_cross_entropy(y, t)\n",
    "#-------------Explain2 in the Qiita-------------\n",
    "\n",
    "    def predict(self, x_data, state):\n",
    "        x = Variable(x_data, volatile=True)\n",
    "\n",
    "        h0      = self.embed(x)\n",
    "        h1_in   = self.l1_x(h0) + self.l1_h(state['h1'])\n",
    "        c1, h1  = F.lstm(state['c1'], h1_in)\n",
    "        h2_in   = self.l2_x(h1) + self.l2_h(state['h2'])\n",
    "        c2, h2  = F.lstm(state['c2'], h2_in)\n",
    "        y       = self.l3(h2)\n",
    "        state   = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "\n",
    "        return state, F.softmax(y)\n",
    "\n",
    "def make_initial_state(n_units, batchsize=50, train=True):\n",
    "    return {name: Variable(np.zeros((batchsize, n_units), dtype=np.float32),\n",
    "            volatile=not train)\n",
    "            for name in ('c1', 'h1', 'c2', 'h2')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNLM(リカレントニューラル言語モデルの設定を行っています）\n",
    "\n",
    "* 作成したリカレントニューラル言語モデルを導入しています。\n",
    "* 最適化の手法はRMSpropを使用\n",
    "http://qiita.com/skitaoka/items/e6afbe238cd69c899b2a\n",
    "* 初期のパラメータを-0.1〜0.1の間で与えています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-----------------------------------model----------------------------------*\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_sorted_funcs', 'collect_parameters', 'copy_parameters_from', 'embed', 'forward_one_step', 'gradients', 'l1_h', 'l1_x', 'l2_h', 'l2_x', 'l3', 'parameters', 'predict', 'to_cpu', 'to_gpu']\n",
      "*----------------------------------embed-----------------------------------*\n",
      "['W', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_check_data_type_backward', '_check_data_type_forward', 'backward', 'backward_cpu', 'backward_gpu', 'check_type_backward', 'check_type_forward', 'forward', 'forward_cpu', 'forward_gpu', 'gW', 'gradient_names', 'gradients', 'label', 'parameter_names', 'parameters', 'to_cpu', 'to_gpu', 'unchain']\n",
      "*--------------------------------model l1_x--------------------------------*\n",
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imod__', '__imul__', '__index__', '__init__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n",
      "Linear\n"
     ]
    }
   ],
   "source": [
    "# Prepare RNNLM model\n",
    "model = CharRNN(len(vocab), n_units)\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=2e-3, alpha=0.95, eps=1e-8)\n",
    "optimizer.setup(model.collect_parameters())\n",
    "\n",
    "#-------------Explain3 in the Qiita-------------\n",
    "print(\"*-----------------------------------model----------------------------------*\")\n",
    "print(dir(model))\n",
    "print(\"*----------------------------------embed-----------------------------------*\")\n",
    "print(dir(model.embed))\n",
    "print(\"*--------------------------------model l1_x--------------------------------*\")\n",
    "print(dir(model.l1_x.W))\n",
    "print(model.l1_x.label)\n",
    "#-------------Explain3 in the Qiita-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習を始める前の設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習データのサイズを取得 \n",
    "* ジャンプの幅を設定（順次学習しない）\n",
    "* パープレキシティを0で初期化 \n",
    "* 最初の時間情報を取得 \n",
    "* 初期状態を現在の状態に付与 \n",
    "* 状態の初期化 \n",
    "* 損失を0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_len    = train_data.shape[0]\n",
    "jump         = whole_len / batchsize\n",
    "epoch        = 0\n",
    "start_at     = time.time()\n",
    "cur_at       = start_at\n",
    "state        = make_initial_state(n_units, batchsize=batchsize)\n",
    "accum_loss   = Variable(np.zeros((), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータ更新方法（確率的勾配法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 確率的勾配法を用いて学習している。\n",
    "* 一定のデータを選択し損失計算をしながらパラメータ更新をしている。\n",
    "* 逐次尤度の計算も行っている。\n",
    "\n",
    "* 適宜学習データのパープレキシティも計算している\n",
    "\n",
    "* バックプロパゲーションでパラメータを更新する。\n",
    "* [truncate](http://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html#recurrent-neural-network)はどれだけ過去の履歴を見るかを表している。\n",
    "* optimizer.clip_gradsの部分でL2正則化をかけている。\n",
    "* 過学習を抑えるために学習効率を徐々に下げている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0/69801.6, train_loss = 4.374126892089844, time = 15.00\n",
      "2.0/69801.6, train_loss = 4.283194885253907, time = 0.75\n",
      "3.0/69801.6, train_loss = 3.860372314453125, time = 0.72\n",
      "4.0/69801.6, train_loss = 3.9505029296875, time = 0.66\n",
      "5.0/69801.6, train_loss = 3.8545703125, time = 0.65\n",
      "6.0/69801.6, train_loss = 3.72376220703125, time = 0.64\n",
      "7.0/69801.6, train_loss = 3.5138900756835936, time = 0.70\n",
      "8.0/69801.6, train_loss = 3.6909906005859376, time = 0.63\n",
      "9.0/69801.6, train_loss = 3.8485650634765625, time = 0.64\n",
      "10.0/69801.6, train_loss = 3.7408856201171874, time = 0.75\n",
      "11.0/69801.6, train_loss = 3.617032470703125, time = 0.72\n",
      "12.0/69801.6, train_loss = 3.5801150512695314, time = 0.78\n",
      "13.0/69801.6, train_loss = 3.544320068359375, time = 0.70\n",
      "14.0/69801.6, train_loss = 3.726731262207031, time = 0.68\n",
      "15.0/69801.6, train_loss = 3.6451376342773436, time = 0.68\n",
      "16.0/69801.6, train_loss = 3.690571594238281, time = 0.71\n",
      "17.0/69801.6, train_loss = 3.636831970214844, time = 0.65\n",
      "18.0/69801.6, train_loss = 3.426300048828125, time = 0.60\n",
      "19.0/69801.6, train_loss = 3.718247375488281, time = 0.82\n",
      "20.0/69801.6, train_loss = 3.703130187988281, time = 0.68\n",
      "21.0/69801.6, train_loss = 3.7016140747070314, time = 0.63\n",
      "22.0/69801.6, train_loss = 3.5339434814453123, time = 0.63\n",
      "23.0/69801.6, train_loss = 3.4388299560546876, time = 0.62\n",
      "24.0/69801.6, train_loss = 3.6539581298828123, time = 0.67\n",
      "25.0/69801.6, train_loss = 3.579648132324219, time = 0.63\n",
      "26.0/69801.6, train_loss = 3.6394720458984375, time = 0.68\n",
      "27.0/69801.6, train_loss = 3.538088073730469, time = 0.69\n",
      "28.0/69801.6, train_loss = 3.438606872558594, time = 0.64\n",
      "29.0/69801.6, train_loss = 3.435274353027344, time = 0.66\n",
      "30.0/69801.6, train_loss = 3.5964178466796874, time = 0.68\n",
      "31.0/69801.6, train_loss = 3.5104415893554686, time = 0.66\n",
      "32.0/69801.6, train_loss = 3.405253601074219, time = 0.80\n",
      "33.0/69801.6, train_loss = 3.435697326660156, time = 0.67\n",
      "34.0/69801.6, train_loss = 3.3297573852539064, time = 0.68\n",
      "35.0/69801.6, train_loss = 3.43087158203125, time = 0.80\n",
      "36.0/69801.6, train_loss = 3.3828759765625, time = 0.78\n",
      "37.0/69801.6, train_loss = 3.4438327026367186, time = 0.85\n",
      "38.0/69801.6, train_loss = 3.317688293457031, time = 0.68\n",
      "39.0/69801.6, train_loss = 3.1735330200195313, time = 0.65\n",
      "40.0/69801.6, train_loss = 3.4004666137695314, time = 0.62\n",
      "41.0/69801.6, train_loss = 3.334483642578125, time = 0.64\n",
      "42.0/69801.6, train_loss = 3.230529479980469, time = 0.70\n",
      "43.0/69801.6, train_loss = 3.2754507446289063, time = 0.64\n",
      "44.0/69801.6, train_loss = 3.126589050292969, time = 0.66\n",
      "45.0/69801.6, train_loss = 3.265015869140625, time = 0.68\n",
      "46.0/69801.6, train_loss = 3.3057733154296876, time = 0.70\n",
      "47.0/69801.6, train_loss = 3.120838623046875, time = 0.71\n",
      "48.0/69801.6, train_loss = 3.1785748291015623, time = 0.63\n",
      "49.0/69801.6, train_loss = 3.213304443359375, time = 0.66\n",
      "50.0/69801.6, train_loss = 3.0786676025390625, time = 0.71\n",
      "51.0/69801.6, train_loss = 3.1948928833007812, time = 0.72\n",
      "52.0/69801.6, train_loss = 3.0520269775390627, time = 0.68\n",
      "53.0/69801.6, train_loss = 3.0775070190429688, time = 0.66\n",
      "54.0/69801.6, train_loss = 3.1689797973632814, time = 0.63\n",
      "55.0/69801.6, train_loss = 3.03840087890625, time = 0.62\n",
      "56.0/69801.6, train_loss = 3.1931552124023437, time = 0.67\n",
      "57.0/69801.6, train_loss = 3.1393923950195313, time = 0.64\n",
      "58.0/69801.6, train_loss = 2.993363037109375, time = 0.63\n",
      "59.0/69801.6, train_loss = 3.0596990966796875, time = 0.62\n",
      "60.0/69801.6, train_loss = 3.005578918457031, time = 0.63\n",
      "61.0/69801.6, train_loss = 3.1613018798828123, time = 0.62\n",
      "62.0/69801.6, train_loss = 3.022474365234375, time = 0.66\n",
      "63.0/69801.6, train_loss = 2.910547790527344, time = 0.65\n",
      "64.0/69801.6, train_loss = 3.065528564453125, time = 0.62\n",
      "65.0/69801.6, train_loss = 2.9872341918945313, time = 0.65\n",
      "66.0/69801.6, train_loss = 3.03759033203125, time = 0.71\n",
      "67.0/69801.6, train_loss = 3.0691098022460936, time = 0.70\n",
      "68.0/69801.6, train_loss = 2.883868408203125, time = 0.73\n",
      "69.0/69801.6, train_loss = 2.87774169921875, time = 0.63\n",
      "70.0/69801.6, train_loss = 3.0551837158203123, time = 0.64\n",
      "71.0/69801.6, train_loss = 2.9906216430664063, time = 0.63\n",
      "72.0/69801.6, train_loss = 2.9961813354492186, time = 0.70\n",
      "73.0/69801.6, train_loss = 2.858243713378906, time = 0.62\n",
      "74.0/69801.6, train_loss = 2.865709228515625, time = 0.67\n",
      "75.0/69801.6, train_loss = 3.002021484375, time = 0.63\n",
      "76.0/69801.6, train_loss = 2.9463455200195314, time = 0.62\n",
      "77.0/69801.6, train_loss = 3.0160040283203124, time = 0.61\n",
      "78.0/69801.6, train_loss = 2.9495199584960936, time = 0.61\n",
      "79.0/69801.6, train_loss = 2.757285461425781, time = 0.62\n",
      "80.0/69801.6, train_loss = 2.9785055541992187, time = 0.67\n",
      "81.0/69801.6, train_loss = 2.920438232421875, time = 0.65\n",
      "82.0/69801.6, train_loss = 2.9740643310546875, time = 0.66\n",
      "83.0/69801.6, train_loss = 2.9163543701171877, time = 0.62\n",
      "84.0/69801.6, train_loss = 2.697911682128906, time = 0.62\n",
      "85.0/69801.6, train_loss = 2.8520916748046874, time = 0.62\n",
      "86.0/69801.6, train_loss = 2.9999945068359377, time = 0.66\n",
      "87.0/69801.6, train_loss = 2.8849578857421876, time = 0.64\n",
      "88.0/69801.6, train_loss = 2.8920501708984374, time = 0.62\n",
      "89.0/69801.6, train_loss = 2.7284786987304686, time = 0.63\n",
      "90.0/69801.6, train_loss = 2.7362161254882813, time = 0.61\n",
      "91.0/69801.6, train_loss = 2.9819161987304685, time = 0.62\n",
      "92.0/69801.6, train_loss = 2.883908996582031, time = 0.62\n",
      "93.0/69801.6, train_loss = 2.9197146606445314, time = 0.67\n",
      "94.0/69801.6, train_loss = 2.8321932983398437, time = 0.63\n",
      "95.0/69801.6, train_loss = 2.617889099121094, time = 0.62\n",
      "96.0/69801.6, train_loss = 2.863136901855469, time = 0.61\n",
      "97.0/69801.6, train_loss = 2.826754455566406, time = 0.62\n",
      "98.0/69801.6, train_loss = 2.96610107421875, time = 0.63\n",
      "99.0/69801.6, train_loss = 2.72625732421875, time = 0.66\n",
      "100.0/69801.6, train_loss = 2.5712200927734377, time = 0.63\n",
      "101.0/69801.6, train_loss = 2.92093017578125, time = 0.61\n",
      "102.0/69801.6, train_loss = 2.807034912109375, time = 0.61\n",
      "103.0/69801.6, train_loss = 2.8414871215820314, time = 0.63\n",
      "104.0/69801.6, train_loss = 2.836608581542969, time = 0.61\n",
      "105.0/69801.6, train_loss = 2.621376647949219, time = 0.65\n",
      "106.0/69801.6, train_loss = 2.6104345703125, time = 0.60\n",
      "107.0/69801.6, train_loss = 2.8926409912109374, time = 0.59\n",
      "108.0/69801.6, train_loss = 2.7672723388671874, time = 0.60\n",
      "109.0/69801.6, train_loss = 2.7778085327148436, time = 0.60\n",
      "110.0/69801.6, train_loss = 2.6124996948242187, time = 0.59\n",
      "111.0/69801.6, train_loss = 2.5698037719726563, time = 0.64\n",
      "112.0/69801.6, train_loss = 2.8031240844726564, time = 0.60\n",
      "113.0/69801.6, train_loss = 2.8003167724609375, time = 0.59\n",
      "114.0/69801.6, train_loss = 2.830586242675781, time = 0.58\n",
      "115.0/69801.6, train_loss = 2.693414611816406, time = 0.60\n",
      "116.0/69801.6, train_loss = 2.4566143798828124, time = 0.60\n",
      "117.0/69801.6, train_loss = 2.7996890258789064, time = 0.65\n",
      "118.0/69801.6, train_loss = 2.721216735839844, time = 0.59\n",
      "119.0/69801.6, train_loss = 2.7530038452148435, time = 0.59\n",
      "120.0/69801.6, train_loss = 2.7028350830078125, time = 0.61\n",
      "121.0/69801.6, train_loss = 2.4264434814453124, time = 0.59\n",
      "122.0/69801.6, train_loss = 2.6423651123046876, time = 0.59\n",
      "123.0/69801.6, train_loss = 2.805417175292969, time = 0.65\n",
      "124.0/69801.6, train_loss = 2.707947082519531, time = 0.59\n",
      "125.0/69801.6, train_loss = 2.686881103515625, time = 0.59\n",
      "126.0/69801.6, train_loss = 2.453623809814453, time = 0.60\n",
      "127.0/69801.6, train_loss = 2.4481550598144532, time = 0.59\n",
      "128.0/69801.6, train_loss = 2.806344299316406, time = 0.59\n",
      "129.0/69801.6, train_loss = 2.6714996337890624, time = 0.64\n",
      "130.0/69801.6, train_loss = 2.6991815185546875, time = 0.59\n",
      "131.0/69801.6, train_loss = 2.632795715332031, time = 0.59\n",
      "132.0/69801.6, train_loss = 2.362914733886719, time = 0.60\n",
      "133.0/69801.6, train_loss = 2.6749618530273436, time = 0.60\n",
      "134.0/69801.6, train_loss = 2.61774169921875, time = 0.59\n",
      "135.0/69801.6, train_loss = 2.7715939331054686, time = 0.63\n",
      "136.0/69801.6, train_loss = 2.516309967041016, time = 0.59\n",
      "137.0/69801.6, train_loss = 2.3168466186523435, time = 0.60\n",
      "138.0/69801.6, train_loss = 2.695550537109375, time = 0.59\n",
      "139.0/69801.6, train_loss = 2.631009826660156, time = 0.59\n",
      "140.0/69801.6, train_loss = 2.6105111694335936, time = 0.59\n",
      "141.0/69801.6, train_loss = 2.60380615234375, time = 0.64\n",
      "142.0/69801.6, train_loss = 2.3338946533203124, time = 0.60\n",
      "143.0/69801.6, train_loss = 2.397059326171875, time = 0.60\n",
      "144.0/69801.6, train_loss = 2.686351318359375, time = 0.60\n",
      "145.0/69801.6, train_loss = 2.597204284667969, time = 0.60\n",
      "146.0/69801.6, train_loss = 2.6088250732421874, time = 0.59\n",
      "147.0/69801.6, train_loss = 2.402690582275391, time = 0.79\n",
      "148.0/69801.6, train_loss = 2.311776123046875, time = 0.76\n",
      "149.0/69801.6, train_loss = 2.606189880371094, time = 0.68\n",
      "150.0/69801.6, train_loss = 2.579651184082031, time = 0.82\n",
      "151.0/69801.6, train_loss = 2.666639709472656, time = 0.66\n",
      "152.0/69801.6, train_loss = 2.4606163024902346, time = 0.66\n",
      "153.0/69801.6, train_loss = 2.2048185729980467, time = 0.80\n",
      "154.0/69801.6, train_loss = 2.6131057739257812, time = 0.70\n",
      "155.0/69801.6, train_loss = 2.5055390930175783, time = 0.68\n",
      "156.0/69801.6, train_loss = 2.5927047729492188, time = 0.66\n",
      "157.0/69801.6, train_loss = 2.485149230957031, time = 0.70\n",
      "158.0/69801.6, train_loss = 2.191769866943359, time = 0.68\n",
      "159.0/69801.6, train_loss = 2.3751872253417967, time = 0.65\n",
      "160.0/69801.6, train_loss = 2.597181701660156, time = 0.68\n",
      "161.0/69801.6, train_loss = 2.579549560546875, time = 0.67\n",
      "162.0/69801.6, train_loss = 2.4865896606445315, time = 0.72\n",
      "163.0/69801.6, train_loss = 2.2616893005371095, time = 0.71\n",
      "164.0/69801.6, train_loss = 2.204287414550781, time = 0.65\n",
      "165.0/69801.6, train_loss = 2.6099700927734375, time = 0.71\n",
      "166.0/69801.6, train_loss = 2.4748985290527346, time = 0.80\n",
      "167.0/69801.6, train_loss = 2.5072906494140623, time = 0.67\n",
      "168.0/69801.6, train_loss = 2.4150094604492187, time = 0.72\n",
      "169.0/69801.6, train_loss = 2.125884552001953, time = 0.67\n",
      "170.0/69801.6, train_loss = 2.4610919189453124, time = 0.68\n",
      "171.0/69801.6, train_loss = 2.443525848388672, time = 0.77\n",
      "172.0/69801.6, train_loss = 2.558204803466797, time = 0.83\n",
      "173.0/69801.6, train_loss = 2.3001895141601563, time = 0.88\n",
      "174.0/69801.6, train_loss = 2.0709532165527342, time = 0.68\n",
      "175.0/69801.6, train_loss = 2.4716998291015626, time = 0.71\n",
      "176.0/69801.6, train_loss = 2.4510342407226564, time = 0.72\n",
      "177.0/69801.6, train_loss = 2.430513916015625, time = 0.70\n",
      "178.0/69801.6, train_loss = 2.3995681762695313, time = 0.78\n",
      "179.0/69801.6, train_loss = 2.102936553955078, time = 0.75\n",
      "180.0/69801.6, train_loss = 2.1954637145996094, time = 0.80\n",
      "181.0/69801.6, train_loss = 2.5198550415039063, time = 0.91\n",
      "182.0/69801.6, train_loss = 2.3892062377929686, time = 0.90\n",
      "183.0/69801.6, train_loss = 2.434296875, time = 0.66\n",
      "184.0/69801.6, train_loss = 2.204425048828125, time = 0.71\n",
      "185.0/69801.6, train_loss = 2.027232818603516, time = 0.63\n",
      "186.0/69801.6, train_loss = 2.389374084472656, time = 0.64\n",
      "187.0/69801.6, train_loss = 2.4142500305175782, time = 0.64\n",
      "188.0/69801.6, train_loss = 2.530564422607422, time = 0.69\n",
      "189.0/69801.6, train_loss = 2.253700408935547, time = 0.67\n",
      "190.0/69801.6, train_loss = 1.9762225341796875, time = 0.93\n",
      "191.0/69801.6, train_loss = 2.4114434814453123, time = 1.07\n",
      "192.0/69801.6, train_loss = 2.302151947021484, time = 0.89\n",
      "193.0/69801.6, train_loss = 2.3997474670410157, time = 0.59\n",
      "194.0/69801.6, train_loss = 2.2631871032714845, time = 0.60\n",
      "195.0/69801.6, train_loss = 2.026741638183594, time = 0.60\n",
      "196.0/69801.6, train_loss = 2.194571075439453, time = 1.20\n",
      "197.0/69801.6, train_loss = 2.413321075439453, time = 0.60\n",
      "198.0/69801.6, train_loss = 2.343932647705078, time = 0.61\n",
      "199.0/69801.6, train_loss = 2.2488082885742187, time = 0.60\n",
      "200.0/69801.6, train_loss = 2.0417681884765626, time = 0.61\n",
      "201.0/69801.6, train_loss = 1.9984083557128907, time = 1.20\n",
      "202.0/69801.6, train_loss = 2.4184259033203124, time = 0.76\n",
      "203.0/69801.6, train_loss = 2.3167996215820312, time = 0.62\n",
      "204.0/69801.6, train_loss = 2.31781982421875, time = 0.63\n",
      "205.0/69801.6, train_loss = 2.2117811584472657, time = 0.66\n",
      "206.0/69801.6, train_loss = 1.881477813720703, time = 0.65\n",
      "207.0/69801.6, train_loss = 2.237288055419922, time = 0.69\n",
      "208.0/69801.6, train_loss = 2.2643658447265627, time = 0.79\n",
      "209.0/69801.6, train_loss = 2.3941485595703127, time = 0.64\n",
      "210.0/69801.6, train_loss = 2.104419403076172, time = 0.65\n",
      "211.0/69801.6, train_loss = 1.8718655395507813, time = 0.81\n",
      "212.0/69801.6, train_loss = 2.228268280029297, time = 0.64\n",
      "213.0/69801.6, train_loss = 2.2819807434082033, time = 0.63\n",
      "214.0/69801.6, train_loss = 2.2960205078125, time = 0.74\n",
      "215.0/69801.6, train_loss = 2.1814755249023436, time = 0.76\n",
      "216.0/69801.6, train_loss = 1.9690496826171875, time = 0.80\n",
      "217.0/69801.6, train_loss = 1.9744659423828126, time = 0.76\n",
      "218.0/69801.6, train_loss = 2.323946685791016, time = 0.73\n",
      "219.0/69801.6, train_loss = 2.2755198669433594, time = 0.83\n",
      "220.0/69801.6, train_loss = 2.1848159790039063, time = 0.87\n",
      "221.0/69801.6, train_loss = 2.0736216735839843, time = 1.12\n",
      "222.0/69801.6, train_loss = 1.8253500366210937, time = 1.07\n",
      "223.0/69801.6, train_loss = 2.1967791748046874, time = 0.73\n",
      "224.0/69801.6, train_loss = 2.227876739501953, time = 0.71\n",
      "225.0/69801.6, train_loss = 2.262899932861328, time = 0.62\n",
      "226.0/69801.6, train_loss = 2.0089376831054686, time = 0.85\n",
      "227.0/69801.6, train_loss = 1.7546572875976563, time = 2.72\n",
      "228.0/69801.6, train_loss = 2.1966346740722655, time = 0.60\n",
      "229.0/69801.6, train_loss = 2.156403045654297, time = 0.61\n",
      "230.0/69801.6, train_loss = 2.2110618591308593, time = 0.73\n",
      "231.0/69801.6, train_loss = 2.018907012939453, time = 0.64\n",
      "232.0/69801.6, train_loss = 1.8293856811523437, time = 0.80\n",
      "233.0/69801.6, train_loss = 1.9735650634765625, time = 0.94\n",
      "234.0/69801.6, train_loss = 2.2385508728027346, time = 0.71\n",
      "235.0/69801.6, train_loss = 2.1876644897460937, time = 0.95\n",
      "236.0/69801.6, train_loss = 2.029978790283203, time = 0.69\n",
      "237.0/69801.6, train_loss = 1.8804071044921875, time = 0.73\n",
      "238.0/69801.6, train_loss = 1.7656315612792968, time = 0.86\n",
      "239.0/69801.6, train_loss = 2.151645050048828, time = 1.21\n",
      "240.0/69801.6, train_loss = 2.1440106201171876, time = 0.92\n",
      "241.0/69801.6, train_loss = 2.107466125488281, time = 0.86\n",
      "242.0/69801.6, train_loss = 1.9792805480957032, time = 1.16\n",
      "243.0/69801.6, train_loss = 1.6949261474609374, time = 1.03\n",
      "244.0/69801.6, train_loss = 2.0337860107421877, time = 0.89\n",
      "245.0/69801.6, train_loss = 2.095948486328125, time = 0.71\n",
      "246.0/69801.6, train_loss = 2.202853546142578, time = 0.63\n",
      "247.0/69801.6, train_loss = 1.8799082946777343, time = 0.59\n",
      "248.0/69801.6, train_loss = 1.6536502075195312, time = 0.62\n",
      "249.0/69801.6, train_loss = 1.9820860290527345, time = 0.64\n",
      "250.0/69801.6, train_loss = 2.104707946777344, time = 0.61\n",
      "251.0/69801.6, train_loss = 2.1009010314941405, time = 0.84\n",
      "252.0/69801.6, train_loss = 1.9936700439453126, time = 0.67\n",
      "253.0/69801.6, train_loss = 1.7639222717285157, time = 0.62\n",
      "254.0/69801.6, train_loss = 1.7142979431152343, time = 0.65\n",
      "255.0/69801.6, train_loss = 2.1205772399902343, time = 0.60\n",
      "256.0/69801.6, train_loss = 2.065251770019531, time = 0.67\n",
      "257.0/69801.6, train_loss = 1.9909014892578125, time = 0.69\n",
      "258.0/69801.6, train_loss = 1.8545896911621094, time = 0.66\n",
      "259.0/69801.6, train_loss = 1.627275390625, time = 0.69\n",
      "260.0/69801.6, train_loss = 1.9461167907714845, time = 0.72\n",
      "261.0/69801.6, train_loss = 2.0230567932128904, time = 0.62\n",
      "262.0/69801.6, train_loss = 2.09577880859375, time = 0.66\n",
      "263.0/69801.6, train_loss = 1.7868692016601562, time = 0.71\n",
      "264.0/69801.6, train_loss = 1.5934178161621093, time = 0.60\n",
      "265.0/69801.6, train_loss = 1.9626609802246093, time = 0.61\n",
      "266.0/69801.6, train_loss = 1.9944563293457032, time = 0.60\n",
      "267.0/69801.6, train_loss = 2.027679138183594, time = 0.60\n",
      "268.0/69801.6, train_loss = 1.8328436279296876, time = 0.59\n",
      "269.0/69801.6, train_loss = 1.648236083984375, time = 0.63\n",
      "270.0/69801.6, train_loss = 1.7465711975097655, time = 0.59\n",
      "271.0/69801.6, train_loss = 2.0585418701171876, time = 0.59\n",
      "272.0/69801.6, train_loss = 1.9768241882324218, time = 0.60\n",
      "273.0/69801.6, train_loss = 1.851323699951172, time = 0.59\n",
      "274.0/69801.6, train_loss = 1.7092098999023437, time = 0.60\n",
      "275.0/69801.6, train_loss = 1.5688441467285157, time = 0.64\n",
      "276.0/69801.6, train_loss = 1.9632598876953125, time = 0.59\n",
      "277.0/69801.6, train_loss = 1.957910919189453, time = 0.58\n",
      "278.0/69801.6, train_loss = 1.9196461486816405, time = 0.59\n",
      "279.0/69801.6, train_loss = 1.7926322937011718, time = 0.59\n",
      "280.0/69801.6, train_loss = 1.456766357421875, time = 0.61\n",
      "281.0/69801.6, train_loss = 1.8539353942871093, time = 0.64\n",
      "282.0/69801.6, train_loss = 1.9044442749023438, time = 0.59\n",
      "283.0/69801.6, train_loss = 1.973719940185547, time = 0.59\n",
      "284.0/69801.6, train_loss = 1.7077769470214843, time = 0.58\n",
      "285.0/69801.6, train_loss = 1.4925602722167968, time = 0.64\n",
      "286.0/69801.6, train_loss = 1.7694586181640626, time = 0.60\n",
      "287.0/69801.6, train_loss = 1.89843505859375, time = 0.64\n",
      "288.0/69801.6, train_loss = 1.9437385559082032, time = 0.60\n",
      "289.0/69801.6, train_loss = 1.7816740417480468, time = 0.58\n",
      "290.0/69801.6, train_loss = 1.5694735717773438, time = 0.59\n",
      "291.0/69801.6, train_loss = 1.52284912109375, time = 0.62\n",
      "292.0/69801.6, train_loss = 1.9047053527832032, time = 0.61\n",
      "293.0/69801.6, train_loss = 1.9149720764160156, time = 0.60\n",
      "294.0/69801.6, train_loss = 1.789016876220703, time = 0.65\n",
      "295.0/69801.6, train_loss = 1.6498876953125, time = 0.59\n",
      "296.0/69801.6, train_loss = 1.4221954345703125, time = 0.63\n",
      "297.0/69801.6, train_loss = 1.788061065673828, time = 0.61\n",
      "298.0/69801.6, train_loss = 1.8544699096679687, time = 0.59\n",
      "299.0/69801.6, train_loss = 1.8745321655273437, time = 0.59\n",
      "300.0/69801.6, train_loss = 1.545062255859375, time = 0.63\n",
      "301.0/69801.6, train_loss = 1.398779296875, time = 0.59\n",
      "302.0/69801.6, train_loss = 1.744907989501953, time = 0.60\n",
      "303.0/69801.6, train_loss = 1.8079678344726562, time = 0.60\n",
      "304.0/69801.6, train_loss = 1.8050225830078126, time = 0.59\n",
      "305.0/69801.6, train_loss = 1.611455841064453, time = 0.60\n",
      "306.0/69801.6, train_loss = 1.4744398498535156, time = 0.69\n",
      "307.0/69801.6, train_loss = 1.5276319885253906, time = 0.60\n",
      "308.0/69801.6, train_loss = 1.8220219421386719, time = 0.62\n",
      "309.0/69801.6, train_loss = 1.8248388671875, time = 0.74\n",
      "310.0/69801.6, train_loss = 1.6502565002441407, time = 0.66\n",
      "311.0/69801.6, train_loss = 1.530330810546875, time = 0.65\n",
      "312.0/69801.6, train_loss = 1.3908509826660156, time = 0.70\n",
      "313.0/69801.6, train_loss = 1.786037139892578, time = 0.65\n",
      "314.0/69801.6, train_loss = 1.7684576416015625, time = 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohgushimasaya/.pyenv/versions/3.4.1/lib/python3.4/site-packages/ipykernel/__main__.py:4: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/ohgushimasaya/.pyenv/versions/3.4.1/lib/python3.4/site-packages/ipykernel/__main__.py:6: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95e0c2c8da26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0maccum_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0maccum_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munchain_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# truncate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0maccum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ohgushimasaya/.pyenv/versions/3.4.1/lib/python3.4/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0min_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mout_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ohgushimasaya/.pyenv/versions/3.4.1/lib/python3.4/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0min_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mout_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(int(jump * n_epochs)):\n",
    "    #-------------Explain4 in the Qiita-------------\n",
    "    x_batch = np.array([train_data[(jump * j + i) % whole_len]\n",
    "                        for j in range(batchsize)])\n",
    "    y_batch = np.array([train_data[(jump * j + i + 1) % whole_len]\n",
    "                        for j in range(batchsize)])\n",
    "\n",
    "    state, loss_i = model.forward_one_step(x_batch, y_batch, state, dropout_ratio=0.5)\n",
    "    accum_loss   += loss_i\n",
    "\n",
    "    if (i + 1) % bprop_len == 0:  # Run truncated BPTT\n",
    "        now = time.time()\n",
    "        print('{}/{}, train_loss = {}, time = {:.2f}'.format((i+1)/bprop_len, jump, accum_loss.data / bprop_len, now-cur_at))\n",
    "        cur_at = now\n",
    "\n",
    "        optimizer.zero_grads()\n",
    "        accum_loss.backward()\n",
    "        accum_loss.unchain_backward()  # truncate\n",
    "        accum_loss = Variable(np.zeros((), dtype=np.float32))\n",
    "\n",
    "        optimizer.clip_grads(grad_clip)\n",
    "        optimizer.update()\n",
    "\n",
    "    if (i + 1) % 10000 == 0:    \n",
    "        fn = ('%s/charrnn_epoch_%.2f.chainermodel' % (checkpoint_dir, float(i)/jump))\n",
    "        pickle.dump(copy.deepcopy(model).to_cpu(), open(fn, 'wb'))\n",
    "\n",
    "    if (i + 1) % jump == 0:\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch >= 10:\n",
    "            optimizer.lr *= 0.97\n",
    "            print('decayed learning rate by a factor {} to {}'.format(0.97, optimizer.lr))\n",
    "    #-------------Explain4 in the Qiita-------------\n",
    "\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 言語の予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習したデータを再度入力\n",
    "* 入力データを辞書として保持\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# load vocabulary\n",
    "vocab = {}\n",
    "#-------------Explain5 in the Qiita-------------\n",
    "def load_predict_data(filename):\n",
    "    global vocab, n_vocab\n",
    "    #words = open(filename).read().replace('\\n', '<eos>').strip().split()\n",
    "    words = open(filename).read().strip().split()\n",
    "    dataset = np.ndarray((len(words),), dtype=np.int32)\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "        dataset[i] = vocab[word]\n",
    "    return dataset\n",
    "\n",
    "train_data = load_predict_data('data_hands_on/linux_source.c')\n",
    "\n",
    "ivocab = {}\n",
    "ivocab = {v:k for k, v in vocab.items()}\n",
    "#-------------Explain5 in the Qiita-------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 学習したモデルを取得\n",
    "* モデルからユニット数を取得\n",
    "* 最初の空文字を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "#-------------Explain6 in the Qiita-------------\n",
    "model = pickle.load(open(\"cv/charrnn_epoch_0.14.chainermodel\", 'rb'))\n",
    "#-------------Explain6 in the Qiita-------------\n",
    "n_units = model.embed.W.shape[1]\n",
    "\n",
    "# initialize generator\n",
    "state = make_initial_state(n_units, batchsize=1, train=False)\n",
    "\n",
    "prev_char = np.array([0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習したモデルを利用して文字の予測を行なう。\n",
    "* 予測で出力された文字と状態を次の入力に使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    #-------------Explain7 in the Qiita-------------\n",
    "    state, prob = model.predict(prev_char, state)\n",
    "\n",
    "    index = np.argmax(cuda.to_cpu(prob.data))\n",
    "    sys.stdout.write(ivocab[index] + \" \")\n",
    "\n",
    "    prev_char = np.array([index], dtype=np.int32)\n",
    "    #-------------Explain7 in the Qiita-------------\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
