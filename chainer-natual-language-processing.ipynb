{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[Chainer](http://chainer.org/) とはニューラルネットの実装を簡単にしたフレームワークです。\n",
    "\n",
    "* 今回は言語の分野でニューラルネットを適用してみました。\n",
    "\n",
    "![](./pictures/Chainer.jpg)\n",
    "\n",
    "* 今回は言語モデルを作成していただきます。\n",
    "\n",
    "\n",
    "言語モデルとはある単語が来たときに次の単語に何が来やすいかを予測するものです。\n",
    "\n",
    "言語モデルにはいくつか種類があるのでここでも紹介しておきます。\n",
    "\n",
    "* n-グラム言語モデル\n",
    " * 単語の数を単純に数え挙げて作成されるモデル。考え方としてはデータにおけるある単語の頻度に近い\n",
    "* ニューラル言語モデル\n",
    " * 単語の辞書ベクトルを潜在空間ベクトルに落とし込み、ニューラルネットで次の文字を学習させる手法\n",
    "\n",
    "* リカレントニューラル言語モデル\n",
    " * 基本的なアルゴリズムは同一だが過去に使用した単語を入力に加えることによって文脈を考慮した言語モデルの学習が可能となる。ニューラル言語モデルとはことなり、より古い情報も取得可能\n",
    "\n",
    "以下では、このChainerを利用しデータを準備するところから実際に言語モデルを構築し学習・評価を行うまでの手順を解説します。\n",
    "\n",
    "1. [各種ライブラリ導入](#Loading-the-Library) \n",
    "2. [初期設定](#Initial-Setting) \n",
    "3. [データ入力](#Input-Data)\n",
    "4. [リカレントニューラル言語モデル設定](#Reccurent-neural-language-model) \n",
    "5. [学習関数](#Training-the-Function)\n",
    "6. [評価関数](#Evaluate-Function)\n",
    "7. [学習を始める前の設定](#Before-Setting)\n",
    "8. [パラメータ更新方法（確率的勾配法）](#SGD)\n",
    "9. [言語の予測](# Predict)\n",
    "\n",
    "もしGPUを使用したい方は、以下にまとめてあるのでご参考ください。\n",
    "\n",
    "[Chainer を用いてリカレントニューラル言語モデル作成のサンプルコードを解説してみた](http://qiita.com/GushiSnow/private/b34da4962dd930d1487a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerの言語処理では多数のライブラリを導入します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from chainer import cuda, Variable, FunctionSet, optimizers\n",
    "import chainer.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`導入するライブラリの代表例は下記です。\n",
    "\n",
    "* `numpy`: 行列計算などの複雑な計算を行なうライブラリ\n",
    "* `chainer`: Chainerの導入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習回数、ユニット数、確率的勾配法に使用するデータの数、学習に使用する文字列の長さ、勾配法で使用する敷居値、学習データの格納場所、モデルの出力場所を設定しています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_epochs    = 50\n",
    "n_epochs    = 10\n",
    "n_units     = 128\n",
    "batchsize   = 50\n",
    "#bprop_len   = 35\n",
    "bprop_len   = 50\n",
    "grad_clip   = 5\n",
    "data_dir = \"data_hands_on\"\n",
    "checkpoint_dir = \"cv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用にダウンロードしたファイルをプログラムに読ませる処理を関数化しています\n",
    "\n",
    "* 学習データをバイナリ形式で読み込んでいます。\n",
    "* 文字データを確保するための行列を定義しています。\n",
    "* データを単語をキー、長さを値とした辞書データにして行列データセットに登録しています。\n",
    "\n",
    "学習データ、単語の長さ、語彙数を取得しています。\n",
    "上記をそれぞれ行列データとして保持しています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_hands_on/linux_source.c\n",
      "corpus length: 581760\n",
      "vocab size: 81\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "def load_data():\n",
    "    vocab = {}\n",
    "    print ('%s/linux_source.c'% data_dir)\n",
    "    words = open('%s/linux_source.c' % data_dir, 'rb').read()\n",
    "    words = list(words)\n",
    "    dataset = np.ndarray((len(words),), dtype=np.int32)\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "        dataset[i] = vocab[word]\n",
    "    print('corpus length:', len(words))\n",
    "    print('vocab size:', len(vocab))\n",
    "    return dataset, words, vocab\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "    \n",
    "train_data, words, vocab = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reccurent neural language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNLM(リカレントニューラル言語モデルの設定を行っています）\n",
    "\n",
    "* EmbedIDで行列変換を行い、疎なベクトルを密なベクトルに変換しています。\n",
    "* 出力が4倍の理由は入力層、出力層、忘却層、前回の出力をLSTMでは入力に使用するためです。\n",
    "* 隠れ層に前回保持した隠れ層の状態を入力することによってLSTMを実現しています。\n",
    "* ドロップアウトにより過学習するのを抑えています。\n",
    "* 予測を行なうメソッドも実装しており、入力されたデータ、状態を元に次の文字列と状態を返すような関数になっています。\n",
    "* モデルの初期化を行なう関数もここで定義しています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CharRNN(FunctionSet):\n",
    "\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        super(CharRNN, self).__init__(\n",
    "            embed = F.EmbedID(n_vocab, n_units),\n",
    "            l1_x = F.Linear(n_units, 4*n_units),\n",
    "            l1_h = F.Linear(n_units, 4*n_units),\n",
    "            l2_h = F.Linear(n_units, 4*n_units),\n",
    "            l2_x = F.Linear(n_units, 4*n_units),\n",
    "            l3   = F.Linear(n_units, n_vocab),\n",
    "        )\n",
    "        for param in self.parameters:\n",
    "            param[:] = np.random.uniform(-0.08, 0.08, param.shape)\n",
    "\n",
    "    def forward_one_step(self, x_data, y_data, state, train=True, dropout_ratio=0.5):\n",
    "        x = Variable(x_data, volatile=not train)\n",
    "        t = Variable(y_data, volatile=not train)\n",
    "\n",
    "        h0      = self.embed(x)\n",
    "        h1_in   = self.l1_x(F.dropout(h0, ratio=dropout_ratio, train=train)) + self.l1_h(state['h1'])\n",
    "        c1, h1  = F.lstm(state['c1'], h1_in)\n",
    "        h2_in   = self.l2_x(F.dropout(h1, ratio=dropout_ratio, train=train)) + self.l2_h(state['h2'])\n",
    "        c2, h2  = F.lstm(state['c2'], h2_in)\n",
    "        y       = self.l3(F.dropout(h2, ratio=dropout_ratio, train=train))\n",
    "        state   = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "\n",
    "        return state, F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    def predict(self, x_data, state):\n",
    "        x = Variable(x_data, volatile=True)\n",
    "\n",
    "        h0      = self.embed(x)\n",
    "        h1_in   = self.l1_x(h0) + self.l1_h(state['h1'])\n",
    "        c1, h1  = F.lstm(state['c1'], h1_in)\n",
    "        h2_in   = self.l2_x(h1) + self.l2_h(state['h2'])\n",
    "        c2, h2  = F.lstm(state['c2'], h2_in)\n",
    "        y       = self.l3(h2)\n",
    "        state   = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "\n",
    "        return state, F.softmax(y)\n",
    "\n",
    "def make_initial_state(n_units, batchsize=50, train=True):\n",
    "    return {name: Variable(np.zeros((batchsize, n_units), dtype=np.float32),\n",
    "            volatile=not train)\n",
    "            for name in ('c1', 'h1', 'c2', 'h2')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNLM(リカレントニューラル言語モデルの設定を行っています）\n",
    "\n",
    "* 作成したリカレントニューラル言語モデルを導入しています。\n",
    "* 最適化の手法はRMSpropを使用\n",
    "http://qiita.com/skitaoka/items/e6afbe238cd69c899b2a\n",
    "* 初期のパラメータを-0.1〜0.1の間で与えています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-----------------------------------model----------------------------------*\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_sorted_funcs', 'collect_parameters', 'copy_parameters_from', 'embed', 'forward_one_step', 'gradients', 'l1_h', 'l1_x', 'l2_h', 'l2_x', 'l3', 'parameters', 'predict', 'to_cpu', 'to_gpu']\n",
      "*----------------------------------embed-----------------------------------*\n",
      "['W', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_check_data_type_backward', '_check_data_type_forward', 'backward', 'backward_cpu', 'backward_gpu', 'check_type_backward', 'check_type_forward', 'forward', 'forward_cpu', 'forward_gpu', 'gW', 'gradient_names', 'gradients', 'label', 'parameter_names', 'parameters', 'to_cpu', 'to_gpu', 'unchain']\n",
      "*--------------------------------model l1_x--------------------------------*\n",
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_wrap__', '__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imod__', '__imul__', '__index__', '__init__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n",
      "Linear\n",
      "('W', 'b')\n"
     ]
    }
   ],
   "source": [
    "# Prepare RNNLM model\n",
    "model = CharRNN(len(vocab), n_units)\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=2e-3, alpha=0.95, eps=1e-8)\n",
    "optimizer.setup(model.collect_parameters())\n",
    "\n",
    "print(\"*-----------------------------------model----------------------------------*\")\n",
    "print(dir(model))\n",
    "print(\"*----------------------------------embed-----------------------------------*\")\n",
    "print(dir(model.embed))\n",
    "print(\"*--------------------------------model l1_x--------------------------------*\")\n",
    "print(dir(model.l1_x.W))\n",
    "print(model.l1_x.label)\n",
    "print(model.l1_x.parameter_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習データのサイズを取得 \n",
    "* ジャンプの幅を設定（順次学習しない）\n",
    "* パープレキシティを0で初期化 \n",
    "* 最初の時間情報を取得 \n",
    "* 初期状態を現在の状態に付与 \n",
    "* 状態の初期化 \n",
    "* 損失を0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_len    = train_data.shape[0]\n",
    "jump         = whole_len / batchsize\n",
    "epoch        = 0\n",
    "start_at     = time.time()\n",
    "cur_at       = start_at\n",
    "state        = make_initial_state(n_units, batchsize=batchsize)\n",
    "accum_loss   = Variable(np.zeros((), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 確率的勾配法を用いて学習している。\n",
    "* 一定のデータを選択し損失計算をしながらパラメータ更新をしている。\n",
    "* 逐次尤度の計算も行っている。\n",
    "\n",
    "* 適宜学習データのパープレキシティも計算している\n",
    "\n",
    "* バックプロパゲーションでパラメータを更新する。\n",
    "* [truncate](http://kiyukuta.github.io/2013/12/09/mlac2013_day9_recurrent_neural_network_language_model.html#recurrent-neural-network)はどれだけ過去の履歴を見るかを表している。\n",
    "* optimizer.clip_gradsの部分でL2正則化をかけている。\n",
    "* 過学習を抑えるために学習効率を徐々に下げている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0/11635.2, train_loss = 4.402514038085937, time = 1.95\n",
      "2.0/11635.2, train_loss = 4.315704345703125, time = 0.66\n",
      "3.0/11635.2, train_loss = 3.7556936645507815, time = 0.67\n",
      "4.0/11635.2, train_loss = 3.7499844360351564, time = 0.64\n",
      "5.0/11635.2, train_loss = 3.6520556640625, time = 0.64\n",
      "6.0/11635.2, train_loss = 3.609979248046875, time = 0.67\n",
      "7.0/11635.2, train_loss = 3.641949462890625, time = 0.70\n",
      "8.0/11635.2, train_loss = 3.6477255249023437, time = 0.67\n",
      "9.0/11635.2, train_loss = 3.6389175415039063, time = 0.70\n",
      "10.0/11635.2, train_loss = 3.6171084594726564, time = 0.70\n",
      "11.0/11635.2, train_loss = 3.5879421997070313, time = 0.65\n",
      "12.0/11635.2, train_loss = 3.6038751220703125, time = 0.65\n",
      "13.0/11635.2, train_loss = 3.6160504150390627, time = 0.66\n",
      "14.0/11635.2, train_loss = 3.6289678955078126, time = 0.64\n",
      "15.0/11635.2, train_loss = 3.6194271850585937, time = 0.65\n",
      "16.0/11635.2, train_loss = 3.602923583984375, time = 0.88\n",
      "17.0/11635.2, train_loss = 3.57336669921875, time = 0.66\n",
      "18.0/11635.2, train_loss = 3.5560153198242186, time = 0.67\n",
      "19.0/11635.2, train_loss = 3.6062966918945314, time = 0.70\n",
      "20.0/11635.2, train_loss = 3.578035888671875, time = 0.63\n",
      "21.0/11635.2, train_loss = 3.572578125, time = 0.64\n",
      "22.0/11635.2, train_loss = 3.5343118286132813, time = 0.62\n",
      "23.0/11635.2, train_loss = 3.4926968383789063, time = 0.63\n",
      "24.0/11635.2, train_loss = 3.461175537109375, time = 0.62\n",
      "25.0/11635.2, train_loss = 3.5064053344726562, time = 0.64\n",
      "26.0/11635.2, train_loss = 3.5161663818359377, time = 0.63\n",
      "27.0/11635.2, train_loss = 3.455145263671875, time = 0.62\n",
      "28.0/11635.2, train_loss = 3.3627633666992187, time = 0.64\n",
      "29.0/11635.2, train_loss = 3.33708251953125, time = 0.61\n",
      "30.0/11635.2, train_loss = 3.31433837890625, time = 0.62\n",
      "31.0/11635.2, train_loss = 3.350509033203125, time = 0.65\n",
      "32.0/11635.2, train_loss = 3.2925650024414064, time = 0.61\n",
      "33.0/11635.2, train_loss = 3.27103759765625, time = 0.61\n",
      "34.0/11635.2, train_loss = 3.2123211669921874, time = 0.65\n",
      "35.0/11635.2, train_loss = 3.2116046142578125, time = 0.66\n",
      "36.0/11635.2, train_loss = 3.206423034667969, time = 0.75\n",
      "37.0/11635.2, train_loss = 3.203974304199219, time = 0.63\n",
      "38.0/11635.2, train_loss = 3.20290283203125, time = 0.62\n",
      "39.0/11635.2, train_loss = 3.1606103515625, time = 0.61\n",
      "40.0/11635.2, train_loss = 3.1393728637695313, time = 0.65\n",
      "41.0/11635.2, train_loss = 3.1083343505859373, time = 0.65\n",
      "42.0/11635.2, train_loss = 3.12970703125, time = 0.62\n",
      "43.0/11635.2, train_loss = 3.1150506591796874, time = 0.65\n",
      "44.0/11635.2, train_loss = 3.1370028686523437, time = 0.62\n",
      "45.0/11635.2, train_loss = 3.077686462402344, time = 0.62\n",
      "46.0/11635.2, train_loss = 3.052848205566406, time = 0.67\n",
      "47.0/11635.2, train_loss = 3.049638671875, time = 0.67\n",
      "48.0/11635.2, train_loss = 3.08010009765625, time = 0.62\n",
      "49.0/11635.2, train_loss = 3.070057067871094, time = 0.61\n",
      "50.0/11635.2, train_loss = 3.04859130859375, time = 0.65\n",
      "51.0/11635.2, train_loss = 3.0087286376953126, time = 0.64\n",
      "52.0/11635.2, train_loss = 3.0048712158203124, time = 0.64\n",
      "53.0/11635.2, train_loss = 2.9859024047851563, time = 0.61\n",
      "54.0/11635.2, train_loss = 2.996537170410156, time = 0.62\n",
      "55.0/11635.2, train_loss = 3.021020812988281, time = 0.61\n",
      "56.0/11635.2, train_loss = 2.978323974609375, time = 0.65\n",
      "57.0/11635.2, train_loss = 2.9405056762695314, time = 0.63\n",
      "58.0/11635.2, train_loss = 2.9402239990234373, time = 0.63\n",
      "59.0/11635.2, train_loss = 2.9491571044921874, time = 0.62\n",
      "60.0/11635.2, train_loss = 2.9584674072265624, time = 0.62\n",
      "61.0/11635.2, train_loss = 2.966025390625, time = 0.62\n",
      "62.0/11635.2, train_loss = 2.9048190307617188, time = 0.64\n",
      "63.0/11635.2, train_loss = 2.8909783935546876, time = 0.61\n",
      "64.0/11635.2, train_loss = 2.9036160278320313, time = 0.62\n",
      "65.0/11635.2, train_loss = 2.9015899658203126, time = 0.62\n",
      "66.0/11635.2, train_loss = 2.8839898681640626, time = 0.62\n",
      "67.0/11635.2, train_loss = 2.9015972900390623, time = 0.62\n",
      "68.0/11635.2, train_loss = 2.8378436279296877, time = 0.64\n",
      "69.0/11635.2, train_loss = 2.8594805908203127, time = 0.62\n",
      "70.0/11635.2, train_loss = 2.844307556152344, time = 0.61\n",
      "71.0/11635.2, train_loss = 2.8728817749023436, time = 0.62\n",
      "72.0/11635.2, train_loss = 2.8455987548828126, time = 0.62\n",
      "73.0/11635.2, train_loss = 2.8401339721679686, time = 0.63\n",
      "74.0/11635.2, train_loss = 2.798060302734375, time = 0.64\n",
      "75.0/11635.2, train_loss = 2.8100982666015626, time = 0.62\n",
      "76.0/11635.2, train_loss = 2.7942214965820313, time = 0.61\n",
      "77.0/11635.2, train_loss = 2.7826513671875, time = 0.61\n",
      "78.0/11635.2, train_loss = 2.8093756103515624, time = 0.62\n",
      "79.0/11635.2, train_loss = 2.7971002197265626, time = 0.62\n",
      "80.0/11635.2, train_loss = 2.7486907958984377, time = 0.66\n",
      "81.0/11635.2, train_loss = 2.7580511474609377, time = 0.62\n",
      "82.0/11635.2, train_loss = 2.7758966064453126, time = 0.61\n",
      "83.0/11635.2, train_loss = 2.7629666137695312, time = 0.61\n",
      "84.0/11635.2, train_loss = 2.766573791503906, time = 0.61\n",
      "85.0/11635.2, train_loss = 2.7293490600585937, time = 0.62\n",
      "86.0/11635.2, train_loss = 2.712596130371094, time = 0.64\n",
      "87.0/11635.2, train_loss = 2.7034326171875, time = 0.62\n",
      "88.0/11635.2, train_loss = 2.71906982421875, time = 0.62\n",
      "89.0/11635.2, train_loss = 2.7157940673828125, time = 0.61\n",
      "90.0/11635.2, train_loss = 2.6983502197265623, time = 0.62\n",
      "91.0/11635.2, train_loss = 2.681618347167969, time = 0.62\n",
      "92.0/11635.2, train_loss = 2.6858453369140625, time = 0.64\n",
      "93.0/11635.2, train_loss = 2.659812316894531, time = 0.62\n",
      "94.0/11635.2, train_loss = 2.6658154296875, time = 0.63\n",
      "95.0/11635.2, train_loss = 2.7126736450195312, time = 0.61\n",
      "96.0/11635.2, train_loss = 2.6376614379882812, time = 0.62\n",
      "97.0/11635.2, train_loss = 2.6155520629882814, time = 0.61\n",
      "98.0/11635.2, train_loss = 2.6484912109375, time = 0.64\n",
      "99.0/11635.2, train_loss = 2.6377682495117187, time = 0.63\n",
      "100.0/11635.2, train_loss = 2.617318420410156, time = 0.59\n",
      "101.0/11635.2, train_loss = 2.6405010986328126, time = 0.59\n",
      "102.0/11635.2, train_loss = 2.585467529296875, time = 0.59\n",
      "103.0/11635.2, train_loss = 2.575533142089844, time = 0.59\n",
      "104.0/11635.2, train_loss = 2.5971450805664062, time = 0.61\n",
      "105.0/11635.2, train_loss = 2.579207763671875, time = 0.60\n",
      "106.0/11635.2, train_loss = 2.5665234375, time = 0.59\n",
      "107.0/11635.2, train_loss = 2.603169250488281, time = 0.59\n",
      "108.0/11635.2, train_loss = 2.5504219055175783, time = 0.59\n",
      "109.0/11635.2, train_loss = 2.547232971191406, time = 0.59\n",
      "110.0/11635.2, train_loss = 2.5338475036621095, time = 0.62\n",
      "111.0/11635.2, train_loss = 2.524090118408203, time = 0.62\n",
      "112.0/11635.2, train_loss = 2.5354803466796874, time = 0.59\n",
      "113.0/11635.2, train_loss = 2.511013946533203, time = 0.61\n",
      "114.0/11635.2, train_loss = 2.5061569213867188, time = 0.60\n",
      "115.0/11635.2, train_loss = 2.516051483154297, time = 0.59\n",
      "116.0/11635.2, train_loss = 2.4902613830566405, time = 0.60\n",
      "117.0/11635.2, train_loss = 2.4801425170898437, time = 0.61\n",
      "118.0/11635.2, train_loss = 2.5338896179199217, time = 0.59\n",
      "119.0/11635.2, train_loss = 2.484871673583984, time = 0.60\n",
      "120.0/11635.2, train_loss = 2.4614430236816407, time = 0.60\n",
      "121.0/11635.2, train_loss = 2.4663328552246093, time = 0.61\n",
      "122.0/11635.2, train_loss = 2.4185275268554687, time = 0.60\n",
      "123.0/11635.2, train_loss = 2.4612081909179686, time = 0.62\n",
      "124.0/11635.2, train_loss = 2.4539385986328126, time = 0.60\n",
      "125.0/11635.2, train_loss = 2.432506256103516, time = 0.59\n",
      "126.0/11635.2, train_loss = 2.4226010131835936, time = 0.60\n",
      "127.0/11635.2, train_loss = 2.4045843505859374, time = 0.62\n",
      "128.0/11635.2, train_loss = 2.410055847167969, time = 0.61\n",
      "129.0/11635.2, train_loss = 2.408439483642578, time = 0.62\n",
      "130.0/11635.2, train_loss = 2.3965492248535156, time = 0.60\n",
      "131.0/11635.2, train_loss = 2.372679901123047, time = 0.59\n",
      "132.0/11635.2, train_loss = 2.3849658203125, time = 0.59\n",
      "133.0/11635.2, train_loss = 2.3645388793945314, time = 0.60\n",
      "134.0/11635.2, train_loss = 2.340069122314453, time = 0.58\n",
      "135.0/11635.2, train_loss = 2.3854306030273436, time = 0.63\n",
      "136.0/11635.2, train_loss = 2.349029846191406, time = 0.59\n",
      "137.0/11635.2, train_loss = 2.3309840393066406, time = 0.59\n",
      "138.0/11635.2, train_loss = 2.3686036682128906, time = 0.60\n",
      "139.0/11635.2, train_loss = 2.3198789978027343, time = 0.59\n",
      "140.0/11635.2, train_loss = 2.308061981201172, time = 0.59\n",
      "141.0/11635.2, train_loss = 2.3368267822265625, time = 0.62\n",
      "142.0/11635.2, train_loss = 2.3225794982910157, time = 0.59\n",
      "143.0/11635.2, train_loss = 2.272443389892578, time = 0.59\n",
      "144.0/11635.2, train_loss = 2.2781050109863283, time = 0.59\n",
      "145.0/11635.2, train_loss = 2.2860894775390626, time = 0.60\n",
      "146.0/11635.2, train_loss = 2.260937042236328, time = 0.60\n",
      "147.0/11635.2, train_loss = 2.29766357421875, time = 0.61\n",
      "148.0/11635.2, train_loss = 2.2472926330566407, time = 0.58\n",
      "149.0/11635.2, train_loss = 2.262310028076172, time = 0.60\n",
      "150.0/11635.2, train_loss = 2.247586517333984, time = 0.60\n",
      "151.0/11635.2, train_loss = 2.2419647216796874, time = 0.60\n",
      "152.0/11635.2, train_loss = 2.2522007751464845, time = 0.59\n",
      "153.0/11635.2, train_loss = 2.2264439392089845, time = 0.61\n",
      "154.0/11635.2, train_loss = 2.2072264099121095, time = 0.60\n",
      "155.0/11635.2, train_loss = 2.230723571777344, time = 0.60\n",
      "156.0/11635.2, train_loss = 2.192499542236328, time = 0.59\n",
      "157.0/11635.2, train_loss = 2.174050750732422, time = 0.60\n",
      "158.0/11635.2, train_loss = 2.2260992431640627, time = 0.59\n",
      "159.0/11635.2, train_loss = 2.2056878662109374, time = 0.62\n",
      "160.0/11635.2, train_loss = 2.1758929443359376, time = 0.59\n",
      "161.0/11635.2, train_loss = 2.169000549316406, time = 0.59\n",
      "162.0/11635.2, train_loss = 2.1514512634277345, time = 0.60\n",
      "163.0/11635.2, train_loss = 2.1481059265136717, time = 0.60\n",
      "164.0/11635.2, train_loss = 2.149321746826172, time = 0.60\n",
      "165.0/11635.2, train_loss = 2.145586395263672, time = 0.62\n",
      "166.0/11635.2, train_loss = 2.137227020263672, time = 0.61\n",
      "167.0/11635.2, train_loss = 2.122711944580078, time = 0.59\n",
      "168.0/11635.2, train_loss = 2.095153503417969, time = 0.59\n",
      "169.0/11635.2, train_loss = 2.1234983825683593, time = 0.59\n",
      "170.0/11635.2, train_loss = 2.1022471618652343, time = 0.59\n",
      "171.0/11635.2, train_loss = 2.115196075439453, time = 0.63\n",
      "172.0/11635.2, train_loss = 2.1148219299316406, time = 0.59\n",
      "173.0/11635.2, train_loss = 2.064796142578125, time = 0.59\n",
      "174.0/11635.2, train_loss = 2.071387939453125, time = 0.59\n",
      "175.0/11635.2, train_loss = 2.1113435363769533, time = 0.58\n",
      "176.0/11635.2, train_loss = 2.09401123046875, time = 0.60\n",
      "177.0/11635.2, train_loss = 2.0601109313964843, time = 0.64\n",
      "178.0/11635.2, train_loss = 2.066763458251953, time = 0.59\n",
      "179.0/11635.2, train_loss = 2.043232727050781, time = 0.59\n",
      "180.0/11635.2, train_loss = 2.028589630126953, time = 0.60\n",
      "181.0/11635.2, train_loss = 2.0706524658203125, time = 0.60\n",
      "182.0/11635.2, train_loss = 2.064805908203125, time = 0.59\n",
      "183.0/11635.2, train_loss = 2.0034913635253906, time = 0.59\n",
      "184.0/11635.2, train_loss = 1.9989085388183594, time = 0.62\n",
      "185.0/11635.2, train_loss = 1.9999172973632813, time = 0.59\n",
      "186.0/11635.2, train_loss = 2.019903106689453, time = 0.59\n",
      "187.0/11635.2, train_loss = 2.010111083984375, time = 0.59\n",
      "188.0/11635.2, train_loss = 2.032429504394531, time = 0.60\n",
      "189.0/11635.2, train_loss = 1.9802877807617187, time = 0.59\n",
      "190.0/11635.2, train_loss = 1.9694796752929689, time = 0.61\n",
      "191.0/11635.2, train_loss = 1.9395648193359376, time = 0.59\n",
      "192.0/11635.2, train_loss = 1.98484375, time = 0.60\n",
      "193.0/11635.2, train_loss = 1.9524237060546874, time = 0.59\n",
      "194.0/11635.2, train_loss = 1.9682794189453126, time = 0.60\n",
      "195.0/11635.2, train_loss = 1.9588006591796876, time = 0.59\n",
      "196.0/11635.2, train_loss = 1.9180674743652344, time = 0.61\n",
      "197.0/11635.2, train_loss = 1.927482147216797, time = 0.60\n",
      "198.0/11635.2, train_loss = 1.9350498962402343, time = 0.59\n",
      "199.0/11635.2, train_loss = 1.906549835205078, time = 0.60\n",
      "200.0/11635.2, train_loss = 1.9368399047851563, time = 0.63\n",
      "201.0/11635.2, train_loss = 1.8987075805664062, time = 0.99\n",
      "202.0/11635.2, train_loss = 1.8685621643066406, time = 0.61\n",
      "203.0/11635.2, train_loss = 1.8921185302734376, time = 0.59\n",
      "204.0/11635.2, train_loss = 1.8888320922851562, time = 0.61\n",
      "205.0/11635.2, train_loss = 1.902234344482422, time = 0.60\n",
      "206.0/11635.2, train_loss = 1.8463433837890626, time = 0.60\n",
      "207.0/11635.2, train_loss = 1.8339715576171876, time = 0.59\n",
      "208.0/11635.2, train_loss = 1.8510870361328124, time = 0.62\n",
      "209.0/11635.2, train_loss = 1.8783082580566406, time = 0.59\n",
      "210.0/11635.2, train_loss = 1.8801287841796874, time = 0.59\n",
      "211.0/11635.2, train_loss = 1.8829151916503906, time = 0.61\n",
      "212.0/11635.2, train_loss = 1.8334141540527344, time = 0.59\n",
      "213.0/11635.2, train_loss = 1.8124052429199218, time = 0.60\n",
      "214.0/11635.2, train_loss = 1.7952888488769532, time = 0.62\n",
      "215.0/11635.2, train_loss = 1.8322401428222657, time = 0.58\n",
      "216.0/11635.2, train_loss = 1.8425804138183595, time = 0.60\n",
      "217.0/11635.2, train_loss = 1.8019888305664062, time = 0.59\n",
      "218.0/11635.2, train_loss = 1.8044627380371094, time = 0.60\n",
      "219.0/11635.2, train_loss = 1.7448330688476563, time = 0.59\n",
      "220.0/11635.2, train_loss = 1.778852996826172, time = 0.61\n",
      "221.0/11635.2, train_loss = 1.7998870849609374, time = 0.60\n",
      "222.0/11635.2, train_loss = 1.8033729553222657, time = 0.61\n",
      "223.0/11635.2, train_loss = 1.7511962890625, time = 0.60\n",
      "224.0/11635.2, train_loss = 1.73448486328125, time = 0.59\n",
      "225.0/11635.2, train_loss = 1.7467073059082032, time = 0.59\n",
      "226.0/11635.2, train_loss = 1.7587339782714844, time = 0.62\n",
      "227.0/11635.2, train_loss = 1.750461883544922, time = 0.61\n",
      "228.0/11635.2, train_loss = 1.76255615234375, time = 0.60\n",
      "229.0/11635.2, train_loss = 1.7282847595214843, time = 0.62\n",
      "230.0/11635.2, train_loss = 1.690084228515625, time = 0.59\n",
      "231.0/11635.2, train_loss = 1.6973643493652344, time = 0.60\n",
      "232.0/11635.2, train_loss = 1.741663818359375, time = 0.62\n",
      "233.0/11635.2, train_loss = 1.6963807678222655, time = 0.59\n",
      "234.0/11635.2, train_loss = 1.7160111999511718, time = 0.58\n",
      "235.0/11635.2, train_loss = 1.7094192504882812, time = 0.60\n",
      "236.0/11635.2, train_loss = 1.6709738159179688, time = 0.59\n",
      "237.0/11635.2, train_loss = 1.670962371826172, time = 0.60\n",
      "238.0/11635.2, train_loss = 1.7095936584472655, time = 0.62\n",
      "239.0/11635.2, train_loss = 1.6693244934082032, time = 0.60\n",
      "240.0/11635.2, train_loss = 1.6819793701171875, time = 0.59\n",
      "241.0/11635.2, train_loss = 1.6245719909667968, time = 0.61\n",
      "242.0/11635.2, train_loss = 1.6246611022949218, time = 0.59\n",
      "243.0/11635.2, train_loss = 1.627864227294922, time = 0.60\n",
      "244.0/11635.2, train_loss = 1.6212680053710937, time = 0.61\n",
      "245.0/11635.2, train_loss = 1.6559719848632812, time = 0.59\n",
      "246.0/11635.2, train_loss = 1.6218524169921875, time = 0.59\n",
      "247.0/11635.2, train_loss = 1.6064430236816407, time = 0.59\n",
      "248.0/11635.2, train_loss = 1.570289306640625, time = 0.60\n",
      "249.0/11635.2, train_loss = 1.6012860107421876, time = 0.61\n",
      "250.0/11635.2, train_loss = 1.6304852294921874, time = 0.61\n",
      "251.0/11635.2, train_loss = 1.6113070678710937, time = 0.62\n",
      "252.0/11635.2, train_loss = 1.5901396179199219, time = 0.58\n",
      "253.0/11635.2, train_loss = 1.5558245849609376, time = 0.59\n",
      "254.0/11635.2, train_loss = 1.5260345458984375, time = 0.62\n",
      "255.0/11635.2, train_loss = 1.5863310241699218, time = 0.59\n",
      "256.0/11635.2, train_loss = 1.5975569152832032, time = 0.59\n",
      "257.0/11635.2, train_loss = 1.5682577514648437, time = 0.62\n",
      "258.0/11635.2, train_loss = 1.54153076171875, time = 0.59\n",
      "259.0/11635.2, train_loss = 1.5176123046875, time = 0.59\n",
      "260.0/11635.2, train_loss = 1.5329010009765625, time = 0.60\n",
      "261.0/11635.2, train_loss = 1.5641653442382812, time = 0.59\n",
      "262.0/11635.2, train_loss = 1.5489479064941407, time = 0.60\n",
      "263.0/11635.2, train_loss = 1.530635528564453, time = 0.62\n",
      "264.0/11635.2, train_loss = 1.5155625915527344, time = 0.60\n",
      "265.0/11635.2, train_loss = 1.4837974548339843, time = 0.60\n",
      "266.0/11635.2, train_loss = 1.5262466430664063, time = 0.59\n",
      "267.0/11635.2, train_loss = 1.5111933898925782, time = 0.59\n",
      "268.0/11635.2, train_loss = 1.5311117553710938, time = 0.59\n",
      "269.0/11635.2, train_loss = 1.5248147583007812, time = 0.62\n",
      "270.0/11635.2, train_loss = 1.44749755859375, time = 0.59\n",
      "271.0/11635.2, train_loss = 1.4700221252441406, time = 0.61\n",
      "272.0/11635.2, train_loss = 1.519090576171875, time = 0.60\n",
      "273.0/11635.2, train_loss = 1.458502960205078, time = 0.59\n",
      "274.0/11635.2, train_loss = 1.4916778564453126, time = 0.60\n",
      "275.0/11635.2, train_loss = 1.467740020751953, time = 0.62\n",
      "276.0/11635.2, train_loss = 1.4357131958007812, time = 0.60\n",
      "277.0/11635.2, train_loss = 1.4526707458496093, time = 0.59\n",
      "278.0/11635.2, train_loss = 1.478741455078125, time = 0.60\n",
      "279.0/11635.2, train_loss = 1.466317138671875, time = 0.61\n",
      "280.0/11635.2, train_loss = 1.483098602294922, time = 0.60\n",
      "281.0/11635.2, train_loss = 1.4366482543945311, time = 0.62\n",
      "282.0/11635.2, train_loss = 1.4242344665527344, time = 0.59\n",
      "283.0/11635.2, train_loss = 1.4346408081054687, time = 0.60\n",
      "284.0/11635.2, train_loss = 1.4281573486328125, time = 0.59\n",
      "285.0/11635.2, train_loss = 1.4475033569335938, time = 0.59\n",
      "286.0/11635.2, train_loss = 1.3914207458496093, time = 0.59\n",
      "287.0/11635.2, train_loss = 1.3838296508789063, time = 0.63\n",
      "288.0/11635.2, train_loss = 1.3706192016601562, time = 0.63\n",
      "289.0/11635.2, train_loss = 1.3814979553222657, time = 0.59\n",
      "290.0/11635.2, train_loss = 1.3829214477539062, time = 0.59\n",
      "291.0/11635.2, train_loss = 1.4110560607910156, time = 0.60\n",
      "292.0/11635.2, train_loss = 1.3908097839355469, time = 0.60\n",
      "293.0/11635.2, train_loss = 1.3100323486328125, time = 0.61\n",
      "294.0/11635.2, train_loss = 1.358126220703125, time = 0.59\n",
      "295.0/11635.2, train_loss = 1.4057675170898438, time = 0.60\n",
      "296.0/11635.2, train_loss = 1.4006826782226562, time = 0.60\n",
      "297.0/11635.2, train_loss = 1.350784912109375, time = 0.59\n",
      "298.0/11635.2, train_loss = 1.34283203125, time = 0.59\n",
      "299.0/11635.2, train_loss = 1.2824696350097655, time = 0.61\n",
      "300.0/11635.2, train_loss = 1.3114949035644532, time = 0.60\n",
      "301.0/11635.2, train_loss = 1.3449418640136719, time = 0.60\n",
      "302.0/11635.2, train_loss = 1.3755860900878907, time = 0.60\n",
      "303.0/11635.2, train_loss = 1.3281452941894532, time = 0.60\n",
      "304.0/11635.2, train_loss = 1.3060812377929687, time = 0.60\n",
      "305.0/11635.2, train_loss = 1.2720113372802735, time = 0.63\n",
      "306.0/11635.2, train_loss = 1.301714630126953, time = 0.59\n",
      "307.0/11635.2, train_loss = 1.3144206237792968, time = 0.58\n",
      "308.0/11635.2, train_loss = 1.3326112365722655, time = 0.60\n",
      "309.0/11635.2, train_loss = 1.2879086303710938, time = 0.60\n",
      "310.0/11635.2, train_loss = 1.2556509399414062, time = 0.59\n",
      "311.0/11635.2, train_loss = 1.2779008483886718, time = 0.65\n",
      "312.0/11635.2, train_loss = 1.2580624389648438, time = 0.61\n",
      "313.0/11635.2, train_loss = 1.2520075225830078, time = 0.59\n",
      "314.0/11635.2, train_loss = 1.3009335327148437, time = 0.59\n",
      "315.0/11635.2, train_loss = 1.2468274688720704, time = 0.60\n",
      "316.0/11635.2, train_loss = 1.2430857849121093, time = 0.60\n",
      "317.0/11635.2, train_loss = 1.2155881500244141, time = 0.60\n",
      "318.0/11635.2, train_loss = 1.278367691040039, time = 0.62\n",
      "319.0/11635.2, train_loss = 1.2518790435791016, time = 0.61\n",
      "320.0/11635.2, train_loss = 1.2351673889160155, time = 0.59\n",
      "321.0/11635.2, train_loss = 1.1784412384033203, time = 0.61\n",
      "322.0/11635.2, train_loss = 1.2001034545898437, time = 0.60\n",
      "323.0/11635.2, train_loss = 1.2262060546875, time = 0.64\n",
      "324.0/11635.2, train_loss = 1.229974365234375, time = 0.62\n",
      "325.0/11635.2, train_loss = 1.233769073486328, time = 0.60\n",
      "326.0/11635.2, train_loss = 1.1858342742919923, time = 0.60\n",
      "327.0/11635.2, train_loss = 1.19056884765625, time = 0.61\n",
      "328.0/11635.2, train_loss = 1.1876948547363282, time = 0.59\n",
      "329.0/11635.2, train_loss = 1.1849935913085938, time = 0.60\n",
      "330.0/11635.2, train_loss = 1.2005753326416015, time = 0.62\n",
      "331.0/11635.2, train_loss = 1.1574283599853517, time = 0.60\n",
      "332.0/11635.2, train_loss = 1.180258560180664, time = 0.60\n",
      "333.0/11635.2, train_loss = 1.1383619689941407, time = 0.59\n",
      "334.0/11635.2, train_loss = 1.1540117645263672, time = 0.60\n",
      "335.0/11635.2, train_loss = 1.1925757598876954, time = 0.59\n",
      "336.0/11635.2, train_loss = 1.2155257415771485, time = 0.61\n",
      "337.0/11635.2, train_loss = 1.1466543579101562, time = 0.61\n",
      "338.0/11635.2, train_loss = 1.1560174560546874, time = 0.60\n",
      "339.0/11635.2, train_loss = 1.1384703826904297, time = 0.60\n",
      "340.0/11635.2, train_loss = 1.134784927368164, time = 0.60\n",
      "341.0/11635.2, train_loss = 1.154782257080078, time = 0.60\n",
      "342.0/11635.2, train_loss = 1.1095726776123047, time = 0.62\n",
      "343.0/11635.2, train_loss = 1.138795394897461, time = 0.60\n",
      "344.0/11635.2, train_loss = 1.1253363037109374, time = 0.60\n",
      "345.0/11635.2, train_loss = 1.1034551239013672, time = 0.59\n",
      "346.0/11635.2, train_loss = 1.1089537811279297, time = 0.60\n",
      "347.0/11635.2, train_loss = 1.0966056060791016, time = 0.60\n",
      "348.0/11635.2, train_loss = 1.1097952270507812, time = 0.62\n",
      "349.0/11635.2, train_loss = 1.0904256439208984, time = 0.59\n",
      "350.0/11635.2, train_loss = 1.0641957855224609, time = 0.59\n",
      "351.0/11635.2, train_loss = 1.0645043182373046, time = 0.59\n",
      "352.0/11635.2, train_loss = 1.086008071899414, time = 0.59\n",
      "353.0/11635.2, train_loss = 1.0850834655761719, time = 0.59\n",
      "354.0/11635.2, train_loss = 1.1177523803710938, time = 0.63\n",
      "355.0/11635.2, train_loss = 1.080596694946289, time = 0.59\n",
      "356.0/11635.2, train_loss = 1.0347242736816407, time = 0.59\n",
      "357.0/11635.2, train_loss = 1.0194886016845703, time = 0.60\n",
      "358.0/11635.2, train_loss = 1.0823411560058593, time = 0.60\n",
      "359.0/11635.2, train_loss = 1.0947532653808594, time = 0.60\n",
      "360.0/11635.2, train_loss = 1.0756941223144532, time = 0.62\n",
      "361.0/11635.2, train_loss = 1.0207633972167969, time = 0.59\n",
      "362.0/11635.2, train_loss = 1.0167444610595704, time = 0.60\n",
      "363.0/11635.2, train_loss = 1.0411103057861328, time = 0.62\n",
      "364.0/11635.2, train_loss = 1.0356010437011718, time = 0.60\n",
      "365.0/11635.2, train_loss = 1.0731586456298827, time = 0.60\n",
      "366.0/11635.2, train_loss = 1.0237786102294921, time = 0.62\n",
      "367.0/11635.2, train_loss = 0.9961614227294922, time = 0.59\n",
      "368.0/11635.2, train_loss = 1.0093663024902344, time = 0.60\n",
      "369.0/11635.2, train_loss = 1.000418472290039, time = 0.60\n",
      "370.0/11635.2, train_loss = 1.0240438842773438, time = 0.60\n",
      "371.0/11635.2, train_loss = 0.9969384765625, time = 0.59\n",
      "372.0/11635.2, train_loss = 0.9845626831054688, time = 0.62\n",
      "373.0/11635.2, train_loss = 0.9610531616210938, time = 0.60\n",
      "374.0/11635.2, train_loss = 0.955778579711914, time = 0.64\n",
      "375.0/11635.2, train_loss = 0.9888034057617188, time = 0.65\n",
      "376.0/11635.2, train_loss = 0.9845471954345704, time = 0.62\n",
      "377.0/11635.2, train_loss = 1.0023898315429687, time = 0.60\n",
      "378.0/11635.2, train_loss = 0.9637915802001953, time = 0.61\n",
      "379.0/11635.2, train_loss = 0.9761818695068359, time = 0.60\n",
      "380.0/11635.2, train_loss = 0.9643114471435547, time = 0.60\n",
      "381.0/11635.2, train_loss = 0.9685594940185547, time = 0.60\n",
      "382.0/11635.2, train_loss = 0.9430902099609375, time = 0.60\n",
      "383.0/11635.2, train_loss = 0.9526361846923828, time = 0.59\n",
      "384.0/11635.2, train_loss = 0.9550043487548828, time = 0.60\n",
      "385.0/11635.2, train_loss = 0.9196736145019532, time = 0.61\n",
      "386.0/11635.2, train_loss = 0.9528466033935546, time = 0.60\n",
      "387.0/11635.2, train_loss = 0.9506595611572266, time = 0.60\n",
      "388.0/11635.2, train_loss = 0.9546302795410156, time = 0.61\n",
      "389.0/11635.2, train_loss = 0.9261982727050782, time = 0.59\n",
      "390.0/11635.2, train_loss = 0.9099306488037109, time = 0.60\n",
      "391.0/11635.2, train_loss = 0.9279841613769532, time = 0.61\n",
      "392.0/11635.2, train_loss = 0.9093838500976562, time = 0.60\n",
      "393.0/11635.2, train_loss = 0.9306172180175781, time = 0.60\n",
      "394.0/11635.2, train_loss = 0.915401611328125, time = 0.60\n",
      "395.0/11635.2, train_loss = 0.9157164764404296, time = 0.60\n",
      "396.0/11635.2, train_loss = 0.8754502868652344, time = 0.59\n",
      "397.0/11635.2, train_loss = 0.87759033203125, time = 0.62\n",
      "398.0/11635.2, train_loss = 0.9302728271484375, time = 0.60\n",
      "399.0/11635.2, train_loss = 0.9148936462402344, time = 0.60\n",
      "400.0/11635.2, train_loss = 0.8941954040527343, time = 0.59\n",
      "401.0/11635.2, train_loss = 0.8811720275878906, time = 0.60\n",
      "402.0/11635.2, train_loss = 0.8339989471435547, time = 0.59\n",
      "403.0/11635.2, train_loss = 0.848011474609375, time = 0.62\n",
      "404.0/11635.2, train_loss = 0.8857594299316406, time = 0.60\n",
      "405.0/11635.2, train_loss = 0.8785747528076172, time = 0.60\n",
      "406.0/11635.2, train_loss = 0.8529013824462891, time = 0.60\n",
      "407.0/11635.2, train_loss = 0.85251220703125, time = 0.60\n",
      "408.0/11635.2, train_loss = 0.8410560607910156, time = 0.59\n",
      "409.0/11635.2, train_loss = 0.8543232727050781, time = 0.63\n",
      "410.0/11635.2, train_loss = 0.8566133117675782, time = 0.60\n",
      "411.0/11635.2, train_loss = 0.8510179138183593, time = 0.62\n",
      "412.0/11635.2, train_loss = 0.8320010375976562, time = 0.60\n",
      "413.0/11635.2, train_loss = 0.82328857421875, time = 0.60\n",
      "414.0/11635.2, train_loss = 0.8253424072265625, time = 0.59\n",
      "415.0/11635.2, train_loss = 0.8422612762451172, time = 0.63\n",
      "416.0/11635.2, train_loss = 0.8637106323242187, time = 0.60\n",
      "417.0/11635.2, train_loss = 0.830360336303711, time = 0.60\n",
      "418.0/11635.2, train_loss = 0.817806396484375, time = 0.60\n",
      "419.0/11635.2, train_loss = 0.8130807495117187, time = 0.61\n",
      "420.0/11635.2, train_loss = 0.8009555053710937, time = 0.60\n",
      "421.0/11635.2, train_loss = 0.8301998138427734, time = 0.62\n",
      "422.0/11635.2, train_loss = 0.8327678680419922, time = 0.59\n",
      "423.0/11635.2, train_loss = 0.8088301086425781, time = 0.64\n",
      "424.0/11635.2, train_loss = 0.7945211029052734, time = 0.62\n",
      "425.0/11635.2, train_loss = 0.7985228729248047, time = 0.59\n",
      "426.0/11635.2, train_loss = 0.7606657409667968, time = 0.58\n",
      "427.0/11635.2, train_loss = 0.7943515777587891, time = 0.62\n",
      "428.0/11635.2, train_loss = 0.8054756927490234, time = 0.61\n",
      "429.0/11635.2, train_loss = 0.7972840881347656, time = 0.60\n",
      "430.0/11635.2, train_loss = 0.7517890167236329, time = 0.61\n",
      "431.0/11635.2, train_loss = 0.7612397766113281, time = 0.60\n",
      "432.0/11635.2, train_loss = 0.7626079559326172, time = 0.59\n",
      "433.0/11635.2, train_loss = 0.7730602264404297, time = 0.62\n",
      "434.0/11635.2, train_loss = 0.7745494079589844, time = 0.60\n",
      "435.0/11635.2, train_loss = 0.7605496978759766, time = 0.59\n",
      "436.0/11635.2, train_loss = 0.7460359191894531, time = 0.59\n",
      "437.0/11635.2, train_loss = 0.777569808959961, time = 0.59\n",
      "438.0/11635.2, train_loss = 0.7635619354248047, time = 0.60\n",
      "439.0/11635.2, train_loss = 0.7525586700439453, time = 0.62\n",
      "440.0/11635.2, train_loss = 0.7343297576904297, time = 0.60\n",
      "441.0/11635.2, train_loss = 0.744082260131836, time = 0.60\n",
      "442.0/11635.2, train_loss = 0.7215809631347656, time = 0.59\n",
      "443.0/11635.2, train_loss = 0.7221848297119141, time = 0.60\n",
      "444.0/11635.2, train_loss = 0.7456044769287109, time = 0.60\n",
      "445.0/11635.2, train_loss = 0.7337067413330078, time = 0.63\n",
      "446.0/11635.2, train_loss = 0.7510256958007813, time = 0.59\n",
      "447.0/11635.2, train_loss = 0.6924132537841797, time = 0.59\n",
      "448.0/11635.2, train_loss = 0.7117327117919922, time = 0.60\n",
      "449.0/11635.2, train_loss = 0.6974955749511719, time = 0.60\n",
      "450.0/11635.2, train_loss = 0.7179107666015625, time = 0.59\n",
      "451.0/11635.2, train_loss = 0.7144795989990235, time = 0.61\n",
      "452.0/11635.2, train_loss = 0.7166959381103516, time = 0.62\n",
      "453.0/11635.2, train_loss = 0.6802857971191406, time = 0.62\n",
      "454.0/11635.2, train_loss = 0.7147635650634766, time = 0.60\n",
      "455.0/11635.2, train_loss = 0.6856361389160156, time = 0.60\n",
      "456.0/11635.2, train_loss = 0.6881043243408204, time = 0.63\n",
      "457.0/11635.2, train_loss = 0.6987975311279296, time = 0.60\n",
      "458.0/11635.2, train_loss = 0.6777056884765625, time = 0.61\n",
      "459.0/11635.2, train_loss = 0.6475298309326172, time = 0.59\n",
      "460.0/11635.2, train_loss = 0.6823623657226563, time = 0.60\n",
      "461.0/11635.2, train_loss = 0.7000227355957032, time = 0.62\n",
      "462.0/11635.2, train_loss = 0.6846609497070313, time = 0.67\n",
      "463.0/11635.2, train_loss = 0.6690274047851562, time = 0.59\n",
      "464.0/11635.2, train_loss = 0.6496151733398438, time = 0.63\n",
      "465.0/11635.2, train_loss = 0.6482036590576172, time = 0.61\n",
      "466.0/11635.2, train_loss = 0.6541663360595703, time = 0.62\n",
      "467.0/11635.2, train_loss = 0.6728118896484375, time = 0.60\n",
      "468.0/11635.2, train_loss = 0.6591326141357422, time = 0.62\n",
      "469.0/11635.2, train_loss = 0.658774642944336, time = 0.60\n",
      "470.0/11635.2, train_loss = 0.6499156188964844, time = 0.62\n",
      "471.0/11635.2, train_loss = 0.6311921691894531, time = 0.59\n",
      "472.0/11635.2, train_loss = 0.6588700866699219, time = 0.67\n",
      "473.0/11635.2, train_loss = 0.6292348861694336, time = 0.60\n",
      "474.0/11635.2, train_loss = 0.6472118377685547, time = 0.63\n",
      "475.0/11635.2, train_loss = 0.6206723403930664, time = 0.63\n",
      "476.0/11635.2, train_loss = 0.6251002120971679, time = 0.62\n",
      "477.0/11635.2, train_loss = 0.6395194625854492, time = 0.61\n",
      "478.0/11635.2, train_loss = 0.6142785263061523, time = 0.59\n",
      "479.0/11635.2, train_loss = 0.6398501205444336, time = 0.60\n",
      "480.0/11635.2, train_loss = 0.6399721908569336, time = 0.59\n",
      "481.0/11635.2, train_loss = 0.6297163391113281, time = 0.60\n",
      "482.0/11635.2, train_loss = 0.5871456527709961, time = 0.63\n",
      "483.0/11635.2, train_loss = 0.5900332641601562, time = 0.60\n",
      "484.0/11635.2, train_loss = 0.608474235534668, time = 0.60\n",
      "485.0/11635.2, train_loss = 0.6188960647583008, time = 0.59\n",
      "486.0/11635.2, train_loss = 0.5942412948608399, time = 0.60\n",
      "487.0/11635.2, train_loss = 0.5757998657226563, time = 0.60\n",
      "488.0/11635.2, train_loss = 0.6012394332885742, time = 0.62\n",
      "489.0/11635.2, train_loss = 0.5731985473632812, time = 0.60\n",
      "490.0/11635.2, train_loss = 0.6042577743530273, time = 0.60\n",
      "491.0/11635.2, train_loss = 0.6063429641723633, time = 0.59\n",
      "492.0/11635.2, train_loss = 0.5860696029663086, time = 0.59\n",
      "493.0/11635.2, train_loss = 0.596372299194336, time = 0.59\n",
      "494.0/11635.2, train_loss = 0.6003379440307617, time = 0.64\n",
      "495.0/11635.2, train_loss = 0.5620021820068359, time = 0.59\n",
      "496.0/11635.2, train_loss = 0.5908531188964844, time = 0.60\n",
      "497.0/11635.2, train_loss = 0.564220199584961, time = 0.60\n",
      "498.0/11635.2, train_loss = 0.5844820785522461, time = 0.60\n",
      "499.0/11635.2, train_loss = 0.5446692276000976, time = 0.59\n",
      "500.0/11635.2, train_loss = 0.5722036361694336, time = 0.62\n",
      "501.0/11635.2, train_loss = 0.5400442504882812, time = 0.60\n",
      "502.0/11635.2, train_loss = 0.5488533401489257, time = 0.60\n",
      "503.0/11635.2, train_loss = 0.5477152633666992, time = 0.61\n",
      "504.0/11635.2, train_loss = 0.5492839050292969, time = 0.59\n",
      "505.0/11635.2, train_loss = 0.5620601654052735, time = 0.60\n",
      "506.0/11635.2, train_loss = 0.5502219772338868, time = 0.61\n",
      "507.0/11635.2, train_loss = 0.5527534484863281, time = 0.59\n",
      "508.0/11635.2, train_loss = 0.5596408843994141, time = 0.60\n",
      "509.0/11635.2, train_loss = 0.5390539932250976, time = 0.61\n",
      "510.0/11635.2, train_loss = 0.5276535034179688, time = 0.60\n",
      "511.0/11635.2, train_loss = 0.5306306457519532, time = 0.73\n",
      "512.0/11635.2, train_loss = 0.5207002258300781, time = 0.81\n",
      "513.0/11635.2, train_loss = 0.5261781311035156, time = 0.66\n",
      "514.0/11635.2, train_loss = 0.5285586929321289, time = 0.73\n",
      "515.0/11635.2, train_loss = 0.5384099578857422, time = 0.85\n",
      "516.0/11635.2, train_loss = 0.5018106460571289, time = 0.78\n",
      "517.0/11635.2, train_loss = 0.5404623031616211, time = 0.78\n",
      "518.0/11635.2, train_loss = 0.5464776992797852, time = 0.78\n",
      "519.0/11635.2, train_loss = 0.5468524932861328, time = 0.71\n",
      "520.0/11635.2, train_loss = 0.5144292449951172, time = 0.87\n",
      "521.0/11635.2, train_loss = 0.5078876113891602, time = 0.65\n",
      "522.0/11635.2, train_loss = 0.5286918640136719, time = 0.62\n",
      "523.0/11635.2, train_loss = 0.49116470336914064, time = 0.62\n",
      "524.0/11635.2, train_loss = 0.4779056930541992, time = 0.61\n",
      "525.0/11635.2, train_loss = 0.5109991073608399, time = 0.63\n",
      "526.0/11635.2, train_loss = 0.5169863510131836, time = 0.62\n",
      "527.0/11635.2, train_loss = 0.4935201644897461, time = 0.62\n",
      "528.0/11635.2, train_loss = 0.48209342956542967, time = 0.61\n",
      "529.0/11635.2, train_loss = 0.4892905807495117, time = 0.61\n",
      "530.0/11635.2, train_loss = 0.5003947067260742, time = 0.62\n",
      "531.0/11635.2, train_loss = 0.5147270584106445, time = 0.63\n",
      "532.0/11635.2, train_loss = 0.47603569030761717, time = 0.61\n",
      "533.0/11635.2, train_loss = 0.46747138977050784, time = 0.62\n",
      "534.0/11635.2, train_loss = 0.4931851577758789, time = 0.61\n",
      "535.0/11635.2, train_loss = 0.5047442626953125, time = 0.61\n",
      "536.0/11635.2, train_loss = 0.49146839141845705, time = 0.61\n",
      "537.0/11635.2, train_loss = 0.5060795974731446, time = 0.63\n",
      "538.0/11635.2, train_loss = 0.4593388748168945, time = 0.61\n",
      "539.0/11635.2, train_loss = 0.47023681640625, time = 0.60\n",
      "540.0/11635.2, train_loss = 0.49459186553955076, time = 0.61\n",
      "541.0/11635.2, train_loss = 0.47008934020996096, time = 0.61\n",
      "542.0/11635.2, train_loss = 0.45977100372314456, time = 0.61\n",
      "543.0/11635.2, train_loss = 0.4909149169921875, time = 0.64\n",
      "544.0/11635.2, train_loss = 0.45030113220214846, time = 0.61\n",
      "545.0/11635.2, train_loss = 0.4397924041748047, time = 0.61\n",
      "546.0/11635.2, train_loss = 0.45033931732177734, time = 0.61\n",
      "547.0/11635.2, train_loss = 0.48328670501708987, time = 0.61\n",
      "548.0/11635.2, train_loss = 0.475185661315918, time = 0.61\n",
      "549.0/11635.2, train_loss = 0.462100830078125, time = 0.64\n",
      "550.0/11635.2, train_loss = 0.4347576904296875, time = 0.62\n",
      "551.0/11635.2, train_loss = 0.465162353515625, time = 0.62\n",
      "552.0/11635.2, train_loss = 0.4152513885498047, time = 0.61\n",
      "553.0/11635.2, train_loss = 0.43358211517333983, time = 0.61\n",
      "554.0/11635.2, train_loss = 0.45122470855712893, time = 0.61\n",
      "555.0/11635.2, train_loss = 0.4371175765991211, time = 0.64\n",
      "556.0/11635.2, train_loss = 0.4439459228515625, time = 0.61\n",
      "557.0/11635.2, train_loss = 0.43260894775390624, time = 0.62\n",
      "558.0/11635.2, train_loss = 0.4331143569946289, time = 0.64\n",
      "559.0/11635.2, train_loss = 0.42281131744384765, time = 0.68\n",
      "560.0/11635.2, train_loss = 0.4346822738647461, time = 0.77\n",
      "561.0/11635.2, train_loss = 0.4340097045898437, time = 0.64\n",
      "562.0/11635.2, train_loss = 0.4163695907592773, time = 0.63\n",
      "563.0/11635.2, train_loss = 0.4411166000366211, time = 0.62\n",
      "564.0/11635.2, train_loss = 0.44124866485595704, time = 0.66\n",
      "565.0/11635.2, train_loss = 0.40019012451171876, time = 0.65\n",
      "566.0/11635.2, train_loss = 0.42273616790771484, time = 0.61\n",
      "567.0/11635.2, train_loss = 0.41348461151123045, time = 0.64\n",
      "568.0/11635.2, train_loss = 0.40236625671386717, time = 0.62\n",
      "569.0/11635.2, train_loss = 0.41089218139648437, time = 0.63\n",
      "570.0/11635.2, train_loss = 0.41820945739746096, time = 0.69\n",
      "571.0/11635.2, train_loss = 0.40575653076171875, time = 0.67\n",
      "572.0/11635.2, train_loss = 0.4029326629638672, time = 0.62\n",
      "573.0/11635.2, train_loss = 0.40724609375, time = 0.64\n",
      "574.0/11635.2, train_loss = 0.4064883041381836, time = 0.64\n",
      "575.0/11635.2, train_loss = 0.4172688674926758, time = 0.64\n",
      "576.0/11635.2, train_loss = 0.3970461654663086, time = 0.61\n",
      "577.0/11635.2, train_loss = 0.4119118118286133, time = 0.60\n",
      "578.0/11635.2, train_loss = 0.4118580627441406, time = 0.60\n",
      "579.0/11635.2, train_loss = 0.3804076385498047, time = 0.63\n",
      "580.0/11635.2, train_loss = 0.4094001007080078, time = 0.60\n",
      "581.0/11635.2, train_loss = 0.39985668182373046, time = 0.59\n",
      "582.0/11635.2, train_loss = 0.4139601898193359, time = 0.59\n",
      "583.0/11635.2, train_loss = 0.3881387710571289, time = 0.60\n",
      "584.0/11635.2, train_loss = 0.40669879913330076, time = 0.59\n",
      "585.0/11635.2, train_loss = 0.40052505493164064, time = 0.59\n",
      "586.0/11635.2, train_loss = 0.3865694046020508, time = 0.61\n",
      "587.0/11635.2, train_loss = 0.3759856414794922, time = 0.59\n",
      "588.0/11635.2, train_loss = 0.3975355911254883, time = 0.59\n",
      "589.0/11635.2, train_loss = 0.37116065979003904, time = 0.64\n",
      "590.0/11635.2, train_loss = 0.37999813079833983, time = 0.59\n",
      "591.0/11635.2, train_loss = 0.37152088165283204, time = 0.60\n",
      "592.0/11635.2, train_loss = 0.36960075378417967, time = 0.61\n",
      "593.0/11635.2, train_loss = 0.3584728240966797, time = 0.59\n",
      "594.0/11635.2, train_loss = 0.37077396392822265, time = 0.59\n",
      "595.0/11635.2, train_loss = 0.38009841918945314, time = 0.62\n",
      "596.0/11635.2, train_loss = 0.36178165435791015, time = 0.59\n",
      "597.0/11635.2, train_loss = 0.3565830230712891, time = 0.61\n",
      "598.0/11635.2, train_loss = 0.3699092483520508, time = 0.61\n",
      "599.0/11635.2, train_loss = 0.3755012512207031, time = 0.60\n",
      "600.0/11635.2, train_loss = 0.37815673828125, time = 0.59\n",
      "601.0/11635.2, train_loss = 0.3734618377685547, time = 0.60\n",
      "602.0/11635.2, train_loss = 0.33642208099365234, time = 0.60\n",
      "603.0/11635.2, train_loss = 0.3398085021972656, time = 0.61\n",
      "604.0/11635.2, train_loss = 0.36998825073242186, time = 0.62\n",
      "605.0/11635.2, train_loss = 0.3877370834350586, time = 0.61\n",
      "606.0/11635.2, train_loss = 0.3424848556518555, time = 0.60\n",
      "607.0/11635.2, train_loss = 0.34924537658691407, time = 0.59\n",
      "608.0/11635.2, train_loss = 0.3401012420654297, time = 0.60\n",
      "609.0/11635.2, train_loss = 0.3445077896118164, time = 0.59\n",
      "610.0/11635.2, train_loss = 0.34564212799072264, time = 0.63\n",
      "611.0/11635.2, train_loss = 0.368752555847168, time = 0.59\n",
      "612.0/11635.2, train_loss = 0.3703035354614258, time = 0.61\n",
      "613.0/11635.2, train_loss = 0.33953983306884766, time = 0.60\n",
      "614.0/11635.2, train_loss = 0.3471566772460937, time = 0.60\n",
      "615.0/11635.2, train_loss = 0.327257080078125, time = 0.59\n",
      "616.0/11635.2, train_loss = 0.33504653930664063, time = 0.61\n",
      "617.0/11635.2, train_loss = 0.31971149444580077, time = 0.59\n",
      "618.0/11635.2, train_loss = 0.3398264312744141, time = 0.60\n",
      "619.0/11635.2, train_loss = 0.3069187355041504, time = 0.59\n",
      "620.0/11635.2, train_loss = 0.326781005859375, time = 0.59\n",
      "621.0/11635.2, train_loss = 0.32485599517822267, time = 0.60\n",
      "622.0/11635.2, train_loss = 0.32881359100341795, time = 0.64\n",
      "623.0/11635.2, train_loss = 0.32999046325683595, time = 0.58\n",
      "624.0/11635.2, train_loss = 0.33882850646972656, time = 0.60\n",
      "625.0/11635.2, train_loss = 0.32465400695800783, time = 0.64\n",
      "626.0/11635.2, train_loss = 0.3259926986694336, time = 0.61\n",
      "627.0/11635.2, train_loss = 0.32469070434570313, time = 0.60\n",
      "628.0/11635.2, train_loss = 0.3078005027770996, time = 0.63\n",
      "629.0/11635.2, train_loss = 0.3126227951049805, time = 0.58\n",
      "630.0/11635.2, train_loss = 0.32703590393066406, time = 0.61\n",
      "631.0/11635.2, train_loss = 0.2965972328186035, time = 0.61\n",
      "632.0/11635.2, train_loss = 0.30639631271362305, time = 0.60\n",
      "633.0/11635.2, train_loss = 0.3346800994873047, time = 0.59\n",
      "634.0/11635.2, train_loss = 0.3361759567260742, time = 0.62\n",
      "635.0/11635.2, train_loss = 0.3329434585571289, time = 0.60\n",
      "636.0/11635.2, train_loss = 0.3110429573059082, time = 0.61\n",
      "637.0/11635.2, train_loss = 0.3067816734313965, time = 0.60\n",
      "638.0/11635.2, train_loss = 0.28490283966064456, time = 0.60\n",
      "639.0/11635.2, train_loss = 0.31461076736450194, time = 0.59\n",
      "640.0/11635.2, train_loss = 0.312459659576416, time = 0.63\n",
      "641.0/11635.2, train_loss = 0.3111379623413086, time = 0.59\n",
      "642.0/11635.2, train_loss = 0.3004654502868652, time = 0.59\n",
      "643.0/11635.2, train_loss = 0.28158470153808596, time = 0.58\n",
      "644.0/11635.2, train_loss = 0.2954850959777832, time = 0.61\n",
      "645.0/11635.2, train_loss = 0.3104821968078613, time = 0.60\n",
      "646.0/11635.2, train_loss = 0.311458683013916, time = 0.63\n",
      "647.0/11635.2, train_loss = 0.286702880859375, time = 0.61\n",
      "648.0/11635.2, train_loss = 0.28158088684082033, time = 0.60\n",
      "649.0/11635.2, train_loss = 0.2917754936218262, time = 0.61\n",
      "650.0/11635.2, train_loss = 0.31290435791015625, time = 0.59\n",
      "651.0/11635.2, train_loss = 0.29885522842407225, time = 0.60\n",
      "652.0/11635.2, train_loss = 0.2941951370239258, time = 0.60\n",
      "653.0/11635.2, train_loss = 0.30185638427734374, time = 0.62\n",
      "654.0/11635.2, train_loss = 0.281029109954834, time = 0.59\n",
      "655.0/11635.2, train_loss = 0.272004451751709, time = 0.60\n",
      "656.0/11635.2, train_loss = 0.2740260314941406, time = 0.60\n",
      "657.0/11635.2, train_loss = 0.2971228790283203, time = 0.60\n",
      "658.0/11635.2, train_loss = 0.29297351837158203, time = 0.59\n",
      "659.0/11635.2, train_loss = 0.2879741096496582, time = 0.62\n",
      "660.0/11635.2, train_loss = 0.29465612411499026, time = 0.60\n",
      "661.0/11635.2, train_loss = 0.28648035049438475, time = 0.60\n",
      "662.0/11635.2, train_loss = 0.27551990509033203, time = 0.60\n",
      "663.0/11635.2, train_loss = 0.28767465591430663, time = 0.61\n",
      "664.0/11635.2, train_loss = 0.29653665542602536, time = 0.61\n",
      "665.0/11635.2, train_loss = 0.26702695846557617, time = 0.62\n",
      "666.0/11635.2, train_loss = 0.26660274505615233, time = 0.59\n",
      "667.0/11635.2, train_loss = 0.27118453979492185, time = 0.61\n",
      "668.0/11635.2, train_loss = 0.28873109817504883, time = 0.59\n",
      "669.0/11635.2, train_loss = 0.28306797027587893, time = 0.60\n",
      "670.0/11635.2, train_loss = 0.27402664184570313, time = 0.60\n",
      "671.0/11635.2, train_loss = 0.25155935287475584, time = 0.62\n",
      "672.0/11635.2, train_loss = 0.2662555885314941, time = 0.61\n",
      "673.0/11635.2, train_loss = 0.26346723556518553, time = 0.60\n",
      "674.0/11635.2, train_loss = 0.28203582763671875, time = 0.60\n",
      "675.0/11635.2, train_loss = 0.2954624366760254, time = 0.61\n",
      "676.0/11635.2, train_loss = 0.25376529693603517, time = 0.59\n",
      "677.0/11635.2, train_loss = 0.26468887329101565, time = 0.61\n",
      "678.0/11635.2, train_loss = 0.26432899475097654, time = 0.59\n",
      "679.0/11635.2, train_loss = 0.2835009765625, time = 0.60\n",
      "680.0/11635.2, train_loss = 0.25950782775878906, time = 0.60\n",
      "681.0/11635.2, train_loss = 0.28410316467285157, time = 0.60\n",
      "682.0/11635.2, train_loss = 0.2585170745849609, time = 0.61\n",
      "683.0/11635.2, train_loss = 0.25771255493164064, time = 0.62\n",
      "684.0/11635.2, train_loss = 0.2657973098754883, time = 0.60\n",
      "685.0/11635.2, train_loss = 0.2577171325683594, time = 0.61\n",
      "686.0/11635.2, train_loss = 0.25891220092773437, time = 0.60\n",
      "687.0/11635.2, train_loss = 0.24403999328613282, time = 0.60\n",
      "688.0/11635.2, train_loss = 0.23650999069213868, time = 0.60\n",
      "689.0/11635.2, train_loss = 0.25920331954956055, time = 0.61\n",
      "690.0/11635.2, train_loss = 0.25863208770751955, time = 0.60\n",
      "691.0/11635.2, train_loss = 0.2511711883544922, time = 0.61\n",
      "692.0/11635.2, train_loss = 0.25317962646484377, time = 0.60\n",
      "693.0/11635.2, train_loss = 0.24361028671264648, time = 0.60\n",
      "694.0/11635.2, train_loss = 0.2612508964538574, time = 0.60\n",
      "695.0/11635.2, train_loss = 0.2592381286621094, time = 0.62\n",
      "696.0/11635.2, train_loss = 0.2612639617919922, time = 0.61\n",
      "697.0/11635.2, train_loss = 0.23980239868164063, time = 0.60\n",
      "698.0/11635.2, train_loss = 0.24695940017700196, time = 0.59\n",
      "699.0/11635.2, train_loss = 0.23651243209838868, time = 0.59\n",
      "700.0/11635.2, train_loss = 0.24100131988525392, time = 0.59\n",
      "701.0/11635.2, train_loss = 0.255158863067627, time = 0.62\n",
      "702.0/11635.2, train_loss = 0.22905466079711914, time = 0.60\n",
      "703.0/11635.2, train_loss = 0.2522780990600586, time = 0.60\n",
      "704.0/11635.2, train_loss = 0.24464797973632812, time = 0.59\n",
      "705.0/11635.2, train_loss = 0.2355879783630371, time = 0.61\n",
      "706.0/11635.2, train_loss = 0.24605594635009764, time = 0.60\n",
      "707.0/11635.2, train_loss = 0.23398031234741212, time = 0.62\n",
      "708.0/11635.2, train_loss = 0.25502910614013674, time = 0.61\n",
      "709.0/11635.2, train_loss = 0.22284069061279296, time = 0.59\n",
      "710.0/11635.2, train_loss = 0.21972002029418947, time = 0.61\n",
      "711.0/11635.2, train_loss = 0.22631797790527344, time = 0.60\n",
      "712.0/11635.2, train_loss = 0.23397348403930665, time = 0.59\n",
      "713.0/11635.2, train_loss = 0.21815134048461915, time = 0.62\n",
      "714.0/11635.2, train_loss = 0.2350881004333496, time = 0.59\n",
      "715.0/11635.2, train_loss = 0.2348905944824219, time = 0.60\n",
      "716.0/11635.2, train_loss = 0.22583919525146484, time = 0.59\n",
      "717.0/11635.2, train_loss = 0.23406925201416015, time = 0.61\n",
      "718.0/11635.2, train_loss = 0.23219142913818358, time = 0.59\n",
      "719.0/11635.2, train_loss = 0.22140060424804686, time = 0.59\n",
      "720.0/11635.2, train_loss = 0.252310791015625, time = 0.61\n",
      "721.0/11635.2, train_loss = 0.23550235748291015, time = 0.62\n",
      "722.0/11635.2, train_loss = 0.21905529022216796, time = 0.63\n",
      "723.0/11635.2, train_loss = 0.22058481216430664, time = 0.61\n",
      "724.0/11635.2, train_loss = 0.21341405868530272, time = 0.60\n",
      "725.0/11635.2, train_loss = 0.22521629333496093, time = 0.61\n",
      "726.0/11635.2, train_loss = 0.24174955368041992, time = 0.61\n",
      "727.0/11635.2, train_loss = 0.2193845748901367, time = 0.58\n",
      "728.0/11635.2, train_loss = 0.19006948471069335, time = 0.60\n",
      "729.0/11635.2, train_loss = 0.2030290985107422, time = 0.60\n",
      "730.0/11635.2, train_loss = 0.21800525665283202, time = 0.61\n",
      "731.0/11635.2, train_loss = 0.22816188812255858, time = 0.59\n",
      "732.0/11635.2, train_loss = 0.21916250228881837, time = 0.62\n",
      "733.0/11635.2, train_loss = 0.20751777648925782, time = 0.59\n",
      "734.0/11635.2, train_loss = 0.21971624374389648, time = 0.60\n",
      "735.0/11635.2, train_loss = 0.2156245231628418, time = 0.60\n",
      "736.0/11635.2, train_loss = 0.219083251953125, time = 0.59\n",
      "737.0/11635.2, train_loss = 0.21394552230834962, time = 0.59\n",
      "738.0/11635.2, train_loss = 0.21843021392822265, time = 0.63\n",
      "739.0/11635.2, train_loss = 0.19511569976806642, time = 0.60\n",
      "740.0/11635.2, train_loss = 0.22122495651245117, time = 0.60\n",
      "741.0/11635.2, train_loss = 0.2013966178894043, time = 0.60\n",
      "742.0/11635.2, train_loss = 0.2152009391784668, time = 0.60\n",
      "743.0/11635.2, train_loss = 0.21099830627441407, time = 0.60\n",
      "744.0/11635.2, train_loss = 0.20907720565795898, time = 0.63\n",
      "745.0/11635.2, train_loss = 0.19806770324707032, time = 0.60\n",
      "746.0/11635.2, train_loss = 0.22840383529663086, time = 0.62\n",
      "747.0/11635.2, train_loss = 0.2097016143798828, time = 0.60\n",
      "748.0/11635.2, train_loss = 0.20719610214233397, time = 0.60\n",
      "749.0/11635.2, train_loss = 0.20953840255737305, time = 0.60\n",
      "750.0/11635.2, train_loss = 0.20426830291748047, time = 0.63\n",
      "751.0/11635.2, train_loss = 0.1995880889892578, time = 0.60\n",
      "752.0/11635.2, train_loss = 0.1932700729370117, time = 0.60\n",
      "753.0/11635.2, train_loss = 0.2057769775390625, time = 0.60\n",
      "754.0/11635.2, train_loss = 0.20036903381347657, time = 0.61\n",
      "755.0/11635.2, train_loss = 0.21495393753051759, time = 0.60\n",
      "756.0/11635.2, train_loss = 0.1814359474182129, time = 0.62\n",
      "757.0/11635.2, train_loss = 0.19690479278564454, time = 0.60\n",
      "758.0/11635.2, train_loss = 0.19179302215576172, time = 0.60\n",
      "759.0/11635.2, train_loss = 0.2152974510192871, time = 0.59\n",
      "760.0/11635.2, train_loss = 0.18811227798461913, time = 0.60\n",
      "761.0/11635.2, train_loss = 0.202744197845459, time = 0.60\n",
      "762.0/11635.2, train_loss = 0.19445016860961914, time = 0.62\n",
      "763.0/11635.2, train_loss = 0.18754467010498047, time = 0.60\n",
      "764.0/11635.2, train_loss = 0.18523242950439453, time = 0.60\n",
      "765.0/11635.2, train_loss = 0.19587354660034179, time = 0.60\n",
      "766.0/11635.2, train_loss = 0.1768364715576172, time = 0.60\n",
      "767.0/11635.2, train_loss = 0.19127470016479492, time = 0.59\n",
      "768.0/11635.2, train_loss = 0.16655691146850585, time = 0.63\n",
      "769.0/11635.2, train_loss = 0.1744173812866211, time = 0.60\n",
      "770.0/11635.2, train_loss = 0.18659255981445313, time = 0.60\n",
      "771.0/11635.2, train_loss = 0.1807941246032715, time = 0.59\n",
      "772.0/11635.2, train_loss = 0.18406301498413086, time = 0.60\n",
      "773.0/11635.2, train_loss = 0.17534292221069336, time = 0.60\n",
      "774.0/11635.2, train_loss = 0.17354726791381836, time = 0.61\n",
      "775.0/11635.2, train_loss = 0.18314214706420898, time = 0.60\n",
      "776.0/11635.2, train_loss = 0.17582197189331056, time = 0.60\n",
      "777.0/11635.2, train_loss = 0.18933137893676757, time = 0.59\n",
      "778.0/11635.2, train_loss = 0.19703102111816406, time = 0.60\n",
      "779.0/11635.2, train_loss = 0.1767597961425781, time = 0.61\n",
      "780.0/11635.2, train_loss = 0.17249191284179688, time = 0.61\n",
      "781.0/11635.2, train_loss = 0.20246147155761718, time = 0.60\n",
      "782.0/11635.2, train_loss = 0.1813035202026367, time = 0.59\n",
      "783.0/11635.2, train_loss = 0.18026313781738282, time = 0.61\n",
      "784.0/11635.2, train_loss = 0.16032243728637696, time = 0.59\n",
      "785.0/11635.2, train_loss = 0.1773666763305664, time = 0.60\n",
      "786.0/11635.2, train_loss = 0.17197734832763673, time = 0.59\n",
      "787.0/11635.2, train_loss = 0.1830756378173828, time = 0.62\n",
      "788.0/11635.2, train_loss = 0.17781139373779298, time = 0.60\n",
      "789.0/11635.2, train_loss = 0.1742844581604004, time = 0.59\n",
      "790.0/11635.2, train_loss = 0.18434120178222657, time = 0.59\n",
      "791.0/11635.2, train_loss = 0.1934894371032715, time = 0.60\n",
      "792.0/11635.2, train_loss = 0.16306951522827148, time = 0.60\n",
      "793.0/11635.2, train_loss = 0.1826198196411133, time = 0.62\n",
      "794.0/11635.2, train_loss = 0.1657089614868164, time = 0.60\n",
      "795.0/11635.2, train_loss = 0.15876199722290038, time = 0.60\n",
      "796.0/11635.2, train_loss = 0.1596360683441162, time = 0.60\n",
      "797.0/11635.2, train_loss = 0.15671184539794922, time = 0.59\n",
      "798.0/11635.2, train_loss = 0.16729833602905272, time = 0.59\n",
      "799.0/11635.2, train_loss = 0.16976964950561524, time = 0.62\n",
      "800.0/11635.2, train_loss = 0.17889331817626952, time = 0.60\n",
      "801.0/11635.2, train_loss = 0.18264602661132812, time = 0.60\n",
      "802.0/11635.2, train_loss = 0.17102903366088867, time = 0.59\n",
      "803.0/11635.2, train_loss = 0.16802431106567384, time = 0.58\n",
      "804.0/11635.2, train_loss = 0.16349231719970703, time = 0.61\n",
      "805.0/11635.2, train_loss = 0.16261064529418945, time = 0.62\n",
      "806.0/11635.2, train_loss = 0.1709593963623047, time = 0.61\n",
      "807.0/11635.2, train_loss = 0.16354631423950194, time = 0.60\n",
      "808.0/11635.2, train_loss = 0.16290830612182616, time = 0.61\n",
      "809.0/11635.2, train_loss = 0.17652368545532227, time = 0.59\n",
      "810.0/11635.2, train_loss = 0.15217275619506837, time = 0.60\n",
      "811.0/11635.2, train_loss = 0.1534467887878418, time = 0.64\n",
      "812.0/11635.2, train_loss = 0.16887256622314453, time = 0.59\n",
      "813.0/11635.2, train_loss = 0.14574314117431642, time = 0.61\n",
      "814.0/11635.2, train_loss = 0.16952468872070312, time = 0.60\n",
      "815.0/11635.2, train_loss = 0.17343997955322266, time = 0.60\n",
      "816.0/11635.2, train_loss = 0.16827898025512694, time = 0.60\n",
      "817.0/11635.2, train_loss = 0.16920875549316405, time = 0.62\n",
      "818.0/11635.2, train_loss = 0.16848915100097656, time = 0.59\n",
      "819.0/11635.2, train_loss = 0.15272527694702148, time = 0.64\n",
      "820.0/11635.2, train_loss = 0.15746504783630372, time = 0.64\n",
      "821.0/11635.2, train_loss = 0.16257265090942383, time = 0.60\n",
      "822.0/11635.2, train_loss = 0.1636473274230957, time = 0.60\n",
      "823.0/11635.2, train_loss = 0.1635592460632324, time = 0.62\n",
      "824.0/11635.2, train_loss = 0.1603322982788086, time = 0.60\n",
      "825.0/11635.2, train_loss = 0.1542566967010498, time = 0.60\n",
      "826.0/11635.2, train_loss = 0.1655632209777832, time = 0.59\n",
      "827.0/11635.2, train_loss = 0.15871521949768067, time = 0.59\n",
      "828.0/11635.2, train_loss = 0.15806612014770507, time = 0.60\n",
      "829.0/11635.2, train_loss = 0.15673267364501953, time = 0.63\n",
      "830.0/11635.2, train_loss = 0.1455593776702881, time = 0.60\n",
      "831.0/11635.2, train_loss = 0.1548782444000244, time = 0.59\n",
      "832.0/11635.2, train_loss = 0.15247249603271484, time = 0.60\n",
      "833.0/11635.2, train_loss = 0.15793586730957032, time = 0.60\n",
      "834.0/11635.2, train_loss = 0.17999513626098632, time = 0.60\n",
      "835.0/11635.2, train_loss = 0.1451423168182373, time = 0.61\n",
      "836.0/11635.2, train_loss = 0.15193864822387695, time = 0.59\n",
      "837.0/11635.2, train_loss = 0.15235008239746095, time = 0.60\n",
      "838.0/11635.2, train_loss = 0.1562653350830078, time = 0.59\n",
      "839.0/11635.2, train_loss = 0.1386026382446289, time = 0.60\n",
      "840.0/11635.2, train_loss = 0.1538671398162842, time = 0.60\n",
      "841.0/11635.2, train_loss = 0.1373622512817383, time = 0.62\n",
      "842.0/11635.2, train_loss = 0.1564915084838867, time = 0.60\n",
      "843.0/11635.2, train_loss = 0.1640800094604492, time = 0.60\n",
      "844.0/11635.2, train_loss = 0.15827961921691894, time = 0.59\n",
      "845.0/11635.2, train_loss = 0.1465774154663086, time = 0.59\n",
      "846.0/11635.2, train_loss = 0.14460516929626466, time = 0.61\n",
      "847.0/11635.2, train_loss = 0.15022668838500977, time = 0.63\n",
      "848.0/11635.2, train_loss = 0.1452681827545166, time = 0.60\n",
      "849.0/11635.2, train_loss = 0.15258052825927734, time = 0.60\n",
      "850.0/11635.2, train_loss = 0.12809481620788574, time = 0.60\n",
      "851.0/11635.2, train_loss = 0.14844039916992188, time = 0.59\n",
      "852.0/11635.2, train_loss = 0.1604130172729492, time = 0.60\n",
      "853.0/11635.2, train_loss = 0.12412200927734375, time = 0.60\n",
      "854.0/11635.2, train_loss = 0.1377955913543701, time = 0.62\n",
      "855.0/11635.2, train_loss = 0.1396436023712158, time = 0.58\n",
      "856.0/11635.2, train_loss = 0.14634992599487304, time = 0.59\n",
      "857.0/11635.2, train_loss = 0.14155479431152343, time = 0.59\n",
      "858.0/11635.2, train_loss = 0.15098065376281739, time = 0.60\n",
      "859.0/11635.2, train_loss = 0.1437531280517578, time = 0.60\n",
      "860.0/11635.2, train_loss = 0.1326248550415039, time = 0.62\n",
      "861.0/11635.2, train_loss = 0.12271351814270019, time = 0.60\n",
      "862.0/11635.2, train_loss = 0.14978245735168458, time = 0.61\n",
      "863.0/11635.2, train_loss = 0.1382505989074707, time = 0.61\n",
      "864.0/11635.2, train_loss = 0.15204548835754395, time = 0.60\n",
      "865.0/11635.2, train_loss = 0.12524197578430177, time = 0.59\n",
      "866.0/11635.2, train_loss = 0.14295534133911134, time = 0.63\n",
      "867.0/11635.2, train_loss = 0.1321534538269043, time = 0.59\n",
      "868.0/11635.2, train_loss = 0.12703980445861818, time = 0.60\n",
      "869.0/11635.2, train_loss = 0.14543767929077148, time = 0.60\n",
      "870.0/11635.2, train_loss = 0.14626129150390624, time = 0.60\n",
      "871.0/11635.2, train_loss = 0.12735405921936035, time = 0.61\n",
      "872.0/11635.2, train_loss = 0.1340433120727539, time = 0.62\n",
      "873.0/11635.2, train_loss = 0.14420860290527343, time = 0.60\n",
      "874.0/11635.2, train_loss = 0.1482042694091797, time = 0.59\n",
      "875.0/11635.2, train_loss = 0.13210798263549806, time = 0.60\n",
      "876.0/11635.2, train_loss = 0.14545976638793945, time = 0.60\n",
      "877.0/11635.2, train_loss = 0.13910061836242676, time = 0.60\n",
      "878.0/11635.2, train_loss = 0.14856404304504395, time = 0.63\n",
      "879.0/11635.2, train_loss = 0.131214599609375, time = 0.61\n",
      "880.0/11635.2, train_loss = 0.13213513374328614, time = 0.62\n",
      "881.0/11635.2, train_loss = 0.1344131374359131, time = 0.60\n",
      "882.0/11635.2, train_loss = 0.1264609909057617, time = 0.60\n",
      "883.0/11635.2, train_loss = 0.12629197120666505, time = 0.60\n",
      "884.0/11635.2, train_loss = 0.13091279029846192, time = 0.62\n",
      "885.0/11635.2, train_loss = 0.13648416519165038, time = 0.60\n",
      "886.0/11635.2, train_loss = 0.12021610260009766, time = 0.60\n",
      "887.0/11635.2, train_loss = 0.12009315490722657, time = 0.61\n",
      "888.0/11635.2, train_loss = 0.1283383560180664, time = 0.60\n",
      "889.0/11635.2, train_loss = 0.11673828125, time = 0.60\n",
      "890.0/11635.2, train_loss = 0.12302385330200195, time = 0.62\n",
      "891.0/11635.2, train_loss = 0.13775526046752928, time = 0.60\n",
      "892.0/11635.2, train_loss = 0.12799443244934083, time = 0.59\n",
      "893.0/11635.2, train_loss = 0.12500433921813964, time = 0.64\n",
      "894.0/11635.2, train_loss = 0.12218957901000976, time = 0.64\n",
      "895.0/11635.2, train_loss = 0.12267871856689454, time = 0.62\n",
      "896.0/11635.2, train_loss = 0.12318702697753907, time = 0.63\n",
      "897.0/11635.2, train_loss = 0.1295633125305176, time = 0.59\n",
      "898.0/11635.2, train_loss = 0.11893569946289062, time = 0.59\n",
      "899.0/11635.2, train_loss = 0.13606284141540528, time = 0.61\n",
      "900.0/11635.2, train_loss = 0.13169870376586915, time = 0.59\n",
      "901.0/11635.2, train_loss = 0.11780911445617676, time = 0.60\n",
      "902.0/11635.2, train_loss = 0.11788051605224609, time = 0.62\n",
      "903.0/11635.2, train_loss = 0.12851189613342284, time = 0.61\n",
      "904.0/11635.2, train_loss = 0.11703452110290527, time = 0.60\n",
      "905.0/11635.2, train_loss = 0.12625298500061036, time = 0.60\n",
      "906.0/11635.2, train_loss = 0.13676149368286133, time = 0.60\n",
      "907.0/11635.2, train_loss = 0.1250270938873291, time = 0.59\n",
      "908.0/11635.2, train_loss = 0.11521737098693847, time = 0.63\n",
      "909.0/11635.2, train_loss = 0.12425307273864745, time = 0.60\n",
      "910.0/11635.2, train_loss = 0.11337902069091797, time = 0.60\n",
      "911.0/11635.2, train_loss = 0.11990533828735352, time = 0.61\n",
      "912.0/11635.2, train_loss = 0.11849893569946289, time = 0.61\n",
      "913.0/11635.2, train_loss = 0.1355151653289795, time = 0.60\n",
      "914.0/11635.2, train_loss = 0.1297160243988037, time = 0.63\n",
      "915.0/11635.2, train_loss = 0.11496562004089356, time = 0.60\n",
      "916.0/11635.2, train_loss = 0.11537654876708985, time = 0.61\n",
      "917.0/11635.2, train_loss = 0.12963404655456542, time = 0.60\n",
      "918.0/11635.2, train_loss = 0.12268765449523926, time = 0.61\n",
      "919.0/11635.2, train_loss = 0.11666790962219238, time = 0.59\n",
      "920.0/11635.2, train_loss = 0.11323617935180665, time = 0.60\n",
      "921.0/11635.2, train_loss = 0.11329797744750976, time = 0.64\n",
      "922.0/11635.2, train_loss = 0.1060080623626709, time = 0.62\n",
      "923.0/11635.2, train_loss = 0.12215954780578614, time = 0.61\n",
      "924.0/11635.2, train_loss = 0.12431562423706055, time = 0.60\n",
      "925.0/11635.2, train_loss = 0.10920960426330567, time = 0.60\n",
      "926.0/11635.2, train_loss = 0.11181071281433105, time = 0.59\n",
      "927.0/11635.2, train_loss = 0.10907914161682129, time = 0.61\n",
      "928.0/11635.2, train_loss = 0.11261747360229492, time = 0.61\n",
      "929.0/11635.2, train_loss = 0.10820091247558594, time = 0.60\n",
      "930.0/11635.2, train_loss = 0.11952947616577149, time = 0.59\n",
      "931.0/11635.2, train_loss = 0.10337409019470215, time = 0.60\n",
      "932.0/11635.2, train_loss = 0.10883906364440918, time = 0.61\n",
      "933.0/11635.2, train_loss = 0.11872374534606933, time = 0.62\n",
      "934.0/11635.2, train_loss = 0.1220470142364502, time = 0.59\n",
      "935.0/11635.2, train_loss = 0.11557518005371094, time = 0.60\n",
      "936.0/11635.2, train_loss = 0.11439454078674316, time = 0.60\n",
      "937.0/11635.2, train_loss = 0.11409160614013672, time = 0.61\n",
      "938.0/11635.2, train_loss = 0.11147638320922852, time = 0.60\n",
      "939.0/11635.2, train_loss = 0.10637090682983398, time = 0.62\n",
      "940.0/11635.2, train_loss = 0.11569625854492188, time = 0.60\n",
      "941.0/11635.2, train_loss = 0.10416380882263183, time = 0.60\n",
      "942.0/11635.2, train_loss = 0.11574203491210938, time = 0.60\n",
      "943.0/11635.2, train_loss = 0.11280612945556641, time = 0.59\n",
      "944.0/11635.2, train_loss = 0.11420939445495605, time = 0.59\n",
      "945.0/11635.2, train_loss = 0.10328263282775879, time = 0.63\n",
      "946.0/11635.2, train_loss = 0.11114034652709961, time = 0.59\n",
      "947.0/11635.2, train_loss = 0.13484343528747558, time = 0.60\n",
      "948.0/11635.2, train_loss = 0.11574491500854492, time = 0.61\n",
      "949.0/11635.2, train_loss = 0.12421233177185059, time = 0.60\n",
      "950.0/11635.2, train_loss = 0.10693574905395507, time = 0.60\n",
      "951.0/11635.2, train_loss = 0.10592168807983399, time = 0.63\n",
      "952.0/11635.2, train_loss = 0.10895313262939453, time = 0.60\n",
      "953.0/11635.2, train_loss = 0.12961092948913575, time = 0.61\n",
      "954.0/11635.2, train_loss = 0.11452810287475586, time = 0.61\n",
      "955.0/11635.2, train_loss = 0.10044384956359863, time = 0.60\n",
      "956.0/11635.2, train_loss = 0.10816912651062012, time = 0.60\n",
      "957.0/11635.2, train_loss = 0.10715612411499023, time = 0.63\n",
      "958.0/11635.2, train_loss = 0.10525101661682129, time = 0.59\n",
      "959.0/11635.2, train_loss = 0.10246912002563477, time = 0.59\n",
      "960.0/11635.2, train_loss = 0.10221351623535156, time = 0.60\n",
      "961.0/11635.2, train_loss = 0.10133697509765625, time = 0.62\n",
      "962.0/11635.2, train_loss = 0.10217215538024903, time = 0.60\n",
      "963.0/11635.2, train_loss = 0.11151543617248535, time = 0.63\n",
      "964.0/11635.2, train_loss = 0.1013320255279541, time = 0.60\n",
      "965.0/11635.2, train_loss = 0.11482768058776856, time = 0.61\n",
      "966.0/11635.2, train_loss = 0.11062047958374023, time = 0.59\n",
      "967.0/11635.2, train_loss = 0.11217528343200683, time = 0.59\n",
      "968.0/11635.2, train_loss = 0.10315306663513184, time = 0.61\n",
      "969.0/11635.2, train_loss = 0.10005725860595703, time = 0.61\n",
      "970.0/11635.2, train_loss = 0.10733674049377441, time = 0.61\n",
      "971.0/11635.2, train_loss = 0.10625814437866211, time = 0.60\n",
      "972.0/11635.2, train_loss = 0.0926167106628418, time = 0.61\n",
      "973.0/11635.2, train_loss = 0.08505910873413086, time = 0.60\n",
      "974.0/11635.2, train_loss = 0.09748207092285156, time = 0.60\n",
      "975.0/11635.2, train_loss = 0.10892029762268067, time = 0.62\n",
      "976.0/11635.2, train_loss = 0.10564091682434082, time = 0.60\n",
      "977.0/11635.2, train_loss = 0.09688648223876953, time = 0.59\n",
      "978.0/11635.2, train_loss = 0.09050464630126953, time = 0.60\n",
      "979.0/11635.2, train_loss = 0.09000904083251954, time = 0.60\n",
      "980.0/11635.2, train_loss = 0.09265246391296386, time = 0.60\n",
      "981.0/11635.2, train_loss = 0.1050373649597168, time = 0.64\n",
      "982.0/11635.2, train_loss = 0.09223529815673828, time = 0.61\n",
      "983.0/11635.2, train_loss = 0.10053440093994141, time = 0.59\n",
      "984.0/11635.2, train_loss = 0.10000777244567871, time = 0.60\n",
      "985.0/11635.2, train_loss = 0.10223369598388672, time = 0.61\n",
      "986.0/11635.2, train_loss = 0.08526337623596192, time = 0.61\n",
      "987.0/11635.2, train_loss = 0.09075318336486816, time = 0.60\n",
      "988.0/11635.2, train_loss = 0.11025334358215332, time = 0.61\n",
      "989.0/11635.2, train_loss = 0.10640886306762695, time = 0.59\n",
      "990.0/11635.2, train_loss = 0.0987885570526123, time = 0.60\n",
      "991.0/11635.2, train_loss = 0.0815676498413086, time = 0.59\n",
      "992.0/11635.2, train_loss = 0.09304128646850586, time = 0.60\n",
      "993.0/11635.2, train_loss = 0.10228915214538574, time = 0.60\n",
      "994.0/11635.2, train_loss = 0.111463041305542, time = 0.64\n",
      "995.0/11635.2, train_loss = 0.10230068206787109, time = 0.60\n",
      "996.0/11635.2, train_loss = 0.09281705856323243, time = 0.60\n",
      "997.0/11635.2, train_loss = 0.09113993644714355, time = 0.61\n",
      "998.0/11635.2, train_loss = 0.09174817085266113, time = 0.60\n",
      "999.0/11635.2, train_loss = 0.10989117622375488, time = 0.60\n",
      "1000.0/11635.2, train_loss = 0.08785916328430175, time = 0.62\n",
      "1001.0/11635.2, train_loss = 0.09364882469177246, time = 0.60\n",
      "1002.0/11635.2, train_loss = 0.09670141220092773, time = 0.62\n",
      "1003.0/11635.2, train_loss = 0.09039030075073243, time = 0.61\n",
      "1004.0/11635.2, train_loss = 0.10182448387145997, time = 0.59\n",
      "1005.0/11635.2, train_loss = 0.09184576034545898, time = 0.61\n",
      "1006.0/11635.2, train_loss = 0.10018857955932617, time = 0.63\n",
      "1007.0/11635.2, train_loss = 0.09161184310913086, time = 0.60\n",
      "1008.0/11635.2, train_loss = 0.09029772758483887, time = 0.60\n",
      "1009.0/11635.2, train_loss = 0.10021242141723632, time = 0.63\n",
      "1010.0/11635.2, train_loss = 0.10610872268676758, time = 0.60\n",
      "1011.0/11635.2, train_loss = 0.07560238838195801, time = 0.61\n",
      "1012.0/11635.2, train_loss = 0.10279220581054688, time = 0.62\n",
      "1013.0/11635.2, train_loss = 0.08630025863647461, time = 0.60\n",
      "1014.0/11635.2, train_loss = 0.08733232498168945, time = 0.61\n",
      "1015.0/11635.2, train_loss = 0.07600906372070312, time = 0.61\n",
      "1016.0/11635.2, train_loss = 0.09906391143798828, time = 0.60\n",
      "1017.0/11635.2, train_loss = 0.09169198989868164, time = 0.60\n",
      "1018.0/11635.2, train_loss = 0.10054946899414062, time = 0.66\n",
      "1019.0/11635.2, train_loss = 0.09154497146606445, time = 0.64\n",
      "1020.0/11635.2, train_loss = 0.09020352363586426, time = 0.60\n",
      "1021.0/11635.2, train_loss = 0.09294321060180664, time = 0.60\n",
      "1022.0/11635.2, train_loss = 0.0902663516998291, time = 0.60\n",
      "1023.0/11635.2, train_loss = 0.09122117042541504, time = 0.61\n",
      "1024.0/11635.2, train_loss = 0.08974480628967285, time = 0.63\n",
      "1025.0/11635.2, train_loss = 0.08128918647766113, time = 0.60\n",
      "1026.0/11635.2, train_loss = 0.08016547203063965, time = 0.59\n",
      "1027.0/11635.2, train_loss = 0.08783533096313477, time = 0.62\n",
      "1028.0/11635.2, train_loss = 0.09037171363830566, time = 0.60\n",
      "1029.0/11635.2, train_loss = 0.07802715301513671, time = 0.61\n",
      "1030.0/11635.2, train_loss = 0.08174332618713379, time = 0.63\n",
      "1031.0/11635.2, train_loss = 0.07913373947143555, time = 0.60\n",
      "1032.0/11635.2, train_loss = 0.08990123748779297, time = 0.60\n",
      "1033.0/11635.2, train_loss = 0.09953407287597656, time = 0.60\n",
      "1034.0/11635.2, train_loss = 0.09530158996582032, time = 0.61\n",
      "1035.0/11635.2, train_loss = 0.08539460182189941, time = 0.61\n",
      "1036.0/11635.2, train_loss = 0.09453502655029297, time = 0.61\n",
      "1037.0/11635.2, train_loss = 0.09058211326599121, time = 0.60\n",
      "1038.0/11635.2, train_loss = 0.10229515075683594, time = 0.60\n",
      "1039.0/11635.2, train_loss = 0.08076457023620605, time = 0.60\n",
      "1040.0/11635.2, train_loss = 0.08152597427368163, time = 0.60\n",
      "1041.0/11635.2, train_loss = 0.08164010047912598, time = 0.61\n",
      "1042.0/11635.2, train_loss = 0.07715325355529785, time = 0.63\n",
      "1043.0/11635.2, train_loss = 0.09142571449279785, time = 0.60\n",
      "1044.0/11635.2, train_loss = 0.08644261360168456, time = 0.62\n",
      "1045.0/11635.2, train_loss = 0.08106743812561035, time = 0.59\n",
      "1046.0/11635.2, train_loss = 0.08740612030029297, time = 0.68\n",
      "1047.0/11635.2, train_loss = 0.0930528450012207, time = 0.79\n",
      "1048.0/11635.2, train_loss = 0.09246376991271972, time = 0.78\n",
      "1049.0/11635.2, train_loss = 0.08046828269958496, time = 0.61\n",
      "1050.0/11635.2, train_loss = 0.08911059379577636, time = 0.60\n",
      "1051.0/11635.2, train_loss = 0.08492591857910156, time = 0.63\n",
      "1052.0/11635.2, train_loss = 0.07678311824798584, time = 0.61\n",
      "1053.0/11635.2, train_loss = 0.09091424942016602, time = 0.65\n",
      "1054.0/11635.2, train_loss = 0.08324934005737304, time = 0.66\n",
      "1055.0/11635.2, train_loss = 0.08216217041015625, time = 0.63\n",
      "1056.0/11635.2, train_loss = 0.09195502281188965, time = 0.60\n",
      "1057.0/11635.2, train_loss = 0.08029464721679687, time = 0.60\n",
      "1058.0/11635.2, train_loss = 0.08872387886047363, time = 0.61\n",
      "1059.0/11635.2, train_loss = 0.07937915802001953, time = 0.63\n",
      "1060.0/11635.2, train_loss = 0.08913060188293458, time = 0.60\n",
      "1061.0/11635.2, train_loss = 0.07471024036407471, time = 0.63\n",
      "1062.0/11635.2, train_loss = 0.09127679824829102, time = 0.60\n",
      "1063.0/11635.2, train_loss = 0.09013686180114747, time = 0.60\n",
      "1064.0/11635.2, train_loss = 0.07787606239318848, time = 0.60\n",
      "1065.0/11635.2, train_loss = 0.07965569972991943, time = 0.62\n",
      "1066.0/11635.2, train_loss = 0.08087907791137695, time = 0.61\n",
      "1067.0/11635.2, train_loss = 0.08414196014404297, time = 0.63\n",
      "1068.0/11635.2, train_loss = 0.08300246238708496, time = 0.61\n",
      "1069.0/11635.2, train_loss = 0.07734332084655762, time = 0.59\n",
      "1070.0/11635.2, train_loss = 0.0794720983505249, time = 0.60\n",
      "1071.0/11635.2, train_loss = 0.07602535724639893, time = 0.62\n",
      "1072.0/11635.2, train_loss = 0.06814353466033936, time = 0.60\n",
      "1073.0/11635.2, train_loss = 0.07610515594482421, time = 0.63\n",
      "1074.0/11635.2, train_loss = 0.07723192691802978, time = 0.60\n",
      "1075.0/11635.2, train_loss = 0.07672430992126465, time = 0.60\n",
      "1076.0/11635.2, train_loss = 0.08341924667358398, time = 0.61\n",
      "1077.0/11635.2, train_loss = 0.09292542457580566, time = 0.61\n",
      "1078.0/11635.2, train_loss = 0.07636435985565186, time = 0.61\n",
      "1079.0/11635.2, train_loss = 0.09048290252685547, time = 0.62\n",
      "1080.0/11635.2, train_loss = 0.07541596412658691, time = 0.61\n",
      "1081.0/11635.2, train_loss = 0.07220705509185792, time = 0.61\n",
      "1082.0/11635.2, train_loss = 0.07611199855804443, time = 0.59\n",
      "1083.0/11635.2, train_loss = 0.08837619781494141, time = 0.60\n",
      "1084.0/11635.2, train_loss = 0.07942936897277832, time = 0.62\n",
      "1085.0/11635.2, train_loss = 0.08374131202697754, time = 0.64\n",
      "1086.0/11635.2, train_loss = 0.07452249526977539, time = 0.61\n",
      "1087.0/11635.2, train_loss = 0.09076435089111329, time = 0.59\n",
      "1088.0/11635.2, train_loss = 0.07887969970703125, time = 0.61\n",
      "1089.0/11635.2, train_loss = 0.07425016403198242, time = 0.60\n",
      "1090.0/11635.2, train_loss = 0.08150609970092773, time = 0.60\n",
      "1091.0/11635.2, train_loss = 0.07870055198669433, time = 0.62\n",
      "1092.0/11635.2, train_loss = 0.07409706592559814, time = 0.61\n",
      "1093.0/11635.2, train_loss = 0.0729117488861084, time = 0.61\n",
      "1094.0/11635.2, train_loss = 0.0882344150543213, time = 0.60\n",
      "1095.0/11635.2, train_loss = 0.0826798915863037, time = 0.60\n",
      "1096.0/11635.2, train_loss = 0.08662364959716796, time = 0.61\n",
      "1097.0/11635.2, train_loss = 0.06253873825073242, time = 0.61\n",
      "1098.0/11635.2, train_loss = 0.0698803186416626, time = 0.60\n",
      "1099.0/11635.2, train_loss = 0.08286458015441894, time = 0.61\n",
      "1100.0/11635.2, train_loss = 0.08017489433288574, time = 0.62\n",
      "1101.0/11635.2, train_loss = 0.0721411657333374, time = 0.62\n",
      "1102.0/11635.2, train_loss = 0.0821249771118164, time = 0.61\n",
      "1103.0/11635.2, train_loss = 0.07768081665039063, time = 0.62\n",
      "1104.0/11635.2, train_loss = 0.08476938247680664, time = 0.63\n",
      "1105.0/11635.2, train_loss = 0.07535206317901612, time = 0.62\n",
      "1106.0/11635.2, train_loss = 0.07626870155334473, time = 0.64\n",
      "1107.0/11635.2, train_loss = 0.07795877933502197, time = 0.61\n",
      "1108.0/11635.2, train_loss = 0.07353412628173828, time = 0.61\n",
      "1109.0/11635.2, train_loss = 0.07181768894195556, time = 0.63\n",
      "1110.0/11635.2, train_loss = 0.07716011524200439, time = 0.61\n",
      "1111.0/11635.2, train_loss = 0.06366435527801513, time = 0.60\n",
      "1112.0/11635.2, train_loss = 0.06519225597381592, time = 0.62\n",
      "1113.0/11635.2, train_loss = 0.07620403289794922, time = 0.60\n",
      "1114.0/11635.2, train_loss = 0.08128237724304199, time = 0.60\n",
      "1115.0/11635.2, train_loss = 0.07074036598205566, time = 0.66\n",
      "1116.0/11635.2, train_loss = 0.07389233112335206, time = 0.68\n",
      "1117.0/11635.2, train_loss = 0.06873011112213134, time = 0.65\n",
      "1118.0/11635.2, train_loss = 0.08273183822631835, time = 0.64\n",
      "1119.0/11635.2, train_loss = 0.07198221683502197, time = 0.62\n",
      "1120.0/11635.2, train_loss = 0.07377216339111328, time = 0.61\n",
      "1121.0/11635.2, train_loss = 0.06445034980773925, time = 0.61\n",
      "1122.0/11635.2, train_loss = 0.06811771392822266, time = 0.62\n",
      "1123.0/11635.2, train_loss = 0.0698006534576416, time = 0.61\n",
      "1124.0/11635.2, train_loss = 0.07176909446716309, time = 0.63\n",
      "1125.0/11635.2, train_loss = 0.06997127532958984, time = 0.61\n",
      "1126.0/11635.2, train_loss = 0.07282783985137939, time = 0.61\n",
      "1127.0/11635.2, train_loss = 0.0707318639755249, time = 0.60\n",
      "1128.0/11635.2, train_loss = 0.06970529556274414, time = 0.63\n",
      "1129.0/11635.2, train_loss = 0.07284854888916016, time = 0.62\n",
      "1130.0/11635.2, train_loss = 0.06206409454345703, time = 0.60\n",
      "1131.0/11635.2, train_loss = 0.07189321994781495, time = 0.63\n",
      "1132.0/11635.2, train_loss = 0.06450504302978516, time = 0.65\n",
      "1133.0/11635.2, train_loss = 0.06615993976593018, time = 0.63\n",
      "1134.0/11635.2, train_loss = 0.07417404174804687, time = 0.63\n",
      "1135.0/11635.2, train_loss = 0.0703796100616455, time = 0.61\n",
      "1136.0/11635.2, train_loss = 0.06905959129333496, time = 0.61\n",
      "1137.0/11635.2, train_loss = 0.07275697708129883, time = 0.61\n",
      "1138.0/11635.2, train_loss = 0.06329641342163086, time = 0.61\n",
      "1139.0/11635.2, train_loss = 0.08092629432678222, time = 0.60\n",
      "1140.0/11635.2, train_loss = 0.06851191997528076, time = 0.63\n",
      "1141.0/11635.2, train_loss = 0.06714769840240478, time = 0.62\n",
      "1142.0/11635.2, train_loss = 0.07065879344940186, time = 0.61\n",
      "1143.0/11635.2, train_loss = 0.07864572525024414, time = 0.61\n",
      "1144.0/11635.2, train_loss = 0.07686572074890137, time = 0.60\n",
      "1145.0/11635.2, train_loss = 0.06597724914550782, time = 0.62\n",
      "1146.0/11635.2, train_loss = 0.06424396991729736, time = 0.65\n",
      "1147.0/11635.2, train_loss = 0.0696602201461792, time = 0.63\n",
      "1148.0/11635.2, train_loss = 0.06889792442321778, time = 0.63\n",
      "1149.0/11635.2, train_loss = 0.06335121154785156, time = 0.62\n",
      "1150.0/11635.2, train_loss = 0.06963294506072998, time = 0.61\n",
      "1151.0/11635.2, train_loss = 0.06492639541625976, time = 0.61\n",
      "1152.0/11635.2, train_loss = 0.06593943119049073, time = 0.62\n",
      "1153.0/11635.2, train_loss = 0.06870046615600586, time = 0.59\n",
      "1154.0/11635.2, train_loss = 0.0701338529586792, time = 0.61\n",
      "1155.0/11635.2, train_loss = 0.06326706886291504, time = 0.61\n",
      "1156.0/11635.2, train_loss = 0.06484856128692627, time = 0.61\n",
      "1157.0/11635.2, train_loss = 0.0676037311553955, time = 0.63\n",
      "1158.0/11635.2, train_loss = 0.0690312671661377, time = 0.63\n",
      "1159.0/11635.2, train_loss = 0.07227356433868408, time = 0.60\n",
      "1160.0/11635.2, train_loss = 0.06052402496337891, time = 0.61\n",
      "1161.0/11635.2, train_loss = 0.05747657299041748, time = 0.60\n",
      "1162.0/11635.2, train_loss = 0.06277680397033691, time = 0.61\n",
      "1163.0/11635.2, train_loss = 0.06550650119781494, time = 0.60\n",
      "1164.0/11635.2, train_loss = 0.06996540546417236, time = 0.65\n",
      "1165.0/11635.2, train_loss = 0.06398813247680664, time = 0.61\n",
      "1166.0/11635.2, train_loss = 0.0660623550415039, time = 0.61\n",
      "1167.0/11635.2, train_loss = 0.055845174789428714, time = 0.61\n",
      "1168.0/11635.2, train_loss = 0.06345738410949707, time = 0.60\n",
      "1169.0/11635.2, train_loss = 0.06957396984100342, time = 0.63\n",
      "1170.0/11635.2, train_loss = 0.06586628913879394, time = 0.63\n",
      "1171.0/11635.2, train_loss = 0.05923497676849365, time = 0.60\n",
      "1172.0/11635.2, train_loss = 0.07701136589050293, time = 0.60\n",
      "1173.0/11635.2, train_loss = 0.058718752861022946, time = 0.61\n",
      "1174.0/11635.2, train_loss = 0.06370745182037353, time = 0.60\n",
      "1175.0/11635.2, train_loss = 0.06959833145141602, time = 0.61\n",
      "1176.0/11635.2, train_loss = 0.07267368316650391, time = 0.68\n",
      "1177.0/11635.2, train_loss = 0.06357963562011719, time = 0.63\n",
      "1178.0/11635.2, train_loss = 0.06785329818725586, time = 0.62\n",
      "1179.0/11635.2, train_loss = 0.05803537845611572, time = 0.61\n",
      "1180.0/11635.2, train_loss = 0.06258018016815185, time = 0.60\n",
      "1181.0/11635.2, train_loss = 0.057310295104980466, time = 0.62\n",
      "1182.0/11635.2, train_loss = 0.07642616271972656, time = 0.62\n",
      "1183.0/11635.2, train_loss = 0.05350503921508789, time = 0.62\n",
      "1184.0/11635.2, train_loss = 0.06107689380645752, time = 0.62\n",
      "1185.0/11635.2, train_loss = 0.06803278923034668, time = 0.62\n",
      "1186.0/11635.2, train_loss = 0.06295473575592041, time = 0.63\n",
      "1187.0/11635.2, train_loss = 0.06110732078552246, time = 0.62\n",
      "1188.0/11635.2, train_loss = 0.06231942176818848, time = 0.62\n",
      "1189.0/11635.2, train_loss = 0.05142205238342285, time = 0.65\n",
      "1190.0/11635.2, train_loss = 0.054026732444763186, time = 0.61\n",
      "1191.0/11635.2, train_loss = 0.06498674869537353, time = 0.62\n",
      "1192.0/11635.2, train_loss = 0.06973844528198242, time = 0.61\n",
      "1193.0/11635.2, train_loss = 0.058508296012878415, time = 0.61\n",
      "1194.0/11635.2, train_loss = 0.0676809549331665, time = 0.61\n",
      "1195.0/11635.2, train_loss = 0.06083256244659424, time = 0.63\n",
      "1196.0/11635.2, train_loss = 0.06703534126281738, time = 0.61\n",
      "1197.0/11635.2, train_loss = 0.06725636005401611, time = 0.62\n",
      "1198.0/11635.2, train_loss = 0.06042610168457031, time = 0.60\n",
      "1199.0/11635.2, train_loss = 0.06575369358062744, time = 0.62\n",
      "1200.0/11635.2, train_loss = 0.07807735443115234, time = 0.63\n",
      "1201.0/11635.2, train_loss = 0.0687355089187622, time = 0.69\n",
      "1202.0/11635.2, train_loss = 0.05308807373046875, time = 0.60\n",
      "1203.0/11635.2, train_loss = 0.05509905815124512, time = 0.63\n",
      "1204.0/11635.2, train_loss = 0.06536741733551026, time = 0.61\n",
      "1205.0/11635.2, train_loss = 0.06112613677978516, time = 0.65\n",
      "1206.0/11635.2, train_loss = 0.060230960845947264, time = 0.61\n",
      "1207.0/11635.2, train_loss = 0.07389657974243163, time = 0.63\n",
      "1208.0/11635.2, train_loss = 0.06052250385284424, time = 0.61\n",
      "1209.0/11635.2, train_loss = 0.0583529806137085, time = 0.62\n",
      "1210.0/11635.2, train_loss = 0.05802971839904785, time = 0.61\n",
      "1211.0/11635.2, train_loss = 0.06617424964904785, time = 0.61\n",
      "1212.0/11635.2, train_loss = 0.055504283905029296, time = 0.62\n",
      "1213.0/11635.2, train_loss = 0.05826620101928711, time = 0.64\n",
      "1214.0/11635.2, train_loss = 0.0505793046951294, time = 0.61\n",
      "1215.0/11635.2, train_loss = 0.058840675354003905, time = 0.61\n",
      "1216.0/11635.2, train_loss = 0.0637239694595337, time = 0.63\n",
      "1217.0/11635.2, train_loss = 0.05532663345336914, time = 0.61\n",
      "1218.0/11635.2, train_loss = 0.056727085113525394, time = 0.62\n",
      "1219.0/11635.2, train_loss = 0.052835884094238283, time = 0.63\n",
      "1220.0/11635.2, train_loss = 0.052721714973449706, time = 0.63\n",
      "1221.0/11635.2, train_loss = 0.06456460952758789, time = 0.62\n",
      "1222.0/11635.2, train_loss = 0.06869205951690674, time = 0.62\n",
      "1223.0/11635.2, train_loss = 0.05969882011413574, time = 0.60\n",
      "1224.0/11635.2, train_loss = 0.05663567066192627, time = 0.62\n",
      "1225.0/11635.2, train_loss = 0.05303642272949219, time = 0.62\n",
      "1226.0/11635.2, train_loss = 0.06726786136627197, time = 0.61\n",
      "1227.0/11635.2, train_loss = 0.06484060764312743, time = 0.62\n",
      "1228.0/11635.2, train_loss = 0.05581832885742188, time = 0.61\n",
      "1229.0/11635.2, train_loss = 0.06248610019683838, time = 0.62\n",
      "1230.0/11635.2, train_loss = 0.06661394119262695, time = 0.61\n",
      "1231.0/11635.2, train_loss = 0.05527418613433838, time = 0.63\n",
      "1232.0/11635.2, train_loss = 0.05105897903442383, time = 0.61\n",
      "1233.0/11635.2, train_loss = 0.05347747325897217, time = 0.61\n",
      "1234.0/11635.2, train_loss = 0.0605104398727417, time = 0.61\n",
      "1235.0/11635.2, train_loss = 0.058160834312438965, time = 0.61\n",
      "1236.0/11635.2, train_loss = 0.05810274600982666, time = 0.61\n",
      "1237.0/11635.2, train_loss = 0.06547741889953614, time = 0.64\n",
      "1238.0/11635.2, train_loss = 0.05499113082885742, time = 0.62\n",
      "1239.0/11635.2, train_loss = 0.06233983039855957, time = 0.61\n",
      "1240.0/11635.2, train_loss = 0.06694068431854248, time = 0.61\n",
      "1241.0/11635.2, train_loss = 0.056838607788085936, time = 0.70\n",
      "1242.0/11635.2, train_loss = 0.05761745929718018, time = 0.61\n",
      "1243.0/11635.2, train_loss = 0.060803771018981934, time = 0.64\n",
      "1244.0/11635.2, train_loss = 0.055644960403442384, time = 0.61\n",
      "1245.0/11635.2, train_loss = 0.05763189792633057, time = 0.62\n",
      "1246.0/11635.2, train_loss = 0.04962107181549072, time = 0.59\n",
      "1247.0/11635.2, train_loss = 0.060068726539611816, time = 0.60\n",
      "1248.0/11635.2, train_loss = 0.04946996688842773, time = 0.62\n",
      "1249.0/11635.2, train_loss = 0.04616464614868164, time = 0.65\n",
      "1250.0/11635.2, train_loss = 0.052652020454406735, time = 0.63\n",
      "1251.0/11635.2, train_loss = 0.05349928379058838, time = 0.62\n",
      "1252.0/11635.2, train_loss = 0.05624439239501953, time = 0.61\n",
      "1253.0/11635.2, train_loss = 0.05288627147674561, time = 0.61\n",
      "1254.0/11635.2, train_loss = 0.057728514671325684, time = 0.62\n",
      "1255.0/11635.2, train_loss = 0.05043737888336182, time = 0.62\n",
      "1256.0/11635.2, train_loss = 0.05469153881072998, time = 0.63\n",
      "1257.0/11635.2, train_loss = 0.058475341796875, time = 0.61\n",
      "1258.0/11635.2, train_loss = 0.057797393798828124, time = 0.62\n",
      "1259.0/11635.2, train_loss = 0.05258519649505615, time = 0.62\n",
      "1260.0/11635.2, train_loss = 0.055824298858642575, time = 0.62\n",
      "1261.0/11635.2, train_loss = 0.04555821418762207, time = 0.62\n",
      "1262.0/11635.2, train_loss = 0.05447402000427246, time = 0.65\n",
      "1263.0/11635.2, train_loss = 0.05670521259307861, time = 0.62\n",
      "1264.0/11635.2, train_loss = 0.05568168640136719, time = 0.62\n",
      "1265.0/11635.2, train_loss = 0.06418838024139405, time = 0.64\n",
      "1266.0/11635.2, train_loss = 0.04922062397003174, time = 0.61\n",
      "1267.0/11635.2, train_loss = 0.0534467601776123, time = 0.60\n",
      "1268.0/11635.2, train_loss = 0.0436716365814209, time = 0.63\n",
      "1269.0/11635.2, train_loss = 0.05329963207244873, time = 0.61\n",
      "1270.0/11635.2, train_loss = 0.05886992931365967, time = 0.62\n",
      "1271.0/11635.2, train_loss = 0.05240834712982178, time = 0.60\n",
      "1272.0/11635.2, train_loss = 0.0546228837966919, time = 0.62\n",
      "1273.0/11635.2, train_loss = 0.06234945297241211, time = 0.64\n",
      "1274.0/11635.2, train_loss = 0.04904928684234619, time = 0.65\n",
      "1275.0/11635.2, train_loss = 0.05073189735412598, time = 0.61\n",
      "1276.0/11635.2, train_loss = 0.051609673500061036, time = 0.60\n",
      "1277.0/11635.2, train_loss = 0.049040088653564455, time = 0.61\n",
      "1278.0/11635.2, train_loss = 0.0553731107711792, time = 0.61\n",
      "1279.0/11635.2, train_loss = 0.04965638637542725, time = 0.61\n",
      "1280.0/11635.2, train_loss = 0.052319507598876956, time = 0.64\n",
      "1281.0/11635.2, train_loss = 0.05756315231323242, time = 0.63\n",
      "1282.0/11635.2, train_loss = 0.055647873878479005, time = 0.63\n",
      "1283.0/11635.2, train_loss = 0.05584751129150391, time = 0.63\n",
      "1284.0/11635.2, train_loss = 0.05302587032318115, time = 0.62\n",
      "1285.0/11635.2, train_loss = 0.04514245986938477, time = 0.61\n",
      "1286.0/11635.2, train_loss = 0.045148644447326663, time = 0.66\n",
      "1287.0/11635.2, train_loss = 0.05283773422241211, time = 0.62\n",
      "1288.0/11635.2, train_loss = 0.05165182590484619, time = 0.61\n",
      "1289.0/11635.2, train_loss = 0.05655062198638916, time = 0.63\n",
      "1290.0/11635.2, train_loss = 0.05449004650115967, time = 0.63\n",
      "1291.0/11635.2, train_loss = 0.050532255172729496, time = 0.64\n",
      "1292.0/11635.2, train_loss = 0.043549108505249026, time = 0.64\n",
      "1293.0/11635.2, train_loss = 0.04881252765655517, time = 0.61\n",
      "1294.0/11635.2, train_loss = 0.04869350433349609, time = 0.61\n",
      "1295.0/11635.2, train_loss = 0.04306519985198975, time = 0.62\n",
      "1296.0/11635.2, train_loss = 0.05639344692230225, time = 0.60\n",
      "1297.0/11635.2, train_loss = 0.04942555427551269, time = 0.60\n",
      "1298.0/11635.2, train_loss = 0.046309714317321775, time = 0.65\n",
      "1299.0/11635.2, train_loss = 0.04843369960784912, time = 0.64\n",
      "1300.0/11635.2, train_loss = 0.06151157855987549, time = 0.64\n",
      "1301.0/11635.2, train_loss = 0.05105583667755127, time = 0.60\n",
      "1302.0/11635.2, train_loss = 0.05251175880432129, time = 0.60\n",
      "1303.0/11635.2, train_loss = 0.0523793888092041, time = 0.61\n",
      "1304.0/11635.2, train_loss = 0.043174610137939454, time = 0.63\n",
      "1305.0/11635.2, train_loss = 0.034234871864318846, time = 0.61\n",
      "1306.0/11635.2, train_loss = 0.04744921207427979, time = 0.61\n",
      "1307.0/11635.2, train_loss = 0.04929492473602295, time = 0.60\n",
      "1308.0/11635.2, train_loss = 0.04802695274353028, time = 0.60\n",
      "1309.0/11635.2, train_loss = 0.06272899627685546, time = 0.60\n",
      "1310.0/11635.2, train_loss = 0.055447688102722166, time = 0.64\n",
      "1311.0/11635.2, train_loss = 0.051881175041198734, time = 0.61\n",
      "1312.0/11635.2, train_loss = 0.04315836429595947, time = 0.61\n",
      "1313.0/11635.2, train_loss = 0.06338186264038086, time = 0.62\n",
      "1314.0/11635.2, train_loss = 0.049732327461242676, time = 0.60\n",
      "1315.0/11635.2, train_loss = 0.06009276390075684, time = 0.61\n",
      "1316.0/11635.2, train_loss = 0.054481711387634274, time = 0.64\n",
      "1317.0/11635.2, train_loss = 0.047155637741088864, time = 0.62\n",
      "1318.0/11635.2, train_loss = 0.052749552726745606, time = 0.62\n",
      "1319.0/11635.2, train_loss = 0.057878336906433105, time = 0.61\n",
      "1320.0/11635.2, train_loss = 0.04140425682067871, time = 0.61\n",
      "1321.0/11635.2, train_loss = 0.046799120903015134, time = 0.60\n",
      "1322.0/11635.2, train_loss = 0.051239604949951174, time = 0.60\n",
      "1323.0/11635.2, train_loss = 0.045831065177917484, time = 0.62\n",
      "1324.0/11635.2, train_loss = 0.0561275053024292, time = 0.60\n",
      "1325.0/11635.2, train_loss = 0.047771973609924315, time = 0.60\n",
      "1326.0/11635.2, train_loss = 0.0453359317779541, time = 0.65\n",
      "1327.0/11635.2, train_loss = 0.05006892681121826, time = 0.64\n",
      "1328.0/11635.2, train_loss = 0.040878219604492186, time = 0.60\n",
      "1329.0/11635.2, train_loss = 0.05200996875762939, time = 0.63\n",
      "1330.0/11635.2, train_loss = 0.049727683067321775, time = 0.59\n",
      "1331.0/11635.2, train_loss = 0.048045778274536134, time = 0.62\n",
      "1332.0/11635.2, train_loss = 0.0481868314743042, time = 0.60\n",
      "1333.0/11635.2, train_loss = 0.04086029529571533, time = 0.61\n",
      "1334.0/11635.2, train_loss = 0.048597917556762696, time = 0.61\n",
      "1335.0/11635.2, train_loss = 0.04502120018005371, time = 0.64\n",
      "1336.0/11635.2, train_loss = 0.040974369049072264, time = 0.61\n",
      "1337.0/11635.2, train_loss = 0.0441532564163208, time = 0.61\n",
      "1338.0/11635.2, train_loss = 0.06703541278839112, time = 0.61\n",
      "1339.0/11635.2, train_loss = 0.045147762298583985, time = 0.60\n",
      "1340.0/11635.2, train_loss = 0.04395307064056397, time = 0.60\n",
      "1341.0/11635.2, train_loss = 0.050392870903015134, time = 0.63\n",
      "1342.0/11635.2, train_loss = 0.0404473352432251, time = 0.60\n",
      "1343.0/11635.2, train_loss = 0.043654255867004395, time = 0.63\n",
      "1344.0/11635.2, train_loss = 0.04700319766998291, time = 0.60\n",
      "1345.0/11635.2, train_loss = 0.05065470695495605, time = 0.62\n",
      "1346.0/11635.2, train_loss = 0.04223274230957031, time = 0.60\n",
      "1347.0/11635.2, train_loss = 0.04715360641479492, time = 0.63\n",
      "1348.0/11635.2, train_loss = 0.048285093307495114, time = 0.60\n",
      "1349.0/11635.2, train_loss = 0.05132341861724853, time = 0.61\n",
      "1350.0/11635.2, train_loss = 0.04672515869140625, time = 0.60\n",
      "1351.0/11635.2, train_loss = 0.05437560558319092, time = 0.61\n",
      "1352.0/11635.2, train_loss = 0.04421546936035156, time = 0.62\n",
      "1353.0/11635.2, train_loss = 0.050668830871582034, time = 0.64\n",
      "1354.0/11635.2, train_loss = 0.04287019729614258, time = 0.61\n",
      "1355.0/11635.2, train_loss = 0.039037771224975586, time = 0.61\n",
      "1356.0/11635.2, train_loss = 0.040732007026672366, time = 0.60\n",
      "1357.0/11635.2, train_loss = 0.046847896575927736, time = 0.61\n",
      "1358.0/11635.2, train_loss = 0.043296093940734866, time = 0.60\n",
      "1359.0/11635.2, train_loss = 0.04890552043914795, time = 0.64\n",
      "1360.0/11635.2, train_loss = 0.043727540969848634, time = 0.60\n",
      "1361.0/11635.2, train_loss = 0.04909366607666016, time = 0.61\n",
      "1362.0/11635.2, train_loss = 0.03877692222595215, time = 0.61\n",
      "1363.0/11635.2, train_loss = 0.04319921970367432, time = 0.61\n",
      "1364.0/11635.2, train_loss = 0.042531614303588865, time = 0.61\n",
      "1365.0/11635.2, train_loss = 0.05173091411590576, time = 0.64\n",
      "1366.0/11635.2, train_loss = 0.04709412574768066, time = 0.60\n",
      "1367.0/11635.2, train_loss = 0.050797891616821286, time = 0.60\n",
      "1368.0/11635.2, train_loss = 0.05046182632446289, time = 0.61\n",
      "1369.0/11635.2, train_loss = 0.052807888984680175, time = 0.62\n",
      "1370.0/11635.2, train_loss = 0.036818952560424806, time = 0.59\n",
      "1371.0/11635.2, train_loss = 0.053439302444458006, time = 0.64\n",
      "1372.0/11635.2, train_loss = 0.041820130348205566, time = 0.60\n",
      "1373.0/11635.2, train_loss = 0.040716328620910645, time = 0.60\n",
      "1374.0/11635.2, train_loss = 0.047191891670227054, time = 0.60\n",
      "1375.0/11635.2, train_loss = 0.044885411262512206, time = 0.62\n",
      "1376.0/11635.2, train_loss = 0.04673062801361084, time = 0.60\n",
      "1377.0/11635.2, train_loss = 0.053616294860839846, time = 0.62\n",
      "1378.0/11635.2, train_loss = 0.04172623634338379, time = 0.60\n",
      "1379.0/11635.2, train_loss = 0.042167229652404783, time = 0.60\n",
      "1380.0/11635.2, train_loss = 0.04295758724212646, time = 0.62\n",
      "1381.0/11635.2, train_loss = 0.04367888450622558, time = 0.62\n",
      "1382.0/11635.2, train_loss = 0.04437557220458985, time = 0.61\n",
      "1383.0/11635.2, train_loss = 0.03295841693878174, time = 0.64\n",
      "1384.0/11635.2, train_loss = 0.04089896678924561, time = 0.61\n",
      "1385.0/11635.2, train_loss = 0.043338356018066404, time = 0.62\n",
      "1386.0/11635.2, train_loss = 0.03893617630004883, time = 0.60\n",
      "1387.0/11635.2, train_loss = 0.04211008548736572, time = 0.60\n",
      "1388.0/11635.2, train_loss = 0.04027295112609863, time = 0.60\n",
      "1389.0/11635.2, train_loss = 0.04284188270568848, time = 0.61\n",
      "1390.0/11635.2, train_loss = 0.04322892665863037, time = 0.62\n",
      "1391.0/11635.2, train_loss = 0.036068692207336425, time = 0.60\n",
      "1392.0/11635.2, train_loss = 0.04501286029815674, time = 0.62\n",
      "1393.0/11635.2, train_loss = 0.04379239082336426, time = 0.60\n",
      "1394.0/11635.2, train_loss = 0.04448539733886719, time = 0.60\n",
      "1395.0/11635.2, train_loss = 0.04796751976013183, time = 0.59\n",
      "1396.0/11635.2, train_loss = 0.03848540782928467, time = 0.64\n",
      "1397.0/11635.2, train_loss = 0.046526098251342775, time = 0.60\n",
      "1398.0/11635.2, train_loss = 0.037734513282775876, time = 0.65\n",
      "1399.0/11635.2, train_loss = 0.03849168539047241, time = 0.61\n",
      "1400.0/11635.2, train_loss = 0.04613476753234863, time = 0.63\n",
      "1401.0/11635.2, train_loss = 0.0525541877746582, time = 0.60\n",
      "1402.0/11635.2, train_loss = 0.04319798946380615, time = 0.64\n",
      "1403.0/11635.2, train_loss = 0.042323765754699705, time = 0.61\n",
      "1404.0/11635.2, train_loss = 0.047491083145141604, time = 0.60\n",
      "1405.0/11635.2, train_loss = 0.04453204154968262, time = 0.61\n",
      "1406.0/11635.2, train_loss = 0.040121479034423826, time = 0.61\n",
      "1407.0/11635.2, train_loss = 0.03838704109191895, time = 0.61\n",
      "1408.0/11635.2, train_loss = 0.044887356758117676, time = 0.64\n",
      "1409.0/11635.2, train_loss = 0.04324590682983399, time = 0.60\n",
      "1410.0/11635.2, train_loss = 0.0375288200378418, time = 0.60\n",
      "1411.0/11635.2, train_loss = 0.0427806282043457, time = 0.61\n",
      "1412.0/11635.2, train_loss = 0.048704395294189455, time = 0.61\n",
      "1413.0/11635.2, train_loss = 0.03936111450195313, time = 0.60\n",
      "1414.0/11635.2, train_loss = 0.03749281644821167, time = 0.63\n",
      "1415.0/11635.2, train_loss = 0.035965087413787844, time = 0.61\n",
      "1416.0/11635.2, train_loss = 0.04861867904663086, time = 0.61\n",
      "1417.0/11635.2, train_loss = 0.04216711521148682, time = 0.61\n",
      "1418.0/11635.2, train_loss = 0.047194933891296385, time = 0.60\n",
      "1419.0/11635.2, train_loss = 0.05748283386230469, time = 0.61\n",
      "1420.0/11635.2, train_loss = 0.046128005981445314, time = 0.63\n",
      "1421.0/11635.2, train_loss = 0.04016621112823486, time = 0.61\n",
      "1422.0/11635.2, train_loss = 0.03929457426071167, time = 0.61\n",
      "1423.0/11635.2, train_loss = 0.032689530849456784, time = 0.62\n",
      "1424.0/11635.2, train_loss = 0.041783685684204104, time = 0.62\n",
      "1425.0/11635.2, train_loss = 0.04145177364349365, time = 0.61\n",
      "1426.0/11635.2, train_loss = 0.04128845691680908, time = 0.64\n",
      "1427.0/11635.2, train_loss = 0.03766429662704468, time = 0.61\n",
      "1428.0/11635.2, train_loss = 0.04334622859954834, time = 0.60\n",
      "1429.0/11635.2, train_loss = 0.03894147157669067, time = 0.60\n",
      "1430.0/11635.2, train_loss = 0.04297778606414795, time = 0.60\n",
      "1431.0/11635.2, train_loss = 0.039963879585266114, time = 0.61\n",
      "1432.0/11635.2, train_loss = 0.044153566360473635, time = 0.64\n",
      "1433.0/11635.2, train_loss = 0.0360348916053772, time = 0.60\n",
      "1434.0/11635.2, train_loss = 0.04126413345336914, time = 0.60\n",
      "1435.0/11635.2, train_loss = 0.031471102237701415, time = 0.60\n",
      "1436.0/11635.2, train_loss = 0.0326737904548645, time = 0.60\n",
      "1437.0/11635.2, train_loss = 0.04474184036254883, time = 0.61\n",
      "1438.0/11635.2, train_loss = 0.043781490325927735, time = 0.62\n",
      "1439.0/11635.2, train_loss = 0.044109249114990236, time = 0.59\n",
      "1440.0/11635.2, train_loss = 0.040199594497680666, time = 0.61\n",
      "1441.0/11635.2, train_loss = 0.03791057586669922, time = 0.62\n",
      "1442.0/11635.2, train_loss = 0.037748515605926514, time = 0.62\n",
      "1443.0/11635.2, train_loss = 0.04669191837310791, time = 0.61\n",
      "1444.0/11635.2, train_loss = 0.04079278469085693, time = 0.64\n",
      "1445.0/11635.2, train_loss = 0.03983115196228027, time = 0.62\n",
      "1446.0/11635.2, train_loss = 0.03360446453094482, time = 0.61\n",
      "1447.0/11635.2, train_loss = 0.043038158416748046, time = 0.61\n",
      "1448.0/11635.2, train_loss = 0.037343366146087645, time = 0.62\n",
      "1449.0/11635.2, train_loss = 0.0359566855430603, time = 0.64\n",
      "1450.0/11635.2, train_loss = 0.033405983448028566, time = 0.67\n",
      "1451.0/11635.2, train_loss = 0.03788706302642822, time = 0.61\n",
      "1452.0/11635.2, train_loss = 0.04395896434783936, time = 0.61\n",
      "1453.0/11635.2, train_loss = 0.03579362154006958, time = 0.61\n",
      "1454.0/11635.2, train_loss = 0.036326513290405274, time = 0.61\n",
      "1455.0/11635.2, train_loss = 0.03317362546920776, time = 0.61\n",
      "1456.0/11635.2, train_loss = 0.032854981422424316, time = 0.60\n",
      "1457.0/11635.2, train_loss = 0.04135597229003906, time = 0.63\n",
      "1458.0/11635.2, train_loss = 0.039078152179718016, time = 0.61\n",
      "1459.0/11635.2, train_loss = 0.038814725875854494, time = 0.62\n",
      "1460.0/11635.2, train_loss = 0.03421112060546875, time = 0.61\n",
      "1461.0/11635.2, train_loss = 0.04116825580596924, time = 0.60\n",
      "1462.0/11635.2, train_loss = 0.03840218544006348, time = 0.59\n",
      "1463.0/11635.2, train_loss = 0.03816296815872192, time = 0.63\n",
      "1464.0/11635.2, train_loss = 0.039070029258728024, time = 0.60\n",
      "1465.0/11635.2, train_loss = 0.03827450037002564, time = 0.61\n",
      "1466.0/11635.2, train_loss = 0.036497797966003415, time = 0.60\n",
      "1467.0/11635.2, train_loss = 0.03239941358566284, time = 0.62\n",
      "1468.0/11635.2, train_loss = 0.036555304527282714, time = 0.61\n",
      "1469.0/11635.2, train_loss = 0.03769786596298218, time = 0.64\n",
      "1470.0/11635.2, train_loss = 0.03689302444458008, time = 0.62\n",
      "1471.0/11635.2, train_loss = 0.028786063194274902, time = 0.60\n",
      "1472.0/11635.2, train_loss = 0.03384089708328247, time = 0.60\n",
      "1473.0/11635.2, train_loss = 0.04224511623382568, time = 0.62\n",
      "1474.0/11635.2, train_loss = 0.03662467956542969, time = 0.61\n",
      "1475.0/11635.2, train_loss = 0.03735057592391968, time = 0.63\n",
      "1476.0/11635.2, train_loss = 0.046051106452941894, time = 0.60\n",
      "1477.0/11635.2, train_loss = 0.0388102126121521, time = 0.61\n",
      "1478.0/11635.2, train_loss = 0.042471733093261715, time = 0.60\n",
      "1479.0/11635.2, train_loss = 0.04512844085693359, time = 0.60\n",
      "1480.0/11635.2, train_loss = 0.03517034530639648, time = 0.62\n",
      "1481.0/11635.2, train_loss = 0.037024731636047366, time = 0.65\n",
      "1482.0/11635.2, train_loss = 0.03979020118713379, time = 0.60\n",
      "1483.0/11635.2, train_loss = 0.02924365282058716, time = 0.61\n",
      "1484.0/11635.2, train_loss = 0.03644649028778076, time = 0.60\n",
      "1485.0/11635.2, train_loss = 0.033151650428771974, time = 0.62\n",
      "1486.0/11635.2, train_loss = 0.035511837005615235, time = 0.61\n",
      "1487.0/11635.2, train_loss = 0.040668625831604, time = 0.64\n",
      "1488.0/11635.2, train_loss = 0.03553425312042236, time = 0.60\n",
      "1489.0/11635.2, train_loss = 0.0319593596458435, time = 0.62\n",
      "1490.0/11635.2, train_loss = 0.030070016384124754, time = 0.61\n",
      "1491.0/11635.2, train_loss = 0.03686488151550293, time = 0.60\n",
      "1492.0/11635.2, train_loss = 0.02980538606643677, time = 0.61\n",
      "1493.0/11635.2, train_loss = 0.028069071769714356, time = 0.63\n",
      "1494.0/11635.2, train_loss = 0.0310079288482666, time = 0.63\n",
      "1495.0/11635.2, train_loss = 0.029590420722961426, time = 0.62\n",
      "1496.0/11635.2, train_loss = 0.034007844924926756, time = 0.62\n",
      "1497.0/11635.2, train_loss = 0.04344710350036621, time = 0.62\n",
      "1498.0/11635.2, train_loss = 0.040779128074645996, time = 0.60\n",
      "1499.0/11635.2, train_loss = 0.03852048397064209, time = 0.67\n",
      "1500.0/11635.2, train_loss = 0.033410704135894774, time = 0.63\n",
      "1501.0/11635.2, train_loss = 0.04364532470703125, time = 0.61\n",
      "1502.0/11635.2, train_loss = 0.03710011720657349, time = 0.62\n",
      "1503.0/11635.2, train_loss = 0.03578842639923096, time = 0.62\n",
      "1504.0/11635.2, train_loss = 0.03584550857543945, time = 0.76\n",
      "1505.0/11635.2, train_loss = 0.03389618873596192, time = 0.68\n",
      "1506.0/11635.2, train_loss = 0.03560112953186035, time = 0.62\n",
      "1507.0/11635.2, train_loss = 0.037837913036346434, time = 0.60\n",
      "1508.0/11635.2, train_loss = 0.03986677885055542, time = 0.60\n",
      "1509.0/11635.2, train_loss = 0.03202823162078858, time = 0.60\n",
      "1510.0/11635.2, train_loss = 0.02871991157531738, time = 0.60\n",
      "1511.0/11635.2, train_loss = 0.033662102222442626, time = 0.65\n",
      "1512.0/11635.2, train_loss = 0.03494542598724365, time = 0.61\n",
      "1513.0/11635.2, train_loss = 0.04487063407897949, time = 0.61\n",
      "1514.0/11635.2, train_loss = 0.0359065842628479, time = 0.61\n",
      "1515.0/11635.2, train_loss = 0.0320601749420166, time = 0.61\n",
      "1516.0/11635.2, train_loss = 0.030651092529296875, time = 0.60\n",
      "1517.0/11635.2, train_loss = 0.039332122802734376, time = 0.64\n",
      "1518.0/11635.2, train_loss = 0.03576212882995605, time = 0.60\n",
      "1519.0/11635.2, train_loss = 0.032559850215911866, time = 0.61\n",
      "1520.0/11635.2, train_loss = 0.02924685478210449, time = 0.61\n",
      "1521.0/11635.2, train_loss = 0.028908252716064453, time = 0.61\n",
      "1522.0/11635.2, train_loss = 0.03327862739562988, time = 0.61\n",
      "1523.0/11635.2, train_loss = 0.03331251859664917, time = 0.61\n",
      "1524.0/11635.2, train_loss = 0.045144662857055665, time = 0.62\n",
      "1525.0/11635.2, train_loss = 0.036466879844665526, time = 0.61\n",
      "1526.0/11635.2, train_loss = 0.03194687843322754, time = 0.61\n",
      "1527.0/11635.2, train_loss = 0.04562331199645996, time = 0.61\n",
      "1528.0/11635.2, train_loss = 0.03117790937423706, time = 0.61\n",
      "1529.0/11635.2, train_loss = 0.036976132392883304, time = 0.61\n",
      "1530.0/11635.2, train_loss = 0.03732748508453369, time = 0.62\n",
      "1531.0/11635.2, train_loss = 0.035658295154571536, time = 0.61\n",
      "1532.0/11635.2, train_loss = 0.0343311882019043, time = 0.61\n",
      "1533.0/11635.2, train_loss = 0.027079195976257325, time = 0.60\n",
      "1534.0/11635.2, train_loss = 0.028707764148712157, time = 0.60\n",
      "1535.0/11635.2, train_loss = 0.03377075910568237, time = 0.61\n",
      "1536.0/11635.2, train_loss = 0.03138251781463623, time = 0.64\n",
      "1537.0/11635.2, train_loss = 0.03196510553359985, time = 0.59\n",
      "1538.0/11635.2, train_loss = 0.03757227897644043, time = 0.60\n",
      "1539.0/11635.2, train_loss = 0.03833513498306274, time = 0.60\n",
      "1540.0/11635.2, train_loss = 0.02879046678543091, time = 0.61\n",
      "1541.0/11635.2, train_loss = 0.03014610767364502, time = 0.61\n",
      "1542.0/11635.2, train_loss = 0.04401996612548828, time = 0.62\n",
      "1543.0/11635.2, train_loss = 0.0312353777885437, time = 0.59\n",
      "1544.0/11635.2, train_loss = 0.03489917278289795, time = 0.61\n",
      "1545.0/11635.2, train_loss = 0.04032130241394043, time = 0.60\n",
      "1546.0/11635.2, train_loss = 0.03931357383728027, time = 0.60\n",
      "1547.0/11635.2, train_loss = 0.03157906055450439, time = 0.59\n",
      "1548.0/11635.2, train_loss = 0.04224209785461426, time = 0.62\n",
      "1549.0/11635.2, train_loss = 0.03733376741409302, time = 0.60\n",
      "1550.0/11635.2, train_loss = 0.03601183414459228, time = 0.62\n",
      "1551.0/11635.2, train_loss = 0.03781244277954102, time = 0.60\n",
      "1552.0/11635.2, train_loss = 0.03467025995254516, time = 0.60\n",
      "1553.0/11635.2, train_loss = 0.030257585048675536, time = 0.60\n",
      "1554.0/11635.2, train_loss = 0.036054406166076663, time = 0.62\n",
      "1555.0/11635.2, train_loss = 0.029716439247131347, time = 0.60\n",
      "1556.0/11635.2, train_loss = 0.030632896423339842, time = 0.60\n",
      "1557.0/11635.2, train_loss = 0.03631621837615967, time = 0.59\n",
      "1558.0/11635.2, train_loss = 0.04512777805328369, time = 0.59\n",
      "1559.0/11635.2, train_loss = 0.03414063453674317, time = 0.61\n",
      "1560.0/11635.2, train_loss = 0.02790013551712036, time = 0.63\n",
      "1561.0/11635.2, train_loss = 0.029695980548858643, time = 0.59\n",
      "1562.0/11635.2, train_loss = 0.032307429313659666, time = 0.59\n",
      "1563.0/11635.2, train_loss = 0.03631693124771118, time = 0.60\n",
      "1564.0/11635.2, train_loss = 0.0376047420501709, time = 0.60\n",
      "1565.0/11635.2, train_loss = 0.028306500911712648, time = 0.60\n",
      "1566.0/11635.2, train_loss = 0.03636396169662476, time = 0.62\n",
      "1567.0/11635.2, train_loss = 0.030458540916442872, time = 0.59\n",
      "1568.0/11635.2, train_loss = 0.030795743465423586, time = 0.60\n",
      "1569.0/11635.2, train_loss = 0.03548328161239624, time = 0.59\n",
      "1570.0/11635.2, train_loss = 0.03324230194091797, time = 0.61\n",
      "1571.0/11635.2, train_loss = 0.03670782804489136, time = 0.60\n",
      "1572.0/11635.2, train_loss = 0.03344010591506958, time = 0.63\n",
      "1573.0/11635.2, train_loss = 0.03380972862243652, time = 0.59\n",
      "1574.0/11635.2, train_loss = 0.035939688682556155, time = 0.60\n",
      "1575.0/11635.2, train_loss = 0.03967971086502075, time = 0.60\n",
      "1576.0/11635.2, train_loss = 0.027236793041229248, time = 0.61\n",
      "1577.0/11635.2, train_loss = 0.031779308319091794, time = 0.59\n",
      "1578.0/11635.2, train_loss = 0.038951025009155274, time = 0.61\n",
      "1579.0/11635.2, train_loss = 0.03311986923217773, time = 0.59\n",
      "1580.0/11635.2, train_loss = 0.03257401466369629, time = 0.62\n",
      "1581.0/11635.2, train_loss = 0.036600611209869384, time = 0.60\n",
      "1582.0/11635.2, train_loss = 0.032006251811981204, time = 0.60\n",
      "1583.0/11635.2, train_loss = 0.030706133842468262, time = 0.61\n",
      "1584.0/11635.2, train_loss = 0.035521345138549806, time = 0.62\n",
      "1585.0/11635.2, train_loss = 0.02959806442260742, time = 0.60\n",
      "1586.0/11635.2, train_loss = 0.03385151624679565, time = 0.60\n",
      "1587.0/11635.2, train_loss = 0.03006697416305542, time = 0.60\n",
      "1588.0/11635.2, train_loss = 0.03354755640029907, time = 0.60\n",
      "1589.0/11635.2, train_loss = 0.03152684211730957, time = 0.60\n",
      "1590.0/11635.2, train_loss = 0.03039656162261963, time = 0.59\n",
      "1591.0/11635.2, train_loss = 0.026530954837799072, time = 0.62\n",
      "1592.0/11635.2, train_loss = 0.034192540645599366, time = 0.59\n",
      "1593.0/11635.2, train_loss = 0.03326037168502807, time = 0.62\n",
      "1594.0/11635.2, train_loss = 0.03348196029663086, time = 0.60\n",
      "1595.0/11635.2, train_loss = 0.02995708703994751, time = 0.61\n",
      "1596.0/11635.2, train_loss = 0.0327473521232605, time = 0.60\n",
      "1597.0/11635.2, train_loss = 0.03420675754547119, time = 0.61\n",
      "1598.0/11635.2, train_loss = 0.025965268611907958, time = 0.61\n",
      "1599.0/11635.2, train_loss = 0.03469652414321899, time = 0.60\n",
      "1600.0/11635.2, train_loss = 0.02965589761734009, time = 0.61\n",
      "1601.0/11635.2, train_loss = 0.03600985527038574, time = 0.61\n",
      "1602.0/11635.2, train_loss = 0.0288864541053772, time = 0.60\n",
      "1603.0/11635.2, train_loss = 0.031696908473968506, time = 0.63\n",
      "1604.0/11635.2, train_loss = 0.03041325807571411, time = 0.61\n",
      "1605.0/11635.2, train_loss = 0.03714221239089966, time = 0.62\n",
      "1606.0/11635.2, train_loss = 0.03673911333084107, time = 0.60\n",
      "1607.0/11635.2, train_loss = 0.035247747898101804, time = 0.60\n",
      "1608.0/11635.2, train_loss = 0.029865117073059083, time = 0.60\n",
      "1609.0/11635.2, train_loss = 0.030358333587646485, time = 0.63\n",
      "1610.0/11635.2, train_loss = 0.03617922782897949, time = 0.60\n",
      "1611.0/11635.2, train_loss = 0.0383981204032898, time = 0.61\n",
      "1612.0/11635.2, train_loss = 0.033266816139221195, time = 0.62\n",
      "1613.0/11635.2, train_loss = 0.03244966506958008, time = 0.64\n",
      "1614.0/11635.2, train_loss = 0.025590102672576904, time = 0.65\n",
      "1615.0/11635.2, train_loss = 0.03512754440307617, time = 0.65\n",
      "1616.0/11635.2, train_loss = 0.0307446026802063, time = 0.63\n",
      "1617.0/11635.2, train_loss = 0.04560733795166016, time = 0.61\n",
      "1618.0/11635.2, train_loss = 0.026605141162872315, time = 0.70\n",
      "1619.0/11635.2, train_loss = 0.03960395336151123, time = 0.72\n",
      "1620.0/11635.2, train_loss = 0.024696314334869386, time = 0.62\n",
      "1621.0/11635.2, train_loss = 0.02537499189376831, time = 0.62\n",
      "1622.0/11635.2, train_loss = 0.028589227199554444, time = 0.60\n",
      "1623.0/11635.2, train_loss = 0.03305730819702148, time = 0.60\n",
      "1624.0/11635.2, train_loss = 0.03913286209106445, time = 0.60\n",
      "1625.0/11635.2, train_loss = 0.025949790477752685, time = 0.60\n",
      "1626.0/11635.2, train_loss = 0.025039834976196287, time = 0.61\n",
      "1627.0/11635.2, train_loss = 0.030475289821624757, time = 0.62\n",
      "1628.0/11635.2, train_loss = 0.028718788623809815, time = 0.59\n",
      "1629.0/11635.2, train_loss = 0.02725166320800781, time = 0.62\n",
      "1630.0/11635.2, train_loss = 0.037527387142181394, time = 0.60\n",
      "1631.0/11635.2, train_loss = 0.03822808504104614, time = 0.60\n",
      "1632.0/11635.2, train_loss = 0.029709978103637694, time = 0.61\n",
      "1633.0/11635.2, train_loss = 0.032301440238952636, time = 0.62\n",
      "1634.0/11635.2, train_loss = 0.032730813026428225, time = 0.60\n",
      "1635.0/11635.2, train_loss = 0.02719430923461914, time = 0.59\n",
      "1636.0/11635.2, train_loss = 0.028401570320129396, time = 0.60\n",
      "1637.0/11635.2, train_loss = 0.02446755886077881, time = 0.60\n",
      "1638.0/11635.2, train_loss = 0.029662513732910158, time = 0.62\n",
      "1639.0/11635.2, train_loss = 0.03331429243087768, time = 0.62\n",
      "1640.0/11635.2, train_loss = 0.028123815059661866, time = 0.60\n",
      "1641.0/11635.2, train_loss = 0.02746744155883789, time = 0.59\n",
      "1642.0/11635.2, train_loss = 0.026244006156921386, time = 0.60\n",
      "1643.0/11635.2, train_loss = 0.035678682327270506, time = 0.60\n",
      "1644.0/11635.2, train_loss = 0.02644699573516846, time = 0.61\n",
      "1645.0/11635.2, train_loss = 0.02903883218765259, time = 0.63\n",
      "1646.0/11635.2, train_loss = 0.03511829376220703, time = 0.60\n",
      "1647.0/11635.2, train_loss = 0.026789610385894776, time = 0.60\n",
      "1648.0/11635.2, train_loss = 0.02990048885345459, time = 0.60\n",
      "1649.0/11635.2, train_loss = 0.03455925464630127, time = 0.60\n",
      "1650.0/11635.2, train_loss = 0.035455484390258786, time = 0.60\n",
      "1651.0/11635.2, train_loss = 0.03046858310699463, time = 0.63\n",
      "1652.0/11635.2, train_loss = 0.03238586187362671, time = 0.60\n",
      "1653.0/11635.2, train_loss = 0.02982126474380493, time = 0.60\n",
      "1654.0/11635.2, train_loss = 0.029331550598144532, time = 0.59\n",
      "1655.0/11635.2, train_loss = 0.036454732418060305, time = 0.61\n",
      "1656.0/11635.2, train_loss = 0.03135794162750244, time = 0.60\n",
      "1657.0/11635.2, train_loss = 0.04001953601837158, time = 0.60\n",
      "1658.0/11635.2, train_loss = 0.02567183256149292, time = 0.62\n",
      "1659.0/11635.2, train_loss = 0.02465520620346069, time = 0.60\n",
      "1660.0/11635.2, train_loss = 0.027729313373565673, time = 0.60\n",
      "1661.0/11635.2, train_loss = 0.0237842059135437, time = 0.60\n",
      "1662.0/11635.2, train_loss = 0.029041786193847657, time = 0.61\n",
      "1663.0/11635.2, train_loss = 0.031451749801635745, time = 0.60\n",
      "1664.0/11635.2, train_loss = 0.029684624671936034, time = 0.62\n",
      "1665.0/11635.2, train_loss = 0.03320753574371338, time = 0.60\n",
      "1666.0/11635.2, train_loss = 0.029589545726776124, time = 0.59\n",
      "1667.0/11635.2, train_loss = 0.02989935636520386, time = 0.61\n",
      "1668.0/11635.2, train_loss = 0.02535834550857544, time = 0.60\n",
      "1669.0/11635.2, train_loss = 0.024470789432525633, time = 0.60\n",
      "1670.0/11635.2, train_loss = 0.030786318778991698, time = 0.63\n",
      "1671.0/11635.2, train_loss = 0.02276705265045166, time = 0.60\n",
      "1672.0/11635.2, train_loss = 0.022848279476165773, time = 0.61\n",
      "1673.0/11635.2, train_loss = 0.026528522968292237, time = 0.60\n",
      "1674.0/11635.2, train_loss = 0.02851872444152832, time = 0.60\n",
      "1675.0/11635.2, train_loss = 0.033656632900238036, time = 0.60\n",
      "1676.0/11635.2, train_loss = 0.028828506469726563, time = 0.62\n",
      "1677.0/11635.2, train_loss = 0.02884974718093872, time = 0.61\n",
      "1678.0/11635.2, train_loss = 0.03430511951446533, time = 0.60\n",
      "1679.0/11635.2, train_loss = 0.028917584419250488, time = 0.59\n",
      "1680.0/11635.2, train_loss = 0.02732157230377197, time = 0.60\n",
      "1681.0/11635.2, train_loss = 0.027078466415405275, time = 0.60\n",
      "1682.0/11635.2, train_loss = 0.02403531312942505, time = 0.64\n",
      "1683.0/11635.2, train_loss = 0.028366203308105468, time = 0.60\n",
      "1684.0/11635.2, train_loss = 0.03215481042861938, time = 0.60\n",
      "1685.0/11635.2, train_loss = 0.03015953063964844, time = 0.60\n",
      "1686.0/11635.2, train_loss = 0.024898664951324465, time = 0.60\n",
      "1687.0/11635.2, train_loss = 0.027178878784179687, time = 0.63\n",
      "1688.0/11635.2, train_loss = 0.034446091651916505, time = 0.63\n",
      "1689.0/11635.2, train_loss = 0.0220892071723938, time = 0.60\n",
      "1690.0/11635.2, train_loss = 0.02505439043045044, time = 0.59\n",
      "1691.0/11635.2, train_loss = 0.03176622152328491, time = 0.59\n",
      "1692.0/11635.2, train_loss = 0.029467618465423583, time = 0.62\n",
      "1693.0/11635.2, train_loss = 0.020689980983734133, time = 0.60\n",
      "1694.0/11635.2, train_loss = 0.024818389415740966, time = 0.64\n",
      "1695.0/11635.2, train_loss = 0.030906105041503908, time = 0.60\n",
      "1696.0/11635.2, train_loss = 0.026516282558441163, time = 0.61\n",
      "1697.0/11635.2, train_loss = 0.02777202844619751, time = 0.60\n",
      "1698.0/11635.2, train_loss = 0.02214472532272339, time = 0.60\n",
      "1699.0/11635.2, train_loss = 0.03036975622177124, time = 0.60\n",
      "1700.0/11635.2, train_loss = 0.03180291891098022, time = 0.63\n",
      "1701.0/11635.2, train_loss = 0.03730466365814209, time = 0.61\n",
      "1702.0/11635.2, train_loss = 0.028982558250427247, time = 0.62\n",
      "1703.0/11635.2, train_loss = 0.026690282821655274, time = 0.60\n",
      "1704.0/11635.2, train_loss = 0.02406912326812744, time = 0.60\n",
      "1705.0/11635.2, train_loss = 0.024080235958099366, time = 0.60\n",
      "1706.0/11635.2, train_loss = 0.020563881397247314, time = 0.62\n",
      "1707.0/11635.2, train_loss = 0.026388638019561768, time = 0.60\n",
      "1708.0/11635.2, train_loss = 0.025724809169769287, time = 0.60\n",
      "1709.0/11635.2, train_loss = 0.02401862382888794, time = 0.60\n",
      "1710.0/11635.2, train_loss = 0.02958954334259033, time = 0.62\n",
      "1711.0/11635.2, train_loss = 0.02814138650894165, time = 0.61\n",
      "1712.0/11635.2, train_loss = 0.02756986618041992, time = 0.64\n",
      "1713.0/11635.2, train_loss = 0.02749816417694092, time = 0.60\n",
      "1714.0/11635.2, train_loss = 0.0250262451171875, time = 0.59\n",
      "1715.0/11635.2, train_loss = 0.023770415782928468, time = 0.60\n",
      "1716.0/11635.2, train_loss = 0.019968448877334594, time = 0.60\n",
      "1717.0/11635.2, train_loss = 0.024942290782928467, time = 0.61\n",
      "1718.0/11635.2, train_loss = 0.023666093349456786, time = 0.62\n",
      "1719.0/11635.2, train_loss = 0.0335932993888855, time = 0.61\n",
      "1720.0/11635.2, train_loss = 0.03946040391921997, time = 0.61\n",
      "1721.0/11635.2, train_loss = 0.021584925651550294, time = 0.61\n",
      "1722.0/11635.2, train_loss = 0.02492074966430664, time = 0.60\n",
      "1723.0/11635.2, train_loss = 0.032745952606201174, time = 0.61\n",
      "1724.0/11635.2, train_loss = 0.02592904806137085, time = 0.60\n",
      "1725.0/11635.2, train_loss = 0.030966906547546386, time = 0.61\n",
      "1726.0/11635.2, train_loss = 0.03907078981399536, time = 0.61\n",
      "1727.0/11635.2, train_loss = 0.03836360931396485, time = 0.62\n",
      "1728.0/11635.2, train_loss = 0.027016961574554445, time = 0.61\n",
      "1729.0/11635.2, train_loss = 0.031046888828277587, time = 0.59\n",
      "1730.0/11635.2, train_loss = 0.02263880491256714, time = 0.60\n",
      "1731.0/11635.2, train_loss = 0.03886936902999878, time = 0.62\n",
      "1732.0/11635.2, train_loss = 0.024565563201904297, time = 0.60\n",
      "1733.0/11635.2, train_loss = 0.021469049453735352, time = 0.60\n",
      "1734.0/11635.2, train_loss = 0.026826789379119875, time = 0.60\n",
      "1735.0/11635.2, train_loss = 0.022700481414794922, time = 0.61\n",
      "1736.0/11635.2, train_loss = 0.030821974277496337, time = 0.60\n",
      "1737.0/11635.2, train_loss = 0.021441516876220704, time = 0.65\n",
      "1738.0/11635.2, train_loss = 0.02287914037704468, time = 0.62\n",
      "1739.0/11635.2, train_loss = 0.028209424018859862, time = 0.61\n",
      "1740.0/11635.2, train_loss = 0.034652304649353025, time = 0.60\n",
      "1741.0/11635.2, train_loss = 0.025143585205078124, time = 0.59\n",
      "1742.0/11635.2, train_loss = 0.03507789611816406, time = 0.60\n",
      "1743.0/11635.2, train_loss = 0.02685565710067749, time = 0.63\n",
      "1744.0/11635.2, train_loss = 0.02524080753326416, time = 0.61\n",
      "1745.0/11635.2, train_loss = 0.02305727481842041, time = 0.60\n",
      "1746.0/11635.2, train_loss = 0.02798022508621216, time = 0.60\n",
      "1747.0/11635.2, train_loss = 0.01938328266143799, time = 0.62\n",
      "1748.0/11635.2, train_loss = 0.029123942852020263, time = 0.61\n",
      "1749.0/11635.2, train_loss = 0.03335756540298462, time = 0.63\n",
      "1750.0/11635.2, train_loss = 0.02670562744140625, time = 0.59\n",
      "1751.0/11635.2, train_loss = 0.02543029308319092, time = 0.61\n",
      "1752.0/11635.2, train_loss = 0.023029537200927735, time = 0.61\n",
      "1753.0/11635.2, train_loss = 0.02654637336730957, time = 0.61\n",
      "1754.0/11635.2, train_loss = 0.024055087566375734, time = 0.60\n",
      "1755.0/11635.2, train_loss = 0.024977543354034425, time = 0.62\n",
      "1756.0/11635.2, train_loss = 0.026978521347045897, time = 0.60\n",
      "1757.0/11635.2, train_loss = 0.028031058311462402, time = 0.60\n",
      "1758.0/11635.2, train_loss = 0.0226027512550354, time = 0.61\n",
      "1759.0/11635.2, train_loss = 0.023013434410095214, time = 0.60\n",
      "1760.0/11635.2, train_loss = 0.028886396884918213, time = 0.60\n",
      "1761.0/11635.2, train_loss = 0.033990776538848876, time = 0.63\n",
      "1762.0/11635.2, train_loss = 0.027363884449005126, time = 0.60\n",
      "1763.0/11635.2, train_loss = 0.0218392014503479, time = 0.60\n",
      "1764.0/11635.2, train_loss = 0.021826353073120117, time = 0.61\n",
      "1765.0/11635.2, train_loss = 0.033624780178070066, time = 0.60\n",
      "1766.0/11635.2, train_loss = 0.026488535404205323, time = 0.61\n",
      "1767.0/11635.2, train_loss = 0.02673494577407837, time = 0.63\n",
      "1768.0/11635.2, train_loss = 0.021877067089080812, time = 0.62\n",
      "1769.0/11635.2, train_loss = 0.028143680095672606, time = 0.60\n",
      "1770.0/11635.2, train_loss = 0.034173383712768554, time = 0.60\n",
      "1771.0/11635.2, train_loss = 0.02762787103652954, time = 0.60\n",
      "1772.0/11635.2, train_loss = 0.026235015392303468, time = 0.61\n",
      "1773.0/11635.2, train_loss = 0.029224517345428466, time = 0.63\n",
      "1774.0/11635.2, train_loss = 0.024243454933166503, time = 0.61\n",
      "1775.0/11635.2, train_loss = 0.027989442348480224, time = 0.60\n",
      "1776.0/11635.2, train_loss = 0.021703338623046874, time = 0.60\n",
      "1777.0/11635.2, train_loss = 0.025299386978149416, time = 0.61\n",
      "1778.0/11635.2, train_loss = 0.026884794235229492, time = 0.61\n",
      "1779.0/11635.2, train_loss = 0.026066851615905762, time = 0.63\n",
      "1780.0/11635.2, train_loss = 0.027622241973876954, time = 0.60\n",
      "1781.0/11635.2, train_loss = 0.03020688772201538, time = 0.60\n",
      "1782.0/11635.2, train_loss = 0.025203771591186523, time = 0.60\n",
      "1783.0/11635.2, train_loss = 0.03248645782470703, time = 0.60\n",
      "1784.0/11635.2, train_loss = 0.027506093978881836, time = 0.61\n",
      "1785.0/11635.2, train_loss = 0.028475375175476075, time = 0.63\n",
      "1786.0/11635.2, train_loss = 0.021659739017486572, time = 0.60\n",
      "1787.0/11635.2, train_loss = 0.01982770562171936, time = 0.59\n",
      "1788.0/11635.2, train_loss = 0.024361648559570313, time = 0.60\n",
      "1789.0/11635.2, train_loss = 0.018396917581558227, time = 0.60\n",
      "1790.0/11635.2, train_loss = 0.02643491268157959, time = 0.60\n",
      "1791.0/11635.2, train_loss = 0.02411454439163208, time = 0.61\n",
      "1792.0/11635.2, train_loss = 0.027027876377105714, time = 0.62\n",
      "1793.0/11635.2, train_loss = 0.028265423774719238, time = 0.63\n",
      "1794.0/11635.2, train_loss = 0.022883038520812988, time = 0.60\n",
      "1795.0/11635.2, train_loss = 0.027969930171966553, time = 0.61\n",
      "1796.0/11635.2, train_loss = 0.023933525085449218, time = 0.61\n",
      "1797.0/11635.2, train_loss = 0.025199708938598634, time = 0.60\n",
      "1798.0/11635.2, train_loss = 0.025258781909942626, time = 0.62\n",
      "1799.0/11635.2, train_loss = 0.025252480506896973, time = 0.60\n",
      "1800.0/11635.2, train_loss = 0.03513671398162842, time = 0.59\n",
      "1801.0/11635.2, train_loss = 0.03093109846115112, time = 0.62\n",
      "1802.0/11635.2, train_loss = 0.021399619579315184, time = 0.61\n",
      "1803.0/11635.2, train_loss = 0.0293742036819458, time = 0.60\n",
      "1804.0/11635.2, train_loss = 0.02299078702926636, time = 0.61\n",
      "1805.0/11635.2, train_loss = 0.027106623649597168, time = 0.60\n",
      "1806.0/11635.2, train_loss = 0.023335492610931395, time = 0.59\n",
      "1807.0/11635.2, train_loss = 0.02582747459411621, time = 0.61\n",
      "1808.0/11635.2, train_loss = 0.030599114894866945, time = 0.60\n",
      "1809.0/11635.2, train_loss = 0.023730335235595704, time = 0.60\n",
      "1810.0/11635.2, train_loss = 0.026118834018707276, time = 0.67\n",
      "1811.0/11635.2, train_loss = 0.029154794216156008, time = 0.63\n",
      "1812.0/11635.2, train_loss = 0.01794308066368103, time = 0.62\n",
      "1813.0/11635.2, train_loss = 0.027958588600158693, time = 0.59\n",
      "1814.0/11635.2, train_loss = 0.020450913906097413, time = 0.59\n",
      "1815.0/11635.2, train_loss = 0.024813077449798583, time = 0.61\n",
      "1816.0/11635.2, train_loss = 0.02410801649093628, time = 0.62\n",
      "1817.0/11635.2, train_loss = 0.02346522569656372, time = 0.61\n",
      "1818.0/11635.2, train_loss = 0.022914960384368896, time = 0.60\n",
      "1819.0/11635.2, train_loss = 0.01592360734939575, time = 0.59\n",
      "1820.0/11635.2, train_loss = 0.023553209304809572, time = 0.61\n",
      "1821.0/11635.2, train_loss = 0.027268614768981934, time = 0.60\n",
      "1822.0/11635.2, train_loss = 0.029077227115631103, time = 0.67\n",
      "1823.0/11635.2, train_loss = 0.028810923099517823, time = 0.61\n",
      "1824.0/11635.2, train_loss = 0.0298478627204895, time = 0.61\n",
      "1825.0/11635.2, train_loss = 0.02549004077911377, time = 0.61\n",
      "1826.0/11635.2, train_loss = 0.0243513822555542, time = 0.62\n",
      "1827.0/11635.2, train_loss = 0.025700261592864992, time = 0.62\n",
      "1828.0/11635.2, train_loss = 0.0433796501159668, time = 0.63\n",
      "1829.0/11635.2, train_loss = 0.030898892879486085, time = 0.60\n",
      "1830.0/11635.2, train_loss = 0.03185947418212891, time = 0.61\n",
      "1831.0/11635.2, train_loss = 0.019399276971817016, time = 0.60\n",
      "1832.0/11635.2, train_loss = 0.026623401641845703, time = 0.61\n",
      "1833.0/11635.2, train_loss = 0.02079707384109497, time = 0.61\n",
      "1834.0/11635.2, train_loss = 0.026843867301940917, time = 0.64\n",
      "1835.0/11635.2, train_loss = 0.02302861452102661, time = 0.60\n",
      "1836.0/11635.2, train_loss = 0.026975579261779785, time = 0.60\n",
      "1837.0/11635.2, train_loss = 0.026286969184875487, time = 0.61\n",
      "1838.0/11635.2, train_loss = 0.02406186819076538, time = 0.60\n",
      "1839.0/11635.2, train_loss = 0.02304311513900757, time = 0.61\n",
      "1840.0/11635.2, train_loss = 0.027161636352539063, time = 0.63\n",
      "1841.0/11635.2, train_loss = 0.019384053945541383, time = 0.60\n",
      "1842.0/11635.2, train_loss = 0.022331075668334963, time = 0.61\n",
      "1843.0/11635.2, train_loss = 0.019696917533874512, time = 0.61\n",
      "1844.0/11635.2, train_loss = 0.023095388412475586, time = 0.59\n",
      "1845.0/11635.2, train_loss = 0.02333094596862793, time = 0.59\n",
      "1846.0/11635.2, train_loss = 0.021720256805419922, time = 0.63\n",
      "1847.0/11635.2, train_loss = 0.019297441244125368, time = 0.60\n",
      "1848.0/11635.2, train_loss = 0.027962934970855714, time = 0.61\n",
      "1849.0/11635.2, train_loss = 0.02435119390487671, time = 0.61\n",
      "1850.0/11635.2, train_loss = 0.025318655967712402, time = 0.63\n",
      "1851.0/11635.2, train_loss = 0.023659143447875976, time = 0.61\n",
      "1852.0/11635.2, train_loss = 0.01992465019226074, time = 0.62\n",
      "1853.0/11635.2, train_loss = 0.02695913553237915, time = 0.60\n",
      "1854.0/11635.2, train_loss = 0.018658337593078615, time = 0.59\n",
      "1855.0/11635.2, train_loss = 0.021555075645446776, time = 0.59\n",
      "1856.0/11635.2, train_loss = 0.01980433940887451, time = 0.61\n",
      "1857.0/11635.2, train_loss = 0.028809285163879393, time = 0.61\n",
      "1858.0/11635.2, train_loss = 0.020147438049316405, time = 0.60\n",
      "1859.0/11635.2, train_loss = 0.026644132137298583, time = 0.63\n",
      "1860.0/11635.2, train_loss = 0.025781002044677735, time = 0.59\n",
      "1861.0/11635.2, train_loss = 0.025306074619293212, time = 0.60\n",
      "1862.0/11635.2, train_loss = 0.02384760618209839, time = 0.60\n",
      "1863.0/11635.2, train_loss = 0.017684781551361085, time = 0.60\n",
      "1864.0/11635.2, train_loss = 0.029527666568756102, time = 0.60\n",
      "1865.0/11635.2, train_loss = 0.028994300365448, time = 0.62\n",
      "1866.0/11635.2, train_loss = 0.02938929557800293, time = 0.61\n",
      "1867.0/11635.2, train_loss = 0.024045891761779785, time = 0.60\n",
      "1868.0/11635.2, train_loss = 0.029150693416595458, time = 0.60\n",
      "1869.0/11635.2, train_loss = 0.024140334129333495, time = 0.60\n",
      "1870.0/11635.2, train_loss = 0.02861011266708374, time = 0.61\n",
      "1871.0/11635.2, train_loss = 0.023667502403259277, time = 0.63\n",
      "1872.0/11635.2, train_loss = 0.01953756332397461, time = 0.60\n",
      "1873.0/11635.2, train_loss = 0.027450292110443114, time = 0.60\n",
      "1874.0/11635.2, train_loss = 0.020036544799804688, time = 0.59\n",
      "1875.0/11635.2, train_loss = 0.02538388013839722, time = 0.60\n",
      "1876.0/11635.2, train_loss = 0.02287449359893799, time = 0.61\n",
      "1877.0/11635.2, train_loss = 0.019882510900497436, time = 0.63\n",
      "1878.0/11635.2, train_loss = 0.0277383828163147, time = 0.60\n",
      "1879.0/11635.2, train_loss = 0.023301446437835695, time = 0.61\n",
      "1880.0/11635.2, train_loss = 0.02998154401779175, time = 0.61\n",
      "1881.0/11635.2, train_loss = 0.024842329025268554, time = 0.60\n",
      "1882.0/11635.2, train_loss = 0.02576693058013916, time = 0.60\n",
      "1883.0/11635.2, train_loss = 0.022019736766815186, time = 0.62\n",
      "1884.0/11635.2, train_loss = 0.019875012636184693, time = 0.61\n",
      "1885.0/11635.2, train_loss = 0.020070118904113768, time = 0.61\n",
      "1886.0/11635.2, train_loss = 0.0261012864112854, time = 0.60\n",
      "1887.0/11635.2, train_loss = 0.025655372142791746, time = 0.60\n",
      "1888.0/11635.2, train_loss = 0.022400655746459962, time = 0.60\n",
      "1889.0/11635.2, train_loss = 0.027415359020233156, time = 0.63\n",
      "1890.0/11635.2, train_loss = 0.018095638751983643, time = 0.61\n",
      "1891.0/11635.2, train_loss = 0.019517366886138917, time = 0.61\n",
      "1892.0/11635.2, train_loss = 0.019418153762817383, time = 0.62\n",
      "1893.0/11635.2, train_loss = 0.022152457237243652, time = 0.63\n",
      "1894.0/11635.2, train_loss = 0.023844404220581053, time = 0.61\n",
      "1895.0/11635.2, train_loss = 0.02447141647338867, time = 0.64\n",
      "1896.0/11635.2, train_loss = 0.023736846446990967, time = 0.68\n",
      "1897.0/11635.2, train_loss = 0.02113675117492676, time = 0.62\n",
      "1898.0/11635.2, train_loss = 0.017449859380722046, time = 0.61\n",
      "1899.0/11635.2, train_loss = 0.02582054853439331, time = 0.64\n",
      "1900.0/11635.2, train_loss = 0.022161009311676024, time = 0.61\n",
      "1901.0/11635.2, train_loss = 0.02119652509689331, time = 0.64\n",
      "1902.0/11635.2, train_loss = 0.019981662034988402, time = 0.64\n",
      "1903.0/11635.2, train_loss = 0.02391663074493408, time = 0.61\n",
      "1904.0/11635.2, train_loss = 0.02114147901535034, time = 0.62\n",
      "1905.0/11635.2, train_loss = 0.020532631874084474, time = 0.66\n",
      "1906.0/11635.2, train_loss = 0.024281182289123536, time = 0.65\n",
      "1907.0/11635.2, train_loss = 0.022407310009002687, time = 0.68\n",
      "1908.0/11635.2, train_loss = 0.017600966691970824, time = 0.64\n",
      "1909.0/11635.2, train_loss = 0.020979321002960204, time = 0.65\n",
      "1910.0/11635.2, train_loss = 0.022721505165100096, time = 0.63\n",
      "1911.0/11635.2, train_loss = 0.021036508083343505, time = 0.62\n",
      "1912.0/11635.2, train_loss = 0.01877875566482544, time = 0.65\n",
      "1913.0/11635.2, train_loss = 0.024343862533569335, time = 0.64\n",
      "1914.0/11635.2, train_loss = 0.021365957260131838, time = 0.61\n",
      "1915.0/11635.2, train_loss = 0.023983891010284423, time = 0.61\n",
      "1916.0/11635.2, train_loss = 0.02050971031188965, time = 0.64\n",
      "1917.0/11635.2, train_loss = 0.019950170516967774, time = 0.67\n",
      "1918.0/11635.2, train_loss = 0.021751136779785157, time = 0.63\n",
      "1919.0/11635.2, train_loss = 0.022784650325775146, time = 0.67\n",
      "1920.0/11635.2, train_loss = 0.020757217407226563, time = 0.64\n",
      "1921.0/11635.2, train_loss = 0.020444796085357667, time = 0.64\n",
      "1922.0/11635.2, train_loss = 0.021874027252197267, time = 0.67\n",
      "1923.0/11635.2, train_loss = 0.022077646255493164, time = 0.66\n",
      "1924.0/11635.2, train_loss = 0.02071161985397339, time = 0.63\n",
      "1925.0/11635.2, train_loss = 0.026129999160766602, time = 0.62\n",
      "1926.0/11635.2, train_loss = 0.025412232875823976, time = 0.64\n",
      "1927.0/11635.2, train_loss = 0.017803815603256227, time = 0.63\n",
      "1928.0/11635.2, train_loss = 0.01914088726043701, time = 0.64\n",
      "1929.0/11635.2, train_loss = 0.019494391679763794, time = 0.62\n",
      "1930.0/11635.2, train_loss = 0.019906288385391234, time = 0.62\n",
      "1931.0/11635.2, train_loss = 0.028404297828674315, time = 0.62\n",
      "1932.0/11635.2, train_loss = 0.01919565796852112, time = 0.65\n",
      "1933.0/11635.2, train_loss = 0.01991796612739563, time = 0.61\n",
      "1934.0/11635.2, train_loss = 0.025107245445251464, time = 0.63\n",
      "1935.0/11635.2, train_loss = 0.023579156398773192, time = 0.61\n",
      "1936.0/11635.2, train_loss = 0.020093770027160646, time = 0.61\n",
      "1937.0/11635.2, train_loss = 0.019129323959350585, time = 0.62\n",
      "1938.0/11635.2, train_loss = 0.01937143683433533, time = 0.64\n",
      "1939.0/11635.2, train_loss = 0.016975562572479248, time = 0.63\n",
      "1940.0/11635.2, train_loss = 0.017093396186828612, time = 0.62\n",
      "1941.0/11635.2, train_loss = 0.02572296380996704, time = 0.63\n",
      "1942.0/11635.2, train_loss = 0.022496647834777832, time = 0.62\n",
      "1943.0/11635.2, train_loss = 0.026592807769775392, time = 0.61\n",
      "1944.0/11635.2, train_loss = 0.03201730728149414, time = 0.63\n",
      "1945.0/11635.2, train_loss = 0.023832230567932128, time = 0.61\n",
      "1946.0/11635.2, train_loss = 0.021329309940338135, time = 0.61\n",
      "1947.0/11635.2, train_loss = 0.018707355260849, time = 0.63\n",
      "1948.0/11635.2, train_loss = 0.02320399284362793, time = 0.63\n",
      "1949.0/11635.2, train_loss = 0.021631877422332763, time = 0.62\n",
      "1950.0/11635.2, train_loss = 0.02136629104614258, time = 0.63\n",
      "1951.0/11635.2, train_loss = 0.02300473928451538, time = 0.62\n",
      "1952.0/11635.2, train_loss = 0.02366290330886841, time = 0.62\n",
      "1953.0/11635.2, train_loss = 0.02318000078201294, time = 0.61\n",
      "1954.0/11635.2, train_loss = 0.02112544536590576, time = 0.61\n",
      "1955.0/11635.2, train_loss = 0.017025002241134644, time = 0.62\n",
      "1956.0/11635.2, train_loss = 0.0247745156288147, time = 0.64\n",
      "1957.0/11635.2, train_loss = 0.022994205951690674, time = 0.60\n",
      "1958.0/11635.2, train_loss = 0.021871886253356933, time = 0.60\n",
      "1959.0/11635.2, train_loss = 0.02371524095535278, time = 0.60\n",
      "1960.0/11635.2, train_loss = 0.025704984664916993, time = 0.60\n",
      "1961.0/11635.2, train_loss = 0.01954341173171997, time = 0.61\n",
      "1962.0/11635.2, train_loss = 0.025731968879699706, time = 0.64\n",
      "1963.0/11635.2, train_loss = 0.018657335042953492, time = 0.60\n",
      "1964.0/11635.2, train_loss = 0.021094727516174316, time = 0.59\n",
      "1965.0/11635.2, train_loss = 0.025284547805786133, time = 0.60\n",
      "1966.0/11635.2, train_loss = 0.022505078315734863, time = 0.61\n",
      "1967.0/11635.2, train_loss = 0.022525465488433837, time = 0.60\n",
      "1968.0/11635.2, train_loss = 0.02328465461730957, time = 0.63\n",
      "1969.0/11635.2, train_loss = 0.023666496276855468, time = 0.61\n",
      "1970.0/11635.2, train_loss = 0.02436389207839966, time = 0.72\n",
      "1971.0/11635.2, train_loss = 0.02017601013183594, time = 0.77\n",
      "1972.0/11635.2, train_loss = 0.02940343141555786, time = 0.70\n",
      "1973.0/11635.2, train_loss = 0.022445240020751954, time = 0.74\n",
      "1974.0/11635.2, train_loss = 0.024339447021484373, time = 0.63\n",
      "1975.0/11635.2, train_loss = 0.025357885360717772, time = 0.76\n",
      "1976.0/11635.2, train_loss = 0.028316793441772462, time = 0.75\n",
      "1977.0/11635.2, train_loss = 0.019538414478302003, time = 0.73\n",
      "1978.0/11635.2, train_loss = 0.02061485767364502, time = 0.72\n",
      "1979.0/11635.2, train_loss = 0.029215643405914305, time = 0.80\n",
      "1980.0/11635.2, train_loss = 0.027654130458831788, time = 0.70\n",
      "1981.0/11635.2, train_loss = 0.027148826122283934, time = 0.63\n",
      "1982.0/11635.2, train_loss = 0.022619795799255372, time = 0.63\n",
      "1983.0/11635.2, train_loss = 0.02333700180053711, time = 0.60\n",
      "1984.0/11635.2, train_loss = 0.026898553371429445, time = 0.60\n",
      "1985.0/11635.2, train_loss = 0.018756101131439207, time = 0.61\n",
      "1986.0/11635.2, train_loss = 0.020347545146942137, time = 0.66\n",
      "1987.0/11635.2, train_loss = 0.015089759826660156, time = 0.61\n",
      "1988.0/11635.2, train_loss = 0.021773781776428223, time = 0.63\n",
      "1989.0/11635.2, train_loss = 0.02195399522781372, time = 0.66\n",
      "1990.0/11635.2, train_loss = 0.019943625926971437, time = 0.60\n",
      "1991.0/11635.2, train_loss = 0.01997225046157837, time = 0.63\n",
      "1992.0/11635.2, train_loss = 0.01728939890861511, time = 0.62\n",
      "1993.0/11635.2, train_loss = 0.022830252647399903, time = 0.64\n",
      "1994.0/11635.2, train_loss = 0.021893060207366942, time = 0.78\n",
      "1995.0/11635.2, train_loss = 0.019318296909332275, time = 0.79\n",
      "1996.0/11635.2, train_loss = 0.02293280601501465, time = 0.79\n",
      "1997.0/11635.2, train_loss = 0.02024799108505249, time = 0.81\n",
      "1998.0/11635.2, train_loss = 0.021810529232025148, time = 0.62\n",
      "1999.0/11635.2, train_loss = 0.022018659114837646, time = 0.64\n",
      "2000.0/11635.2, train_loss = 0.028000755310058592, time = 0.61\n",
      "2001.0/11635.2, train_loss = 0.022693898677825928, time = 0.63\n",
      "2002.0/11635.2, train_loss = 0.020752789974212645, time = 0.61\n",
      "2003.0/11635.2, train_loss = 0.021499626636505127, time = 0.61\n",
      "2004.0/11635.2, train_loss = 0.019554374217987062, time = 0.65\n",
      "2005.0/11635.2, train_loss = 0.021490888595581056, time = 0.65\n",
      "2006.0/11635.2, train_loss = 0.019554601907730104, time = 0.62\n",
      "2007.0/11635.2, train_loss = 0.022208352088928223, time = 0.62\n",
      "2008.0/11635.2, train_loss = 0.022810847759246827, time = 0.61\n",
      "2009.0/11635.2, train_loss = 0.018850411176681518, time = 0.59\n",
      "2010.0/11635.2, train_loss = 0.0157143497467041, time = 0.62\n",
      "2011.0/11635.2, train_loss = 0.023456838130950928, time = 0.65\n",
      "2012.0/11635.2, train_loss = 0.019281047582626342, time = 0.60\n",
      "2013.0/11635.2, train_loss = 0.019829858541488648, time = 0.61\n",
      "2014.0/11635.2, train_loss = 0.01761104702949524, time = 0.60\n",
      "2015.0/11635.2, train_loss = 0.024268085956573485, time = 0.62\n",
      "2016.0/11635.2, train_loss = 0.02331010580062866, time = 0.64\n",
      "2017.0/11635.2, train_loss = 0.024945080280303955, time = 0.64\n",
      "2018.0/11635.2, train_loss = 0.01602698564529419, time = 0.66\n",
      "2019.0/11635.2, train_loss = 0.022701909542083742, time = 0.64\n",
      "2020.0/11635.2, train_loss = 0.02180513143539429, time = 0.69\n",
      "2021.0/11635.2, train_loss = 0.016125370264053345, time = 0.74\n",
      "2022.0/11635.2, train_loss = 0.018133103847503662, time = 0.79\n",
      "2023.0/11635.2, train_loss = 0.023102817535400392, time = 0.78\n",
      "2024.0/11635.2, train_loss = 0.01621624231338501, time = 0.68\n",
      "2025.0/11635.2, train_loss = 0.018444474935531616, time = 0.60\n",
      "2026.0/11635.2, train_loss = 0.012284342050552368, time = 0.61\n",
      "2027.0/11635.2, train_loss = 0.01634840965270996, time = 0.62\n",
      "2028.0/11635.2, train_loss = 0.013226369619369507, time = 0.62\n",
      "2029.0/11635.2, train_loss = 0.024961204528808595, time = 0.63\n",
      "2030.0/11635.2, train_loss = 0.019379448890686036, time = 0.61\n",
      "2031.0/11635.2, train_loss = 0.019812178611755372, time = 0.63\n",
      "2032.0/11635.2, train_loss = 0.020651602745056154, time = 0.60\n",
      "2033.0/11635.2, train_loss = 0.01642150282859802, time = 0.63\n",
      "2034.0/11635.2, train_loss = 0.02342301368713379, time = 0.62\n",
      "2035.0/11635.2, train_loss = 0.017167210578918457, time = 0.63\n",
      "2036.0/11635.2, train_loss = 0.013149796724319459, time = 0.61\n",
      "2037.0/11635.2, train_loss = 0.023997678756713867, time = 0.60\n",
      "2038.0/11635.2, train_loss = 0.014736242294311523, time = 0.61\n",
      "2039.0/11635.2, train_loss = 0.017798733711242676, time = 0.60\n",
      "2040.0/11635.2, train_loss = 0.01875727415084839, time = 0.61\n",
      "2041.0/11635.2, train_loss = 0.02296900510787964, time = 0.64\n",
      "2042.0/11635.2, train_loss = 0.026763033866882325, time = 0.60\n",
      "2043.0/11635.2, train_loss = 0.021077685356140137, time = 0.61\n",
      "2044.0/11635.2, train_loss = 0.021323838233947755, time = 0.60\n",
      "2045.0/11635.2, train_loss = 0.017462483644485473, time = 0.61\n",
      "2046.0/11635.2, train_loss = 0.016801446676254272, time = 0.65\n",
      "2047.0/11635.2, train_loss = 0.015088645219802856, time = 0.70\n",
      "2048.0/11635.2, train_loss = 0.021309001445770262, time = 0.68\n",
      "2049.0/11635.2, train_loss = 0.02285690784454346, time = 0.61\n",
      "2050.0/11635.2, train_loss = 0.01979072093963623, time = 0.64\n",
      "2051.0/11635.2, train_loss = 0.024383463859558106, time = 0.61\n",
      "2052.0/11635.2, train_loss = 0.023194546699523925, time = 0.67\n",
      "2053.0/11635.2, train_loss = 0.021555314064025877, time = 0.71\n",
      "2054.0/11635.2, train_loss = 0.02019249677658081, time = 0.68\n",
      "2055.0/11635.2, train_loss = 0.018656005859375, time = 0.65\n",
      "2056.0/11635.2, train_loss = 0.020650496482849123, time = 0.64\n",
      "2057.0/11635.2, train_loss = 0.01768965244293213, time = 0.65\n",
      "2058.0/11635.2, train_loss = 0.02029385566711426, time = 0.64\n",
      "2059.0/11635.2, train_loss = 0.01852373480796814, time = 0.67\n",
      "2060.0/11635.2, train_loss = 0.021650424003601076, time = 0.69\n",
      "2061.0/11635.2, train_loss = 0.01795957326889038, time = 0.68\n",
      "2062.0/11635.2, train_loss = 0.022585608959198, time = 0.66\n",
      "2063.0/11635.2, train_loss = 0.014218090772628785, time = 0.61\n",
      "2064.0/11635.2, train_loss = 0.017676451206207276, time = 0.62\n",
      "2065.0/11635.2, train_loss = 0.01613758325576782, time = 0.61\n",
      "2066.0/11635.2, train_loss = 0.01345786452293396, time = 0.65\n",
      "2067.0/11635.2, train_loss = 0.0156308114528656, time = 0.67\n",
      "2068.0/11635.2, train_loss = 0.02009892225265503, time = 0.67\n",
      "2069.0/11635.2, train_loss = 0.01975311875343323, time = 0.67\n",
      "2070.0/11635.2, train_loss = 0.017931236028671263, time = 0.62\n",
      "2071.0/11635.2, train_loss = 0.020781195163726805, time = 0.66\n",
      "2072.0/11635.2, train_loss = 0.017118862867355346, time = 0.65\n",
      "2073.0/11635.2, train_loss = 0.014658068418502807, time = 0.61\n",
      "2074.0/11635.2, train_loss = 0.016854809522628786, time = 0.61\n",
      "2075.0/11635.2, train_loss = 0.013282409906387328, time = 0.61\n",
      "2076.0/11635.2, train_loss = 0.017295538187026976, time = 0.60\n",
      "2077.0/11635.2, train_loss = 0.019827797412872314, time = 0.61\n",
      "2078.0/11635.2, train_loss = 0.01694626212120056, time = 0.63\n",
      "2079.0/11635.2, train_loss = 0.018287826776504517, time = 0.62\n",
      "2080.0/11635.2, train_loss = 0.01331074833869934, time = 0.61\n",
      "2081.0/11635.2, train_loss = 0.017238708734512328, time = 0.61\n",
      "2082.0/11635.2, train_loss = 0.018605676889419557, time = 0.60\n",
      "2083.0/11635.2, train_loss = 0.02113500118255615, time = 0.62\n",
      "2084.0/11635.2, train_loss = 0.01802364468574524, time = 0.64\n",
      "2085.0/11635.2, train_loss = 0.016161056756973265, time = 0.60\n",
      "2086.0/11635.2, train_loss = 0.022270059585571288, time = 0.61\n",
      "2087.0/11635.2, train_loss = 0.016293832063674928, time = 0.62\n",
      "2088.0/11635.2, train_loss = 0.03301914215087891, time = 0.61\n",
      "2089.0/11635.2, train_loss = 0.02148249387741089, time = 0.61\n",
      "2090.0/11635.2, train_loss = 0.01278670072555542, time = 0.62\n",
      "2091.0/11635.2, train_loss = 0.01566771149635315, time = 0.61\n",
      "2092.0/11635.2, train_loss = 0.01980689525604248, time = 0.61\n",
      "2093.0/11635.2, train_loss = 0.012977808713912964, time = 0.61\n",
      "2094.0/11635.2, train_loss = 0.021198246479034424, time = 0.60\n",
      "2095.0/11635.2, train_loss = 0.017398122549057007, time = 0.61\n",
      "2096.0/11635.2, train_loss = 0.01698724031448364, time = 0.63\n",
      "2097.0/11635.2, train_loss = 0.012955964803695678, time = 0.61\n",
      "2098.0/11635.2, train_loss = 0.022885637283325197, time = 0.61\n",
      "2099.0/11635.2, train_loss = 0.01640050530433655, time = 0.60\n",
      "2100.0/11635.2, train_loss = 0.015172245502471924, time = 0.61\n",
      "2101.0/11635.2, train_loss = 0.014380866289138794, time = 0.60\n",
      "2102.0/11635.2, train_loss = 0.0220867919921875, time = 0.65\n",
      "2103.0/11635.2, train_loss = 0.02075855255126953, time = 0.63\n",
      "2104.0/11635.2, train_loss = 0.019656041860580443, time = 0.61\n",
      "2105.0/11635.2, train_loss = 0.021701815128326415, time = 0.60\n",
      "2106.0/11635.2, train_loss = 0.017502466440200804, time = 0.61\n",
      "2107.0/11635.2, train_loss = 0.019831275939941405, time = 0.59\n",
      "2108.0/11635.2, train_loss = 0.025320005416870118, time = 0.63\n",
      "2109.0/11635.2, train_loss = 0.015308218002319336, time = 0.61\n",
      "2110.0/11635.2, train_loss = 0.01958763599395752, time = 0.61\n",
      "2111.0/11635.2, train_loss = 0.02035832405090332, time = 0.61\n",
      "2112.0/11635.2, train_loss = 0.016724021434783937, time = 0.61\n",
      "2113.0/11635.2, train_loss = 0.021582896709442138, time = 0.61\n",
      "2114.0/11635.2, train_loss = 0.01934281587600708, time = 0.63\n",
      "2115.0/11635.2, train_loss = 0.021795165538787842, time = 0.60\n",
      "2116.0/11635.2, train_loss = 0.01897637128829956, time = 0.61\n",
      "2117.0/11635.2, train_loss = 0.014353450536727905, time = 0.61\n",
      "2118.0/11635.2, train_loss = 0.02192829370498657, time = 0.61\n",
      "2119.0/11635.2, train_loss = 0.019342352151870728, time = 0.61\n",
      "2120.0/11635.2, train_loss = 0.02579929828643799, time = 0.63\n",
      "2121.0/11635.2, train_loss = 0.021919872760772705, time = 0.60\n",
      "2122.0/11635.2, train_loss = 0.020178868770599365, time = 0.60\n",
      "2123.0/11635.2, train_loss = 0.01948114275932312, time = 0.61\n",
      "2124.0/11635.2, train_loss = 0.015581603050231934, time = 0.62\n",
      "2125.0/11635.2, train_loss = 0.01736022114753723, time = 0.61\n",
      "2126.0/11635.2, train_loss = 0.017261931896209715, time = 0.61\n",
      "2127.0/11635.2, train_loss = 0.018253152370452882, time = 0.63\n",
      "2128.0/11635.2, train_loss = 0.016963248252868653, time = 0.61\n",
      "2129.0/11635.2, train_loss = 0.019516725540161133, time = 0.61\n",
      "2130.0/11635.2, train_loss = 0.0167099404335022, time = 0.61\n",
      "2131.0/11635.2, train_loss = 0.018666634559631346, time = 0.60\n",
      "2132.0/11635.2, train_loss = 0.01780511736869812, time = 0.60\n",
      "2133.0/11635.2, train_loss = 0.020610027313232422, time = 0.63\n",
      "2134.0/11635.2, train_loss = 0.012847229242324829, time = 0.60\n",
      "2135.0/11635.2, train_loss = 0.017581073045730592, time = 0.61\n",
      "2136.0/11635.2, train_loss = 0.0197049617767334, time = 0.61\n",
      "2137.0/11635.2, train_loss = 0.019672592878341676, time = 0.61\n",
      "2138.0/11635.2, train_loss = 0.019509130716323854, time = 0.60\n",
      "2139.0/11635.2, train_loss = 0.022480316162109375, time = 0.63\n",
      "2140.0/11635.2, train_loss = 0.01594385027885437, time = 0.61\n",
      "2141.0/11635.2, train_loss = 0.029124860763549806, time = 0.62\n",
      "2142.0/11635.2, train_loss = 0.02327230215072632, time = 0.60\n",
      "2143.0/11635.2, train_loss = 0.01635221242904663, time = 0.61\n",
      "2144.0/11635.2, train_loss = 0.018057321310043336, time = 0.62\n",
      "2145.0/11635.2, train_loss = 0.017127847671508788, time = 0.63\n",
      "2146.0/11635.2, train_loss = 0.019729313850402833, time = 0.61\n",
      "2147.0/11635.2, train_loss = 0.019429560899734497, time = 0.61\n",
      "2148.0/11635.2, train_loss = 0.022168653011322023, time = 0.61\n",
      "2149.0/11635.2, train_loss = 0.02665130853652954, time = 0.61\n",
      "2150.0/11635.2, train_loss = 0.01777380585670471, time = 0.60\n",
      "2151.0/11635.2, train_loss = 0.01784872531890869, time = 0.62\n",
      "2152.0/11635.2, train_loss = 0.020885975360870362, time = 0.61\n",
      "2153.0/11635.2, train_loss = 0.022500452995300294, time = 0.61\n",
      "2154.0/11635.2, train_loss = 0.014324032068252564, time = 0.60\n",
      "2155.0/11635.2, train_loss = 0.01601580023765564, time = 0.60\n",
      "2156.0/11635.2, train_loss = 0.02245767116546631, time = 0.60\n",
      "2157.0/11635.2, train_loss = 0.016742981672286987, time = 0.63\n",
      "2158.0/11635.2, train_loss = 0.015079473257064819, time = 0.61\n",
      "2159.0/11635.2, train_loss = 0.02172401189804077, time = 0.61\n",
      "2160.0/11635.2, train_loss = 0.0194459867477417, time = 0.62\n",
      "2161.0/11635.2, train_loss = 0.01766426920890808, time = 0.62\n",
      "2162.0/11635.2, train_loss = 0.012725675106048584, time = 0.60\n",
      "2163.0/11635.2, train_loss = 0.021223189830780028, time = 0.62\n",
      "2164.0/11635.2, train_loss = 0.01700090169906616, time = 0.62\n",
      "2165.0/11635.2, train_loss = 0.01583357334136963, time = 0.61\n",
      "2166.0/11635.2, train_loss = 0.015680892467498778, time = 0.61\n",
      "2167.0/11635.2, train_loss = 0.01917062759399414, time = 0.61\n",
      "2168.0/11635.2, train_loss = 0.018525664806365968, time = 0.61\n",
      "2169.0/11635.2, train_loss = 0.0178052020072937, time = 0.63\n",
      "2170.0/11635.2, train_loss = 0.01974865198135376, time = 0.60\n",
      "2171.0/11635.2, train_loss = 0.01376520037651062, time = 0.60\n",
      "2172.0/11635.2, train_loss = 0.015045032501220704, time = 0.62\n",
      "2173.0/11635.2, train_loss = 0.01958459973335266, time = 0.60\n",
      "2174.0/11635.2, train_loss = 0.020255329608917235, time = 0.60\n",
      "2175.0/11635.2, train_loss = 0.013432326316833497, time = 0.62\n",
      "2176.0/11635.2, train_loss = 0.018413045406341554, time = 0.61\n",
      "2177.0/11635.2, train_loss = 0.019324049949645997, time = 0.61\n",
      "2178.0/11635.2, train_loss = 0.01657893419265747, time = 0.65\n",
      "2179.0/11635.2, train_loss = 0.02173724889755249, time = 0.62\n",
      "2180.0/11635.2, train_loss = 0.014349043369293213, time = 0.62\n",
      "2181.0/11635.2, train_loss = 0.01467673659324646, time = 0.64\n",
      "2182.0/11635.2, train_loss = 0.01772377848625183, time = 0.60\n",
      "2183.0/11635.2, train_loss = 0.014191384315490723, time = 0.60\n",
      "2184.0/11635.2, train_loss = 0.020507450103759765, time = 0.61\n",
      "2185.0/11635.2, train_loss = 0.01490380883216858, time = 0.61\n",
      "2186.0/11635.2, train_loss = 0.021667520999908447, time = 0.61\n",
      "2187.0/11635.2, train_loss = 0.012576313018798828, time = 0.64\n",
      "2188.0/11635.2, train_loss = 0.02082754611968994, time = 0.60\n",
      "2189.0/11635.2, train_loss = 0.018968971967697142, time = 0.61\n",
      "2190.0/11635.2, train_loss = 0.020322725772857667, time = 0.62\n",
      "2191.0/11635.2, train_loss = 0.02707439661026001, time = 0.61\n",
      "2192.0/11635.2, train_loss = 0.0225071382522583, time = 0.61\n",
      "2193.0/11635.2, train_loss = 0.02792320966720581, time = 0.62\n",
      "2194.0/11635.2, train_loss = 0.019933390617370605, time = 0.63\n",
      "2195.0/11635.2, train_loss = 0.022970175743103026, time = 0.61\n",
      "2196.0/11635.2, train_loss = 0.02345200300216675, time = 0.61\n",
      "2197.0/11635.2, train_loss = 0.010774606466293335, time = 0.60\n",
      "2198.0/11635.2, train_loss = 0.017931032180786132, time = 0.62\n",
      "2199.0/11635.2, train_loss = 0.017335753440856933, time = 0.61\n",
      "2200.0/11635.2, train_loss = 0.014595308303833009, time = 0.67\n",
      "2201.0/11635.2, train_loss = 0.011471145153045655, time = 0.67\n",
      "2202.0/11635.2, train_loss = 0.021274702548980715, time = 0.62\n",
      "2203.0/11635.2, train_loss = 0.02104055404663086, time = 0.61\n",
      "2204.0/11635.2, train_loss = 0.01457332968711853, time = 0.61\n",
      "2205.0/11635.2, train_loss = 0.015154132843017578, time = 0.61\n",
      "2206.0/11635.2, train_loss = 0.01605116844177246, time = 0.63\n",
      "2207.0/11635.2, train_loss = 0.017271664142608643, time = 0.60\n",
      "2208.0/11635.2, train_loss = 0.017673202753067017, time = 0.60\n",
      "2209.0/11635.2, train_loss = 0.022756366729736327, time = 0.61\n",
      "2210.0/11635.2, train_loss = 0.020003626346588133, time = 0.62\n",
      "2211.0/11635.2, train_loss = 0.01564438819885254, time = 0.61\n",
      "2212.0/11635.2, train_loss = 0.015926642417907713, time = 0.63\n",
      "2213.0/11635.2, train_loss = 0.021672816276550294, time = 0.61\n",
      "2214.0/11635.2, train_loss = 0.014557454586029053, time = 0.60\n",
      "2215.0/11635.2, train_loss = 0.01650847673416138, time = 0.61\n",
      "2216.0/11635.2, train_loss = 0.01485032081604004, time = 0.62\n",
      "2217.0/11635.2, train_loss = 0.020285799503326415, time = 0.61\n",
      "2218.0/11635.2, train_loss = 0.01546520709991455, time = 0.63\n",
      "2219.0/11635.2, train_loss = 0.020033934116363526, time = 0.62\n",
      "2220.0/11635.2, train_loss = 0.018121368885040283, time = 0.61\n",
      "2221.0/11635.2, train_loss = 0.01484464406967163, time = 0.61\n",
      "2222.0/11635.2, train_loss = 0.017896794080734253, time = 0.61\n",
      "2223.0/11635.2, train_loss = 0.01908048748970032, time = 0.60\n",
      "2224.0/11635.2, train_loss = 0.019042946100234985, time = 0.63\n",
      "2225.0/11635.2, train_loss = 0.016863638162612916, time = 0.61\n",
      "2226.0/11635.2, train_loss = 0.019987211227416993, time = 0.61\n",
      "2227.0/11635.2, train_loss = 0.016348387002944945, time = 0.60\n",
      "2228.0/11635.2, train_loss = 0.019412426948547362, time = 0.61\n",
      "2229.0/11635.2, train_loss = 0.012342727184295655, time = 0.61\n",
      "2230.0/11635.2, train_loss = 0.019572271108627318, time = 0.65\n",
      "2231.0/11635.2, train_loss = 0.016765117645263672, time = 0.61\n",
      "2232.0/11635.2, train_loss = 0.018184683322906493, time = 0.61\n",
      "2233.0/11635.2, train_loss = 0.015617802143096923, time = 0.62\n",
      "2234.0/11635.2, train_loss = 0.012693895101547241, time = 0.60\n",
      "2235.0/11635.2, train_loss = 0.025753564834594726, time = 0.61\n",
      "2236.0/11635.2, train_loss = 0.020288374423980713, time = 0.63\n",
      "2237.0/11635.2, train_loss = 0.01936489939689636, time = 0.61\n",
      "2238.0/11635.2, train_loss = 0.01556716561317444, time = 0.62\n",
      "2239.0/11635.2, train_loss = 0.016719647645950318, time = 0.61\n",
      "2240.0/11635.2, train_loss = 0.02353459358215332, time = 0.61\n",
      "2241.0/11635.2, train_loss = 0.015654159784317015, time = 0.62\n",
      "2242.0/11635.2, train_loss = 0.012768054008483886, time = 0.64\n",
      "2243.0/11635.2, train_loss = 0.015398118495941162, time = 0.60\n",
      "2244.0/11635.2, train_loss = 0.020715074539184572, time = 0.61\n",
      "2245.0/11635.2, train_loss = 0.017570558786392212, time = 0.61\n",
      "2246.0/11635.2, train_loss = 0.022562532424926757, time = 0.60\n",
      "2247.0/11635.2, train_loss = 0.015733089447021485, time = 0.60\n",
      "2248.0/11635.2, train_loss = 0.01627949833869934, time = 0.63\n",
      "2249.0/11635.2, train_loss = 0.018929436206817626, time = 0.61\n",
      "2250.0/11635.2, train_loss = 0.01671255588531494, time = 0.62\n",
      "2251.0/11635.2, train_loss = 0.013551156520843505, time = 0.60\n",
      "2252.0/11635.2, train_loss = 0.014168314933776856, time = 0.61\n",
      "2253.0/11635.2, train_loss = 0.01950581431388855, time = 0.61\n",
      "2254.0/11635.2, train_loss = 0.017390938997268676, time = 0.63\n",
      "2255.0/11635.2, train_loss = 0.018978466987609865, time = 0.60\n",
      "2256.0/11635.2, train_loss = 0.014908432960510254, time = 0.61\n",
      "2257.0/11635.2, train_loss = 0.014813748598098754, time = 0.61\n",
      "2258.0/11635.2, train_loss = 0.01653852581977844, time = 0.63\n",
      "2259.0/11635.2, train_loss = 0.015669628381729125, time = 0.61\n",
      "2260.0/11635.2, train_loss = 0.015966814756393433, time = 0.61\n",
      "2261.0/11635.2, train_loss = 0.011470571756362916, time = 0.61\n",
      "2262.0/11635.2, train_loss = 0.017672300338745117, time = 0.61\n",
      "2263.0/11635.2, train_loss = 0.010660520792007445, time = 0.61\n",
      "2264.0/11635.2, train_loss = 0.011433651447296142, time = 0.60\n",
      "2265.0/11635.2, train_loss = 0.015518261194229126, time = 0.62\n",
      "2266.0/11635.2, train_loss = 0.01780982255935669, time = 0.62\n",
      "2267.0/11635.2, train_loss = 0.011235361099243163, time = 0.63\n",
      "2268.0/11635.2, train_loss = 0.01518552541732788, time = 0.61\n",
      "2269.0/11635.2, train_loss = 0.0107729172706604, time = 0.61\n",
      "2270.0/11635.2, train_loss = 0.015273847579956056, time = 0.61\n",
      "2271.0/11635.2, train_loss = 0.018279175758361816, time = 0.60\n",
      "2272.0/11635.2, train_loss = 0.016753947734832762, time = 0.61\n",
      "2273.0/11635.2, train_loss = 0.022018954753875733, time = 0.63\n",
      "2274.0/11635.2, train_loss = 0.020134825706481934, time = 0.62\n",
      "2275.0/11635.2, train_loss = 0.021454644203186036, time = 0.60\n",
      "2276.0/11635.2, train_loss = 0.021994507312774657, time = 0.64\n",
      "2277.0/11635.2, train_loss = 0.022953245639801025, time = 0.61\n",
      "2278.0/11635.2, train_loss = 0.01408460021018982, time = 0.61\n",
      "2279.0/11635.2, train_loss = 0.01599623084068298, time = 0.64\n",
      "2280.0/11635.2, train_loss = 0.02140944719314575, time = 0.62\n",
      "2281.0/11635.2, train_loss = 0.014959980249404908, time = 0.60\n",
      "2282.0/11635.2, train_loss = 0.02512730360031128, time = 0.61\n",
      "2283.0/11635.2, train_loss = 0.016173495054244993, time = 0.61\n",
      "2284.0/11635.2, train_loss = 0.01614582061767578, time = 0.60\n",
      "2285.0/11635.2, train_loss = 0.01750870227813721, time = 0.62\n",
      "2286.0/11635.2, train_loss = 0.01807168245315552, time = 0.61\n",
      "2287.0/11635.2, train_loss = 0.01690062165260315, time = 0.61\n",
      "2288.0/11635.2, train_loss = 0.012295358180999756, time = 0.63\n",
      "2289.0/11635.2, train_loss = 0.014224128723144531, time = 0.61\n",
      "2290.0/11635.2, train_loss = 0.011559749841690064, time = 0.62\n",
      "2291.0/11635.2, train_loss = 0.014923923015594483, time = 0.63\n",
      "2292.0/11635.2, train_loss = 0.009220378994941712, time = 0.61\n",
      "2293.0/11635.2, train_loss = 0.016168148517608644, time = 0.60\n",
      "2294.0/11635.2, train_loss = 0.01624466896057129, time = 0.61\n",
      "2295.0/11635.2, train_loss = 0.01392659068107605, time = 0.61\n",
      "2296.0/11635.2, train_loss = 0.019926848411560057, time = 0.64\n",
      "2297.0/11635.2, train_loss = 0.014395205974578858, time = 0.66\n",
      "2298.0/11635.2, train_loss = 0.018890204429626464, time = 0.62\n",
      "2299.0/11635.2, train_loss = 0.01772178053855896, time = 0.61\n",
      "2300.0/11635.2, train_loss = 0.014111557006835938, time = 0.61\n",
      "2301.0/11635.2, train_loss = 0.014151428937911987, time = 0.61\n",
      "2302.0/11635.2, train_loss = 0.017624332904815673, time = 0.64\n",
      "2303.0/11635.2, train_loss = 0.012411675453186034, time = 0.63\n",
      "2304.0/11635.2, train_loss = 0.016900340318679808, time = 0.61\n",
      "2305.0/11635.2, train_loss = 0.016334961652755737, time = 0.66\n",
      "2306.0/11635.2, train_loss = 0.016364376544952392, time = 0.68\n",
      "2307.0/11635.2, train_loss = 0.011942989826202392, time = 0.60\n",
      "2308.0/11635.2, train_loss = 0.011185696125030517, time = 0.62\n",
      "2309.0/11635.2, train_loss = 0.015728816986083985, time = 0.63\n",
      "2310.0/11635.2, train_loss = 0.013569403886795044, time = 0.60\n",
      "2311.0/11635.2, train_loss = 0.014472714662551879, time = 0.61\n",
      "2312.0/11635.2, train_loss = 0.013887367248535155, time = 0.62\n",
      "2313.0/11635.2, train_loss = 0.014271005392074584, time = 0.60\n",
      "2314.0/11635.2, train_loss = 0.012209420204162597, time = 0.62\n",
      "2315.0/11635.2, train_loss = 0.015752317905426024, time = 0.65\n",
      "2316.0/11635.2, train_loss = 0.017345629930496216, time = 0.65\n",
      "2317.0/11635.2, train_loss = 0.017443249225616454, time = 0.63\n",
      "2318.0/11635.2, train_loss = 0.02216177701950073, time = 0.61\n",
      "2319.0/11635.2, train_loss = 0.016973387002944946, time = 0.61\n",
      "2320.0/11635.2, train_loss = 0.014548372030258178, time = 0.61\n",
      "2321.0/11635.2, train_loss = 0.017189892530441283, time = 0.64\n",
      "2322.0/11635.2, train_loss = 0.01635648846626282, time = 0.66\n",
      "2323.0/11635.2, train_loss = 0.01249401569366455, time = 0.62\n",
      "2324.0/11635.2, train_loss = 0.020979151725769044, time = 0.62\n",
      "2325.0/11635.2, train_loss = 0.020731229782104493, time = 0.61\n",
      "2326.0/11635.2, train_loss = 0.01859109878540039, time = 0.61\n",
      "2327.0/11635.2, train_loss = 0.015966570377349852, time = 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohgushimasaya/.pyenv/versions/3.4.1/lib/python3.4/site-packages/ipykernel/__main__.py:3: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n",
      "/Users/ohgushimasaya/.pyenv/versions/3.4.1/lib/python3.4/site-packages/ipykernel/__main__.py:5: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(jump * n_epochs)):\n",
    "    x_batch = np.array([train_data[(jump * j + i) % whole_len]\n",
    "                        for j in range(batchsize)])\n",
    "    y_batch = np.array([train_data[(jump * j + i + 1) % whole_len]\n",
    "                        for j in range(batchsize)])\n",
    "\n",
    "    state, loss_i = model.forward_one_step(x_batch, y_batch, state, dropout_ratio=0.5)\n",
    "    accum_loss   += loss_i\n",
    "\n",
    "    if (i + 1) % bprop_len == 0:  # Run truncated BPTT\n",
    "        now = time.time()\n",
    "        print('{}/{}, train_loss = {}, time = {:.2f}'.format((i+1)/bprop_len, jump, accum_loss.data / bprop_len, now-cur_at))\n",
    "        cur_at = now\n",
    "\n",
    "        optimizer.zero_grads()\n",
    "        accum_loss.backward()\n",
    "        accum_loss.unchain_backward()  # truncate\n",
    "        accum_loss = Variable(np.zeros((), dtype=np.float32))\n",
    "\n",
    "        optimizer.clip_grads(grad_clip)\n",
    "        optimizer.update()\n",
    "\n",
    "    if (i + 1) % 10000 == 0:    \n",
    "        fn = ('%s/charrnn_epoch_%.2f.chainermodel' % (checkpoint_dir, float(i)/jump))\n",
    "        pickle.dump(copy.deepcopy(model).to_cpu(), open(fn, 'wb'))\n",
    "\n",
    "    if (i + 1) % jump == 0:\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch >= 10:\n",
    "            optimizer.lr *= 0.97\n",
    "            print('decayed learning rate by a factor {} to {}'.format(0.97, optimizer.lr))\n",
    "\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習したデータを再度入力\n",
    "* 入力データを辞書として保持\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# load vocabulary\n",
    "vocab = {}\n",
    "def load_predict_data(filename):\n",
    "    global vocab, n_vocab\n",
    "    #words = open(filename).read().replace('\\n', '<eos>').strip().split()\n",
    "    words = open(filename).read().strip().split()\n",
    "    dataset = np.ndarray((len(words),), dtype=np.int32)\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "        dataset[i] = vocab[word]\n",
    "    return dataset\n",
    "\n",
    "train_data = load_predict_data('data_hands_on/linux_source.c')\n",
    "\n",
    "ivocab = {}\n",
    "ivocab = {v:k for k, v in vocab.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 学習したモデルを取得\n",
    "* モデルからユニット数を取得\n",
    "* 最初の空文字を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = pickle.load(open(\"cv/charrnn_epoch_20.62.chainermodel\", 'rb'))\n",
    "n_units = model.embed.W.shape[1]\n",
    "\n",
    "# initialize generator\n",
    "state = make_initial_state(n_units, batchsize=1, train=False)\n",
    "\n",
    "prev_char = np.array([0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習したモデルを利用して文字の予測を行なう。\n",
    "* 予測で出力された文字と状態を次の入力に使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this this this this is will static *sys e->edd, static */ after int sz *sys 4); need e->edd, int sz (bit << num_data_in), e->edd, e->edd, static anything *sys *sys e->edd, static int (bit << e->edd, static e->edd, static int (bit << e->edd, static e->edd, static int (bit << e->edd, static void anything int sz = << e->edd, static int anything int sz int e->edd, static int e->edd, int sz (bit << num_data_in), e->edd, e->edd, static set, anything buf[0] ~((unsigned *FIRST_COMPAT); If this this num_data_in), e->edd, static set, will need anything = need anything static void anything */ action_new_function(struct */ */ this *sys need after int we this lel_idx_bit action_new_function(struct set, that this * ~((unsigned If this this this this is will static *sys e->edd, static */ after int sz *sys 4); need (bit << num_data_in), e->edd, static void *sys need sz (bit << if e->edd, e->edd, e->edd, static anything ~((unsigned *FIRST_COMPAT); If this this num_data_in), e->edd, static set, anything buf[0] = e->edd, static */ after int sz *sys 4); int e->edd, static int (bit << e->edd, e->edd, static set, anything buf[0] ~((unsigned *FIRST_COMPAT); If this this num_data_in), e->edd, static set, will need anything = need anything static void anything */ action_new_function(struct */ */ this *sys will static is anything (bit << num_data_in), anything void anything action_new_function(struct static ~((unsigned this * this return this this this 0; this do_command(struct ~((unsigned *FIRST_COMPAT); If this this this this will is this *sys e->edd, static set, this 0xFFFFFFFF this 0xFFFFFFFF this min(min(multi_run ~((unsigned this will this s->len, this do_command(struct ~((unsigned this long) If this this this this will is this *sys int e->edd, static set, this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); this will this s->len, this do_command(struct ~((unsigned this will tty_struct tty_struct ~((unsigned If this this this this this this frame_pos, will frame_pos, anything *sys 0xFFFFFFFF this *sys will static = e->edd, static set, anything this 0xFFFFFFFF this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run ~((unsigned *FIRST_COMPAT); If this this this this will is this *sys int e->edd, static set, this 0xFFFFFFFF this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run ~((unsigned *FIRST_COMPAT); If this this this this this this frame_pos, will frame_pos, anything = need anything set, = need anything set, = need anything set, = need anything set, ~((unsigned *FIRST_COMPAT); If this this frame_pos, will set, this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); If this this this this num_data_in), will void this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); this will this s->len, this do_command(struct *FIRST_COMPAT); this will tty_struct tty_struct ~((unsigned If this this this this this this frame_pos, will frame_pos, anything *sys 0xFFFFFFFF this *sys will static = e->edd, static set, anything this 0xFFFFFFFF this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run ~((unsigned *FIRST_COMPAT); If this this this this will is this *sys int e->edd, static set, this 0xFFFFFFFF this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run ~((unsigned *FIRST_COMPAT); If this this this this this this frame_pos, will frame_pos, anything = need anything set, = need anything set, = need anything set, = need anything set, ~((unsigned *FIRST_COMPAT); If this this frame_pos, will set, this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); If this this this this num_data_in), will void this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); this will this s->len, this do_command(struct *FIRST_COMPAT); this will tty_struct tty_struct ~((unsigned If this this this this this this frame_pos, will frame_pos, anything *sys 0xFFFFFFFF this *sys will static = e->edd, static set, anything this 0xFFFFFFFF this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run ~((unsigned *FIRST_COMPAT); If this this this this will is this *sys int e->edd, static set, this 0xFFFFFFFF this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run is is is is is is is is tty) ~((unsigned this 4); this min(min(multi_run buf[0] min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run min(min(multi_run ~((unsigned *FIRST_COMPAT); If this this this this this this frame_pos, will frame_pos, anything = need anything set, = need anything set, = need anything set, = need anything set, ~((unsigned *FIRST_COMPAT); If this this frame_pos, will set, this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); If this this this this num_data_in), will void this 0xFFFFFFFF this min(min(multi_run *FIRST_COMPAT); this will this s->len, this do_command(struct *FIRST_COMPAT); this will tty_struct tty_struct ~((unsigned If this this this this this this frame_pos, will frame_pos, anything *sys 0xFFFFFFFF this *sys will static = e->edd, static set, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    state, prob = model.predict(prev_char, state)\n",
    "\n",
    "    index = np.argmax(cuda.to_cpu(prob.data))\n",
    "    sys.stdout.write(ivocab[index] + \" \")\n",
    "\n",
    "    prev_char = np.array([index], dtype=np.int32)\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
