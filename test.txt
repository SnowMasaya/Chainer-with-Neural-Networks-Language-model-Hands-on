#Big Data Conference

##機械学習を利用している領域

スパム判定

商品推薦

コンピューター将棋・囲碁・チェス
：完全読みは探索的な問題で出来ない。機械学習で

##機械学習のメリット

大量処理（並列、高性能
高速（人間の反応速度を超える
高精度（人間を超える。判断がぶれない

###量と速度がポイント

量と速度が圧倒的に違う
大量のデータ、情報源の多様化
人間よりも高速、反応速度が重要

##機械学習が失敗する

出来ない精度を求める
（人間がやらないと出来ない
人にとって簡単なタスク
＊少ない情報から推論
ボトルネック
＊アクションは人が得意。人が途中に介在
＊量と速度のメリット

ルールの管理は複雑、膨大（テストが難しい）
ルールは特定のドメインに特価

##不正検知

##データ分析
１：データ収集（Hadoop、Sparks
２：データ分析
３：機械学習によってシステム化

##ルール
メンテナンス＋データ変化

グラフィカルモデル

特徴抽出はコンサルティング可能

回帰
電力消費予測、年収予測、株価予測

##教師なし学習
データをまとめあげる
変なものだけ取得
データ集合の特徴を学習
データを入れればすぐに動く
制御が難しい
教師ありの学習の前処理

##強化学習
未知の行動と既知の行動を選択する
データ取得まで自動化は強化学習（ラベルは未知
新規データの取得可能

##重要情報のフィルタリング
顧客セグメントの予測
カーネル法

自然言語処理などの超高次元空間では線形分類で十分

##分類の根拠は単純な手法の方が分りやすい
直感的に分りやすい
分類、学習速度が早い
バグを埋め込みにくい
決定木、線形分類器

##教師なし学習
メリット
教師ありの前処理：半教師あり学習（少ないラベル付けデータ
データの傾向分析
クラスタリング結果に対して人手で意味付け

綺麗に分類出来ているかすら分らないのでデータを見る
データ分類の候補にする
どのような分類基準になるか予測できない
結果の意味を解釈するのが難しい
意図通りの基準か分らない
クラスタの意味付けは分らない

##強化学習
データがない場合に有効
仮説の勝ち抜きを自動化
広告バナーの自動化
検索結果画面の自動チューニング
εーGreedy法
UCB(Upper Confidence Bound
Thompson Sampling(事後確率分布に従って、行動をサンプリング

##強化学習
教師ありデータなし
行動と評価を自動化（広告の配信とクリック
状況変化が大きくデータを貯めづらい

教師ありデータがある場合はダメ
教師データを作るコストが低い
実験的な行動を起こせない

DropOutはGoogle が特許を抑えている。
Caffe/torch/pylearn2
Chainer

機械学習を実際にサービスに活かすため

#
機械が得意な所は機械
人が得意なことは人

###機械
大量のデータ処理
24時間働く
数値データから素早い
###人
仮説を立てる
人の気持ちを理解（クリックさせる記事が良いかどうかユーザーの満足度を下げてしま
う。男性に女性の下着の広告を見せる
ニュアンスを読み取る

##アカデミックの評価がそのまま役に立つわけではない
学術研究では過去のデータをいかに再現出来るかを見る
精度が上がっても実際にユーザーに刺さるかは別
データセットによる検証によって成果を見積もることが困難
重要なのはユーザーの満足度（全体の予測性能よりカバレッジが影響。
ユーザー層が変わればモデルが変わる

数値は神より正しい

###目標設定
仮説立案
簡易な実験
モデル実装・自動化

###目標設定
Weekly Active User 
Daily Active User 
N日後継続率
Click/Daily Active User 
どの数値を上げるかをどの程度上げれるかを決める。その後のユーザー満足、会社の利
点

###仮説なきモデル実装はダメ
なぜ上がるかを把握する

仮説が正しかった場合、どの数値にどのような変化が生まれるか
仮説が間違っている
仮説に対する瀬策が間違っている
検証する項目を見る

###簡易な実験

ルールベース：ルールで試す。
ルールが出来ないのであれば、仮説が詰め切れていない
有効な特徴量は一般的にそれ単体でも有効

###モデル実装・自動化
ルールベース・人力で有効性が確認出来たらモデル化、自動化を進める
機械学習は６割程度の精度
全てをモデル化せず効率の良いポイントを考える
絞り込みを行なう
サービス改善によって重要なポイントが変わる
複雑なモデルはサービスの変化について行けるか
この改善ポイントは複雑なモデルは組む価値があるか
基本的にモデルの解釈性と精度はトレードオフ
解釈性がビジネスでは重要

###やる
小規模にやる（A/Bテスト）
数値を見る
事前の目標設定
施策があたるかあたらないかは運。結果次第
試行回数を増やす

##
ルールや人手
スケールするためには機械学習などが必要なのでやる

###学術知識
いま何ができるか知る
流行の勝ちパターンを知る
そのパターンを転用
その手法の優位性を見る。サービスの課題を解決する
WWW,KDD,WSDM
自分で一回、使ってみる

##ユーザーに興味ある情報を提示
ユーザーに興味ある情報提示：分らない
ユーザーが過去に消費した情報に類似した情報を類似
過去に消費した情報に類似しているユーザーが消費している情報
成果の低いデータを眺めて仮説を出す
改善するためになぜ上手く行かないを知る

良い点と悪い点を明確にする
データと目標数値に向き合う

##リスク管理
ユーザーが変わるとモデルが変わる
モデルの導入によって大きく下がる（データ不足、体験が変わることを嫌う、下がることを踏まえ
てテスト）
既存の体験を大きく変えるような変更は避ける（デザイン、機械学習のコントロール

##
本当に必要か：機械学習の価値
研究分野の評価指標は再現性
ひどいことに対してのカバー
推薦されたこと、コンテンツ


機械学習は特別なことではない
アカデミックの評価基準
仮説を持ってKPI設計して取り組む
サービス拡大に対しての断続的な改善は未知
モデルを過信しない（数値に対して

##試す：
少ない、仮説、ルール、人力運用
論文はデータ活用、新しい知識
何をどう応用するかは決める

##機械学習以外のアプローチ
URLの検出、ほぼ自明なルール
スペルの再入力
##少し工夫
好評・不評か判定する代わりに辞書を機械学習で作成
ユーザーの属性を機械学習で当てて、狙った層に広告を出す

###手堅い問題の方がオススメ
####教師あり分類の方がオススメ
正解情報はクラウドソーシングを利用
教師なしの場合はレコメンドなどの手堅い手法
####強化学習
報酬

##問題
データ整備に時間がかかる
当てたい変数がまぎれている
空文字、NULL、なし
おおよそできそうなもの
できるかもを行なう

データさえあれば何でもできるか NO（データから分ることだけ分る
データが沢山あれば分るか NO(100%になるか分らない　統計的な性質が分る
人間に分らないことが分る（人間の方が高性能。大量のデータからによって見られるも
のから分るものは高機能

高度な手法寄りもデータ特性の方が強く影響
データと特徴のバランスを正す
データを多くする。パラメータの数を減らす
バランスを測る尺度（赤池情報基準）

不当に精度が高い

##ケース１
重複データが混ざっている場合
本番データと学習データの傾向が違う
学習データが古い
どこまで出来るか試さないと分らない

精度が良すぎるときは疑う

複数の学習手法を試す
ハイパーパラメータを変える

データに一貫性がない
精度が落ちた場合
実用上問題ないかはデータを見る

ラベルが多すぎる問題は難しい
大分類でOKな問題に設定し直す

要件を再検討
*問題によって重みを見る
間違い事例を精査
＊必要な特徴が取れていない
より高度な方法を検討
ラベルなしデータ
外部リソースを利用した特徴

不均衡データ
正解率ではなく、適合率、再現率で見る
異常データを増やす、通常データを減らす
不均衡なデータのペナルティを変える（比率を与える）

普段の仕事で考えるか

文書分類
単語抽出
